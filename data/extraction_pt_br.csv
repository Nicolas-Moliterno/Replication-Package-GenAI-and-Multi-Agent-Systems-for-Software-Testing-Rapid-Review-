key,title,year,Test Activities,GenAI Model,Framework/Agent,Usage,Evaluation / Maturity,Limitations,Notes / References,month,day,journal,issn,volume,issue,pages,authors,url,language,publisher,location,abstract,notes,doi,keywords,pubmed_id,pmc_id,PDF files
rayyan-394626652,Test Amplification for REST APIs via Single and Multi-agent LLM Systems,2026,Casos de teste da API REST,OpenAI’s GPT-4o mini model,LangGraph LangChain,REST API,"As ferramentas tradicionais muitas vezes não têm capacidade para refinamento dinâmico e iterativo com base no feedback de execução. Nossos sistemas LLM agênticos para amplificação de API REST abordam essas lacunas, aumentando a cobertura com apenas alguns casos de teste direcionados, o que permite um pipeline de CI/CD mais qualitativo e automatizado",Ainda existem oportunidades para melhorar os resultados. O prompting desempenha um papel crucial; prompts mais bem projetados podem produzir resultados ainda melhores. A qualidade da documentação do OpenAPI é outro aspecto importante da precisão dos resultados. É a principal base de conhecimento da nossa abordagem e uma documentação OpenAPI mais abrangente pode produzir melhores resultados,"semelhante à forma como o APITestGenie validamos nossa abordagem usando o PetStore LangSmith Existem várias direções promissoras para pesquisas futuras que se baseiam nas descobertas e insights atuais de trabalhos relacionados. Um caminho importante é explorar o uso de modelos de código aberto, como o LLaMA 3.3, que mostraram desempenho competitivo em relação ao GPT-4o em avaliações recentes. Aproveitar modelos de código aberto pode aumentar a segurança ao permitir uma implantação totalmente local e, ao mesmo tempo, reduzir custos.",,,Lecture Notes in Computer Science,,16107,,161 - 177,"Nooyens, Robbe and Bardakci, Tolgahan and Beyazit, Mutlu and Demeyer, Serge",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016905732&doi=10.1007%2F978-3-032-05188-2_11&partnerID=40&md5=99a684064135afb0a18884b210cdff0c,,,,,Cited by: 0,10.1007/978-3-032-05188-2_11,Amplification; Application programming interfaces (API); Intelligent agents; Interface states; Mo...,,,Test Amplification for REST APIs via Single and Multi-agent LLM Systems.pdf
rayyan-394626653,Extracting Threats from System Descriptions with LLMs Comparing One and Two Agents Strategies,2026,automação da modelagem de ameaças,"OpenAI o3-mini, OpenAI o1, and Claude 3.7 Sonnet",-,o uso da segurança cibernética pode ajudar os testadores a identificar os principais riscos mais cedo e concentrar os esforços de teste de forma mais eficaz,"A avaliação comparou três modelos de linguagem (o1, o3 e Sonnet) em duas configurações operacionais: agente único e dois agentes, utilizando precisão, recall e F1-score como métricas. Os resultados mostram um trade-off claro entre precisão e recall. A configuração de agente único apresentou maior recall, indicando melhor cobertura de ameaças, porém com menor precisão e mais falsos positivos. Já a configuração com dois agentes aumentou consistentemente a precisão, mas reduziu o recall, resultando na detecção de menos ameaças.  Entre os modelos, o Sonnet apresentou o melhor desempenho geral em ambas as configurações, alcançando os maiores F1-scores e mantendo um equilíbrio mais consistente entre precisão e recall. O modelo o1 obteve a maior precisão, mas com recall muito baixo, o que limitou seu desempenho global. O o3 apresentou resultados mais equilibrados, porém inferiores aos do Sonnet.  Em síntese, a configuração de agente único é mais adequada quando a prioridade é cobertura completa de ameaças, enquanto a configuração com dois agentes favorece cenários que exigem maior precisão. Em ambos os casos, o Sonnet demonstrou ser o modelo mais confiável para apoiar testes de cibersegurança por meio da identificação automatizada de ameaças.","a qualidade destes modelos não superou consistentemente a dos modelos criados por especialistas humanos. Os resultados do LLM muitas vezes careciam de profundidade, omitiam certas ameaças ou continham raciocínio falho","Estrutura STRIDE (Spoofing, Adulteração, Repúdio, Divulgação de Informações, Negação de Serviço, Elevação de Privilégio) O conjunto de dados usado neste estudo foi compilado a partir de vários exemplos de modelos de ameaças disponíveis publicamente https://github.com/TalEliyahu/Threat_Model_Examples 8 https://github.com/hysnsec/awesome-threat-modelling?tab=readme-ov-file# Para facilitar a análise, os documentos coletados foram pré-processados e divididos em dois conjuntos de dados estruturados: – Conjunto de dados de descrições do sistema: inclui descrições textuais de 24 sistemas diferentes. – Conjunto de dados da lista de ameaças: Contém um total de 745 ameaças identificadas associadas a estes sistemas, com uma média de aproximadamente 31 ameaças por sistema. Outra descoberta importante é que os LLMs sugeriram alguns novos métodos de ataque que não foram incluídos no conjunto de dados. Essas ideias de ataque não foram vistas antes nos dados de treinamento, mas são lógicas e podem ser usadas por invasores. Isso significa que os LLMs podem ajudar a identificar ameaças futuras antes que elas se tornem problemas reais, tornando-os ferramentas úteis na pesquisa de segurança cibernética e no planejamento de defesa. Metodologia DevSecOps modelo PYTM",,,Lecture Notes in Computer Science,,16107,,231 - 247,"Zelenskiy, Leonid and Sadovykh, Andrey",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016904785&doi=10.1007%2F978-3-032-05188-2_15&partnerID=40&md5=f99ae9370a58abd4366247580d9c8511,,,,,Cited by: 0,10.1007/978-3-032-05188-2_15,Cybersecurity; Industrial management; Information systems; Information use; Network security; Cyb...,,,978-3-032-05188-2.pdf
rayyan-394626662,Query-efficient and dataset-independent red teaming for LLMs content safety evaluation,2025,"Red Teaming Automatizado (Teste Adversarial) e Avaliação de Segurança de Conteúdo. O objetivo é gerar prompts de ataque que exponham vulnerabilidades no modelo alvo, forçando-o a gerar conteúdo tóxico ou ilegal.","Llama-2-7b-chat e Vicuna-7b-v1.5 (Modelos Alvo). Usa um LLM ""Gerador"" para criar os ataques iniciais.",RAPT (Reinforcement Learning-based Adaptive Prompt Testing). Arquitetura cíclica composta por: 1. Generator: Um LLM que cria candidatos a casos de teste (ataques). 2. Selector: Um agente de Aprendizagem por Reforço (Contextual Multi-Armed Bandit) que aprende quais ataques são mais eficazes e seleciona apenas os melhores para enviar ao alvo.,"Otimização Adaptativa de Testes: Diferente de frameworks que geram milhares de testes aleatórios (fuzzing cego), o RAPT: 1. Gera um lote de ataques. 2. O Selector estima a probabilidade de sucesso baseado no histórico. 3. Executa apenas os testes de alta probabilidade. 4. Usa o resultado (sucesso/falha) para atualizar a política do agente (Update Autônomo da Estratégia).","Alta Maturidade (Publicado em Journal Q1). Métricas: Taxa de Sucesso de Ataque (ASR), Eficiência de Consulta (número de queries para achar falha) e Diversidade. Resultados: O RAPT superou baselines de estado da arte (como PEZ e GBDA) atingindo maior ASR com menos consultas ao modelo, provando a tese de eficiência.","Dependência do Gerador: A criatividade dos ataques ainda é limitada pelo vocabulary do LLM gerador inicial. Foco em Texto: O estudo limita-se a ataques textuais, sem considerar injeções multimodais (imagens) que são tendências em 2025.","Eficiência via Seleção Inteligente: Para a sua tese, este é o argumento técnico para ""Eficiência"": não basta gerar testes autonomamente; é preciso ter um mecanismo (neste caso, RL) para filtrar e priorizar os testes antes da execução. Isso reduz custos computacionais e tempo de CI/CD.",,,Knowledge-Based Systems,,329,,,"Liu, Shuo and Cheng, Xiang and Su, Sen",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015138753&doi=10.1016%2Fj.knosys.2025.114404&partnerID=40&md5=71877d405c7b4e49a76a50db48ef3ed7,,,,,Cited by: 0,10.1016/j.knosys.2025.114404,Computational linguistics; Markov processes; Natural language processing systems; Query processin...,,,Query-efficient and dataset-independent red teaming for LLMs content safety evaluation.pdf
rayyan-394626667,DCA-Bench: A Benchmark for Dataset Curation Agents,2025,"casos de teste, Cada caso de teste normalmente contém vários arquivos, projetados para criar um ambiente mínimo para descobrir problemas ocultos de qualidade de dados","agente curador de linha de base, que é baseado na API OpenAI Assistant com GPT-4-0125-preview equipado com a ferramenta Code Interpreter Para desenvolver um avaliador confiável e econômico, testamos os seguintes modelos como backend GPT-4o (2024-11-20); GPT-4o (2025-05-13); o3-mini (31/01/2025); GPT-4 (prévia 0125); GPT-3.5-Turbo; Llama 3.3 70B Instruct; Llama 3 70B Instruct; DeepSeek-R1; DeepSeek-V3",SGLang LangChain,A coleção Dataset Curation Agent Benchmark de casos representativos de problemas de qualidade de dados de plataformas populares de conjuntos de dados,"A curadoria de conjuntos de dados é um problema complexo e abrangente, e os casos de teste que coletamos podem não cobrir totalmente todo o conjunto de problemas. Pesquisas futuras podem se concentrar no desenvolvimento de sistemas de agentes LLM mais sofisticados, estabelecendo as melhores práticas para gerenciar informações multimodais na curadoria de conjuntos de dados","devido à complexidade dos arquivos do conjunto de dados, não podemos garantir que todos os problemas nos arquivos do conjunto de dados no DCA-Bench sejam rotulados",Dataset Quality Management,,,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,2,,5482 - 5492,"Huang, Benhao and Yu, Yingzhuo and Huang, Jin and Zhang, Xingjian and Ma, Jiaqi W.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014362039&doi=10.1145%2F3711896.3737422&partnerID=40&md5=fe0bf44c620b538b3308c99a81c94e05,,,,,Cited by: 0; All Open Access; Gold Open Access,10.1145/3711896.3737422,Artificial intelligence; Data curation; Human computer interaction; Intelligent agents; Large dat...,,,2406.07275v2_40_.pdf
rayyan-394626670,Mutation-Guided LLM-based Test Generation at Meta,2025,Teste de mutação,Llama 3.1 70Bn,TestGen-LLM,Meta’s Llama team,"valiação industrial em larga escala: abordagem implementada e avaliada em um ambiente industrial real (Meta), indicando alto nível de maturidade experimental.  Prova de conceito avançada / pré-adoção industrial: sistema ACH demonstra viabilidade prática ao integrar geração de mutantes e geração de testes baseada em LLMs.  Resultados empíricos promissores, com evidências de que LLMs reduzem barreiras históricas da aplicação de mutation testing na indústria.  Não totalmente generalizado: apesar dos resultados positivos, a maturidade ainda depende de validação em outros contextos (linguagens, domínios e tipos de falhas). valiação industrial em larga escala: abordagem implementada e avaliada em um ambiente industrial real (Meta), indicando alto nível de maturidade experimental.  Prova de conceito avançada / pré-adoção industrial: sistema ACH demonstra viabilidade prática ao integrar geração de mutantes e geração de testes baseada em LLMs.  Resultados empíricos promissores, com evidências de que LLMs reduzem barreiras históricas da aplicação de mutation testing na indústria.  Não totalmente generalizado: apesar dos resultados positivos, a maturidade ainda depende de validação em outros contextos (linguagens, domínios e tipos de falhas). Resultados empíricos promissores, com evidências de que LLMs reduzem barreiras históricas da aplicação de mutation testing na indústria. Não totalmente generalizado: apesar dos resultados positivos, a maturidade ainda depende de validação em outros contextos (linguagens, domínios e tipos de falhas).","Generalização incerta: resultados podem ser específicos a Kotlin, Android, contexto da Meta ou a falhas de privacidade simuladas. Relevância dos mutantes: dificuldade em garantir que mutantes gerados representem instâncias específicas de falhas reais, e não apenas a classe geral do problema. Ausência de métricas formais de similaridade entre falhas, dificultando a avaliação consistente da relevância dos mutantes. Dependência de oráculo de regressão: abordagem protege contra regressões futuras, mas não detecta falhas já existentes no código. Problema do oráculo não resolvido: ausência de inferência automática de oráculos com alta precisão pode gerar falsos positivos e desperdício de esforço. Necessidade de maior precisão em geração de testes e oráculos para evitar sobrecarga em engenheiros. Fluxos LLM ainda exploratórios: necessidade de mais pesquisa em fine-tuning, prompt engineering, re-prompting e Chain-of-Thought para garantir relevância e confiabilidade.",O modelo de linguagem única Llama 3.1 70Bn [42] foi utilizado em todos os agentes relatados. Os prompts usados pelos três agentes do LLM,,,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,,,180 - 191,"Foster, Christopher and Gulati, Abhishek and Harman, Mark and Harper, Inna and Mao, Ke and Ritchey, Jillian and Robert, Hervé and Sengupta, Shubho",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013964900&doi=10.1145%2F3696630.3728544&partnerID=40&md5=72e4cc0d7327e32e3ebb61d1e2662a5f,,,,,Cited by: 1,10.1145/3696630.3728544,Automatic test pattern generation; Engineers; Software testing; Automated test generations; Equiv...,,,Mutation-Guided LLM-based Test Generation at Meta_r3t.pdf
rayyan-394626672,ProphetAgent: Automatically Synthesizing GUI Tests from Test Cases in Natural Language for Mobile Apps,2025,Testes de GUI de casos de teste,"GPT4o Para responder ao RQ2, realizamos testes usando um LLM diferente, Doubao-pro-128k",ProphetAgent,"Mobile Apps Avaliação do método em aplicações Android reais, incluindo dois aplicativos industriais de larga escala (Douyin e Doubao, da ByteDance) e seis aplicativos Android de código aberto, com o objetivo de validar a efetividade e a generalização da abordagem em cenários reais de teste funcional.","Avaliação empírica extensa: método avaliado em 120 casos de teste, com taxa de conclusão de execução de 78,1% e baixa taxa de falsos positivos (6,8%). Validação em aplicações industriais reais (ex.: Douyin), aumentando a credibilidade e relevância prática dos resultados Validação humana parcial: verificação manual da acurácia semântica realizada por profissionais (88% de acurácia) Comparação indireta com trabalhos relacionados, indicando desempenho superior, embora sem comparação direta por indisponibilidade de ferramentas anteriores. Estágio avançado de protótipo / pré-adoção industrial, demonstrando ganhos claros de produtividade e viabilidade prática","Suporte limitado ao nível de abstração: ProphetAgent lida apenas com casos de teste de baixo nível, exigindo que cada sentença represente uma única ação, não suportando intenções de alto nível. Dependência do grafo de conhecimento (CUTG): só gera testes executáveis para cenários previamente explorados e incluídos no grafo. Cobertura condicionada à exploração automática: uso de técnicas básicas de exploração (Droidbot), o que limita o alcance de cenários mais complexos ou raros Sensibilidade ao formato de entrada: requer descrições textuais cuidadosamente formatadas para garantir parsing e execução corretos Ameaças à validade externa: resultados podem depender da representatividade dos aplicativos selecionados Ameaças à validade interna: erros na anotação semântica podem afetar a efetividade do método, apesar da acurácia relativamente alta (88%) Generalização dependente de avanços futuros em técnicas de exploração e enriquecimento do grafo de conhecimento","O objetivo principal do ProphetAgent é permitir que desenvolvedores e testadores executem automaticamente etapas de teste em linguagem natural. O SemanticAgent anota cada informação de transição com informações semânticas explícitas em páginas de interface do usuário e eventos de interface do usuário. O GenerationAgent é responsável por combinar um caminho no CUTG que se alinha com o caso de teste escrito em linguagem natural e gerar código executável para execução. Implantamos o GUI Explorer para explorar o aplicativo de destino e registrar as informações de transição da GUI após cada evento da IU ser executado. O Graph Builder aproveita os dados de transição da GUI coletados pelo GUI Explorer para agrupar páginas e eventos da IU construindo o CUTG enriquecido com informações semânticas Nosso experimento visa responder a estas questões de pesquisa: • RQ1: Quão eficaz e eficiente é o ProphetAgent na síntese de testes de GUI a partir das etapas de teste em linguagem natural e como ele se compara às técnicas de última geração? • RQ2: Qual é o impacto dos diferentes agentes LLM no método que propomos? Comparamos nosso método com duas técnicas principais para converter linguagem natural em testes de GUI executáveis: uma técnica mais estabelecida (AppAgent [31]) e uma técnica de última geração recente (AutoDroid [28]), ambas as quais utilizam LLMs para gerar testes de GUI executáveis para aplicativos Android a partir de frases que descrevem tarefas de GUI. https://github.com/prophetagent/Home Uma demonstração do ProphetAgent está disponível em https://youtu. be/iCsGis__5gg",,,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,,,174 - 179,"Kong, Qichao and Lv, Zhengwei and Xiong, Yiheng and Sun, Jingling and Su, Ting and Wang, Dingchun and Li, Letao and Yang, Xu and Huo, Gang",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013961463&doi=10.1145%2F3696630.3728543&partnerID=40&md5=b5c6eee38a63a745a4434ad68f42cac5,,,,,Cited by: 0,10.1145/3696630.3728543,Application programs; Computer software selection and evaluation; Graphic methods; Graphical user...,,,fse2025-ProphetAgent.pdf
rayyan-394626673,From Overload to Insight: Bridging Code Search and Code Review with LLMs,2025,"Apoio à revisão de código Análise de mudanças (change sets) Atua indiretamente sem garantia de qualidade, mas não gera nem executa testes. Atividades de teste: Suporte à revisão de código / Análise de qualidade (indireta) Propõe um assistente humano no circuito baseado em LLM para integrar os resultados da pesquisa de código na revisão de código, com o objetivo de reduzir a sobrecarga cognitiva e melhorar a eficácia do revisor.","O artigo não especifica explicitamente modelos concretos (ex.: GPT-4, Claude)","LLM-based Interactive Assistant (Human-in-the-Loop) Não utiliza frameworks explícitos como LangChain, AutoGen ou LangGraph.","Suporte à revisão de código (Code Review) Uso principal:  Reduzir sobrecarga cognitiva dos revisores  Agregar e contextualizar resultados de múltiplas ferramentas  Permitir interações context-aware, guiadas por perguntas do revisor Uso principal:  Reduzir sobrecarga cognitiva dos revisores  Agregar e contextualizar resultados de múltiplas ferramentas  Permitir interações context-aware, guiadas por perguntas do revisor","Estágio exploratório / conceitual com protótipo O trabalho propõe uma nova direção de pesquisa ao integrar code search + code review mediado por LLMs Não há validação em larga escala nem avaliação quantitativa formal O foco está em design, interação humano-no-loop e potencial de impacto, não em maturidade industrial",Ausência de avaliação empírica quantitativa Não há estudo de:  Precisão  Recall  Impacto mensurável na qualidade do código Dependência de:  Qualidade das ferramentas de busca existentes  Capacidade do LLM de sintetizar corretamente informações heterogêneas Não aborda:  Custos computacionais  Questões de segurança ou privacidade Possível risco de:  Sobrecarga cognitiva se mal projetado  Confiança excessiva nas respostas do LLM,"O sistema atua como:  Assistente interativo para code review  Camada de orquestração e sumarização de resultados de ferramentas de busca Arquitetura conceitual, centrada na interação contínua entre humano e LLM",,,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,,,656 - 660,"Rao, Nikitha and Vasilescu, Bogdan and Holmes, Reid",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013959386&doi=10.1145%2F3696630.3728518&partnerID=40&md5=44b507a779648293d9b152108a61218b,,,,,Cited by: 0; All Open Access; Gold Open Access,10.1145/3696630.3728518,Automation; Computer software selection and evaluation; Software quality; Software testing; Stati...,,,From_Overload_to_Insight_Bridging_Code_Search_and_Code_Review_with_LLMs.pdf
rayyan-394626679,"AI-DRIVEN TOOLS IN MODERN SOFTWARE QUALITY ASSURANCE: AN ASSESSMENT OF BENEFITS, CHALLENGES, AND FUTURE DIRECTIONS",2025,"O artigo cobre praticamente todo o espectro de QA, incluindo Análise estática de código  Geração de casos de teste funcionais  Validação de casos de teste  Geração de testes unitários e de integração  Otimização de suíte de testes  Mutation testing  Testes end-to-end automatizados  Testes exploratórios  Equivalence partitioning  Metamorphic testing  Validação de aplicações baseadas em IA","múltiplos modelos de IA generativa OpenAI: GPT-4.5, GPT-4o, GPT-4o-mini Google: Gemini-2.5-Pro, Gemini-2.0-Flash-Lite Mistral: Mistral-Large, Ministral-8B Transformers especializados: CodeBERT (análise estática) O artigo também compara modelos grandes vs. pequenos, analisando custo, desempenho e flakiness","O artigo não propõe um único framework proprietário, mas descreve uma arquitetura conceitual composta por múltiplos agentes e componentes, incluindo LLM-as-a-Generator (test case e unit test generation);  LLM-as-a-Judge para validação de casos de teste;  Agentes ReAct para execução end-to-end (reasoning + acting);  Integração com ferramentas existentes (SonarQube, CodeBERT, Playwright, BrowserUse);  Pipelines com RAG (Retrieval-Augmented Generation) para enriquecimento de contexto;  Uso de mutation testing guiado por LLM Portanto, trata-se de um framework arquitetural híbrido e agent-based, orientado a tarefas de QA","O uso principal é Quality Assurance moderna em sistemas distribuídos e aplicações web/enterprise, com foco em Acelerar a criação de testes a partir de requisitos textuais;  Reduzir custo e esforço manual em QA;  Automatizar regressões end-to-end de forma mais resiliente a mudanças de UI;  Apoiar shift-left testing;  Melhorar cobertura e confiabilidade de testes;  Suporte a pipelines CI/CD com agentes inteligentes O trabalho demonstra uso prático e experimental avançado, indicando aplicabilidade real em ambientes industriais, embora ainda com necessidade de supervisão humana","O trabalho representa uma evolução consolidada do uso de IA em QA, saindo de aplicações isoladas (ex.: geração de testes ou análise estática pontual) para uma visão integrada ao longo de todo o SDLC. Diferentemente de estudos anteriores focados em uma única técnica, o artigo demonstra a combinação progressiva de:  análise estática baseada em transformers,  geração automática de casos de teste,  geração de testes estruturais (unitários e de integração),  otimização via mutation testing,  automação end-to-end com agentes baseados em LLM Além disso, avança o estado da arte ao avaliar maturidade prática, custos, flakiness e viabilidade industrial, indicando uma transição clara de pesquisa exploratória para adoção semi-industrial / experimental avançada","O estudo identifica limitações claras e relevantes para adoção prática nconsistência de formato e qualidade, especialmente em modelos menores;  Tendência dos agentes a “corrigir” testes negativos, gerando falsos negativos;  Geração de cobertura semanticamente redundante;  Baixa explicabilidade dos LLMs (black-box);  Risco de loops de raciocínio em agentes menos capazes;  Dependência de APIs externas e custos computacionais;  Necessidade de verificação humana dos resultados;  Potencial efeito de deskilling em profissionais de QA Essas limitações mostram que a tecnologia ainda requer governança, guardrails e validação rigorosa","Os modelos são usados em diferentes papéis:  geração de testes,  julgamento de qualidade (LLM-as-a-Judge),  execução agentic end-to-end,  análise semântica,  suporte à mutation testing Código, dados e logs disponibilizados publicamente no GitHub eferências extensivas sobre mutation testing, ReAct, metamorphic testing e LLM-as-a-Judge",,,Technology Audit and Production Reserves,,3,2,44 - 54,"Pysmennyi, Ihor and Kyslyi, Roman and Kleshch, Kyrylo",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011843831&doi=10.15587%2F2706-5448.2025.330595&partnerID=40&md5=25baf85fa1312707ac7952b86bd77ad4,,,,,Cited by: 0; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access,10.15587/2706-5448.2025.330595,,,,"AI-DRIVEN TOOLS IN MODERN SOFTWARE QUALITY ASSURANCE AN ASSESSMENT OF BENEFITS, CHALLENGES, AND FUTURE DIRECTIONS_8u9.pdf"
rayyan-394626697,Beyond Test Cases: Multi-Agent Collaboration for Detecting Defects in Full-Score Code Implementations,2025,Avaliação funcional de código Detecção de defeitos semânticos Geração de contraexemplos Validação formal de comportamentos Análise além de test cases tradicionais Verificação de conformidade com especificações Vai além de testes: análise semântica e verificação formal guiada por LLMs,"O artigo não fixa um único modelo específico, focando no papel funcional do LLM, não no fornecedor Uso de LLMs como agentes de raciocínio e síntese, não como oráculo final Large Language Models (LLMs) utilizados para:  geração de especificações formais,  análise semântica do código,  raciocínio sobre possíveis defeitos","Maveric: um framework multiagente composto por quatro agentes especializados Template Generator Agent  Deriva especificações formais a partir da descrição do problema Consistency Checker Agent  Verifica alinhamento semântico entre a especificação gerada e o problema original Code Analyzer Agent  Analisa o código, identifica defeitos potenciais e gera contraexemplos Counterexample Validator Agent  Valida formalmente os contraexemplos usando técnicas de verificação formal Arquitetura multi-agent + formal methods, fortemente modular e orientada a verificação",Avaliação automática de código em plataformas educacionais Detecção de defeitos ocultos em códigos que passam todos os testes Especialmente útil onde test cases são insuficientes para garantir corretude,"Avança o estado da arte ao ir além de avaliação baseada apenas em casos de teste, atacando explicitamente o problema de falsos positivos de corretude Evolui de abordagens LLM-only para uma arquitetura híbrida LLM + verificação formal.  Introduz uma colaboração multiagente especializada, onde cada agente atua em uma etapa distinta do processo de avaliação Representa um passo importante rumo a avaliação de corretude semântica completa, especialmente em ambientes educacionais e de programação competitiva","Dependência da qualidade da especificação formal gerada automaticamente pelo LLM Potencial limitação de generalização para domínios fora de programação algorítmica bem especificada Avaliação focada em 100 submissões completas, o que pode limitar escalabilidade para grandes bases industriais Requer infraestrutura de verificação formal, o que pode aumentar complexidade de adoção Voltado principalmente para defeitos funcionais, não cobrindo aspectos não funcionais (performance, segurança, usabilidade)","Avaliação empírica com 100 códigos de nota máxima, oriundos de 10 tarefas reais de uma plataforma educacional amplamente utilizada Revisão manual identificou 32 códigos com defeitos funcionais Maveric detectou 31 defeitos corretamente, sem falsos positivos Tempo médio de avaliação: < 1 minuto por programa LLM-only baseline: 25 defeitos detectados + 6 falsos positivos Demonstra vantagem clara da colaboração multiagente com verificação formal.",,,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",,,,124 - 129,"Li, Yiwei and Liu, Jiaxin and Hu, Yanfeng and Liu, Chen and Zhang, Yating and Yin, Liangze and Dong, Wei",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018743838&doi=10.18293%2FSEKE2025-053&partnerID=40&md5=6b4813dad78e2b4f3340c1ac6b4a3fe8,,,,,Cited by: 0,10.18293/SEKE2025-053,Codes (symbols); Computer programming languages; Computer systems programming; Defects; E-learnin...,,,Beyond_Test_Cases_MultiAgent_Collaboration_for.pdf
rayyan-394626698,Comparative Study on Test Case generation using Generative AI,2025,"Geração de Testes Unitários (Unit Test Generation). O foco é criar testes que garantam que o software atenda aos requisitos e padrões, medindo cobertura e qualidade.","Closed Source: GPT-4o (Melhor performance), GPT-3.5, OpenAI Codex Open Source: Llama 3.1 (8B, 70B, 405B), DeepSeek-Coder V2 (16B), CodeLlama (7B a 70B), Codestral 22B, Gemma 27B.","Utilizou o benchmark TestGenEval (baseado em 11 repositórios Python reais) e HumanEval . Ambiente de execução via Docker e scripts Python automatizados . O estudo discute o uso futuro de ""AI Agents"" e ""RAG"" (Retrieval Augmented Generation), mas o experimento principal foi via prompting direto.",A solução utiliza Prompting direto nos modelos via API (para modelos fechados) ou inferência local (para modelos abertos) . O fluxo é: Seleção do Modelo -> Seleção do Dataset -> Prompting -> Avaliação estatística . O estudo sugere o uso futuro de Chain of Thought (CoT) e Role-playing para melhorar a qualidade.,"Métrica: Cobertura de Código (Code Coverage) e Mutation Score . Resultados: GPT-4o atingiu 35.2% de cobertura e 18.8% de Mutation Score. O melhor Open Source foi Llama 3.1 70B com 30.6% de cobertura. Maturidade: Estudo comparativo acadêmico. Conclui que os modelos atuais ""ainda não estão no nível de equipes humanas de QA"".","Alucinações/Erros: Testes gerados com imports incorretos, variáveis indefinidas ou incompletos Janela de Contexto: Dificuldade em entender o escopo completo do código em projetos grandes Hardware: Modelos grandes (ex: Llama 3.1 405B) são difíceis de rodar localmente Lógica de Negócio: Modelos falham em capturar regras de negócio específicas e casos de borda (edge cases)","Eficiência: O estudo destaca o modelo DeepSeek-Coder V2 16B como uma opção viável para rodar localmente (""home setting"") com 28.2% de cobertura, equilibrando custo e performance . Autonomia/Updates: O artigo sugere explicitamente para trabalhos futuros o uso de Agentes de IA que possam ""criar arquivos e alterar códigos ou configurações automaticamente mantendo o contexto do projeto inteiro"" Estratégia de Contexto: Propõe ""Escopo Dinâmico"" (Dynamic Scope) para manter apenas partes importantes do código no contexto durante a geração em grandes projetos",,,,,,,366 - 369,"Azzam, Adham and Hany, Omar and Mansour, Hesham",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018464135&doi=10.1109%2FIMSA65733.2025.11166964&partnerID=40&md5=b86914aaa102a4a2761613b1734aa6aa,,,,,Cited by: 0,10.1109/IMSA65733.2025.11166964,Artificial intelligence; Open source software; Open systems; Closed source; Comparatives studies;...,,,Comparative_Study_on_Test_Case_generation_using_Generative_AI_vSm.pdf
rayyan-394626699,An LLM-based software developer agent demonstrated through a port-logistic optimization case study,2025,Geração automática de testes unitários suporte indireto a validação de requisitos (SRS) e revisão de código,GPT-4o Claude 3.7 Sonnet (LLMs proprietários),Agente próprio baseado em LangGraph (arquitetura multi-step com validação e competição entre modelos),"O agente gera código e, na etapa final, gera testes unitários automaticamente para as implementações selecionadas testes fazem parte de um pipeline agentic de desenvolvimento",Protótipo experimental; avaliação por estudos de caso (Snake game e framework de otimização logística sem métricas formais de qualidade de teste Distante de uso industrial real para testes autônomos,Testes unitários gerados são dependentes da qualidade do código gerado; dificuldades em contextos complexos alta de avaliação empírica específica da qualidade/cobertura dos testes forte necessidade de intervenção humana,"""the agent … is capable of generating … function implementations, and corresponding unit tests”   An_LLMbased_software_developer_…  ; testes aparecem como subproduto do desenvolvimento, não como foco principal",,,,,,,,"Dulai, Tibor and Kiss, Gábor",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018454710&doi=10.1109%2FACDSA65407.2025.11166656&partnerID=40&md5=07beea4a4eddd6e7f441df7515005770,,,,,Cited by: 0,10.1109/ACDSA65407.2025.11166656,Computer programming; Intelligent agents; Logistics; Ports and harbors; Software testing; Specifi...,,,An_LLMbased_software_developer_agent_demonstrated_through_a_portlogistic_optimization_case_study.pdf
rayyan-394626700,"Multi-Agent LLM Collaboration for Adaptive Code Review, Debugging, and Security Analysis",2025,Revisão automática de código (qualidade) Detecção de defeitos (debugging) Análise de segurança (vulnerabilidades) suporte a QA contínuo,"LLMs pré-treinados (ex.: GPT-4, CodeLlama – modelos exatos podem variar)",Framework multi-agente próprio com três agentes especializados + FAISS (RAG/memória de longo prazo),"Código é analisado automaticamente por agentes paralelos (review, debugging, segurança), com refinamento colaborativo e adaptação baseada em histórico do desenvolvedor; aplicável em CI/CD e IDEs","Protótipo experimental avançado avaliação quantitativa com experimentos controlados (precisão, latência, adaptação do usuário)",Não gera casos de teste explicitamente foco em análise estática/semântica dependência de modelos proprietários resultados baseados em snippets e não em grandes sistemas industriais,"“multi-agent LLM framework for adaptive code review, debugging, and security analysis”   MultiAgent_LLM_Collaboration_fo…  ; demonstra redução de feedback redundante e melhoria de precisão ao longo do tempo",,,,,,,541 - 546,"Sharanarthi, Tanush and Polineni, Sreenidhi",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017962329&doi=10.1109%2FMRAI65197.2025.11135756&partnerID=40&md5=c1c8dcd7efc5a31fdf3f2f8723e6caf1,,,,,Cited by: 0,10.1109/MRAI65197.2025.11135756,Codes (symbols); Computer programming languages; Computer software selection and evaluation; Dist...,,,MultiAgent_LLM_Collaboration_for_Adaptive_Code_Review_Debugging_and_Security_Analysis.pdf
rayyan-394626702,Enhancing LLM-based Quantum Code Generation with Multi-Agent Optimization and Quantum Error Correction,2025,est-driven development (TDD) implícito validação sintática e semântica uso de test suites para avaliar código gerado testes experimentais sob ruído quântico; avaliação de confiabilidade via QEC,StarCoder-3B (fine-tuned) GPT-4o usado para geração de prompts CoT/SCoT,"Framework multi-agente próprio (3 agentes: Code Generator, Semantic Analyzer, QEC Decoder) com multi-pass inference, CoT, SCoT, RAG",A GenAI gera código quântico iterativamente; uma test suite própria é usada para validar correção sintática e semântica resultados são avaliados por métricas de teste (pass@k) e por execução experimental com e sem correção de erros,"Protótipo acadêmico avançado avaliação quantitativa extensa (pass@k, % de testes válidos, experimentos sob ruído) domínio específico (quantum)",Não gera casos de teste explicitamente; foco em análise estática/semântica dependência de modelos proprietários resultados baseados em snippets e não em grandes sistemas industriais,demonstra redução de feedback redundante e melhoria de precisão ao longo do tempo,,,,,,,,"Campbell, Charlie and Chen, Mark and Luk, Wayne W.C. and Fan, Hongxiang",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017605997&doi=10.1109%2FDAC63849.2025.11133316&partnerID=40&md5=27976ae3a148261af6d3b69c8ea47b27,,,,,Cited by: 0,10.1109/DAC63849.2025.11133316,Automatic programming; Computer programming languages; Error correction; Intelligent agents; Iter...,,,Enhancing_LLMbased_Quantum_Code_Generation_with_MultiAgent_Optimization_and_Quantum_Error_Correction.pdf
rayyan-394626707,OpenROAD Agent: An Intelligent Self-Correcting Script Generator for OpenROAD,2025,"Validação automática baseada em testes de execução; detecção de falhas (scripts inválidos); verificação funcional indireta via métricas de design (DRC, timing, área, potência)",LLM (não explicitamente nomeado; modelo proprietário via API),OpenROAD Agent – agente GenAI com loop de auto-correção integrado ao OpenROAD EDA flow,"O agente gera scripts Tcl, executa o fluxo OpenROAD, usa falhas de execução e métricas como oráculo de teste, e corrige o script automaticamente até atingir critérios válidos","Protótipo acadêmico avançado avaliação empírica com múltiplos designs e métricas quantitativas (taxa de sucesso, número de iterações, QoR)",Não há geração explícita de casos de teste testes são específicos do domínio EDA dependência forte do ambiente OpenROAD; ausência de avaliação industrial longitudinal,falhas de execução funcionam como mecanismo de teste,,,,,,,16 - 22,"Wu, Bingyue and Sharma, Utsav and Rovinski, Austin and Chhabria, Vidya A.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015871212&doi=10.1109%2FICLAD65226.2025.00039&partnerID=40&md5=163d4d6230f67a28f31669c32c0f1cfa,,,,,Cited by: 0,10.1109/ICLAD65226.2025.00039,Computational linguistics; Integrated circuit design; Open source software; Open systems; Personn...,,,OpenROAD_Agent_An_Intelligent_SelfCorrecting_Script_Generator_for_OpenROAD.pdf
rayyan-394626709,Toward Generative 6G Simulation: An Experimental Multi-Agent LLM and ns-3 Integration,2025,Geração automática de casos de teste; execução automática de testes validação funcional e de desempenho; debugging baseado em falhas testes de estresse e edge cases análise de resultados,LLMs via ChatOpenAI (ex.: GPT-4o / gpt-4o-mini) embeddings OpenAI,"Framework multi-agente baseado em LangChain + LangGraph, integrado ao ns-3 (Simulation Generation Agent, Test Designer Agent, Test Executor Agent, Result Interpretation Agent)","Testes são gerados automaticamente pelo Test Designer Agent executados pelo Test Executor Agent resultados (logs, métricas) são analisados por LLM e usados para atualizar automaticamente o código da simulação em loop iterativo","Protótipo acadêmico avançado, com avaliação quantitativa detalhada (pass@k, iterações médias, tempo de resposta, taxa de erro sintático, métricas de desempenho de simulação)",Domínio específico (simulação de redes 5G/6G) testes dependem de frameworks do ns-3 ausência de validação industrial real necessidade de conhecimento especializado para interpretar métricas,“the Test Designer Agent generates comprehensive automated test suites” pipeline completo de geração–teste–execução–interpretação,,,,,,,,"Rezazadeh, Farhad and Gargari, Amir Ashtari and Lagen, Sandra and Song, Houbing and Niyato, Dusit (Tao) and Liu, Lingjia",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015738145&doi=10.1109%2FMeditCom64437.2025.11104374&partnerID=40&md5=d97a85dffc69ab925ee5e4de28c33ce6,,,,,Cited by: 0,10.1109/MeditCom64437.2025.11104374,Chains; Codes (symbols); Computational linguistics; Computer simulation languages; Computer syste...,,,Toward Generative 6G Simulation An Experimental Multi-Agent LLM and ns-3 Integration_oho.pdf
rayyan-394626714,AgentTester: An LLM-Based Tool for Unit Test Generation with Automatically Generated Prompts,2025,"geração automática de casos de teste consistindo em módulos de AutoPrompting, Prompt Distillation e Validation-Repair",ChatGLM API glm-4 model gpt-3.5-turbo,O modelo ChatTester e a configuração experimental do seu artigo original servem como base de comparação com o AgentTester.,"AgentTester, que consiste em três módulos principais: AutoPrompting, Prompt Distillation e Validation-Repair Geração automática de casos de teste unitários para projetos Java utilizando LLMs Avaliação da qualidade dos testes gerados em termos de:  Correção sintática.  Taxa de compilação.  Taxa de testes corretos.  Cobertura (linha, método, classe e branch) Aplicado em três projetos Java reais (jInstagram, TabulaPDF, Zappos)","três projetos Java representativos, provenientes do GitHub, como projetos de referência com mais de 15 mil linhas de código e mais de mil métodos principais. Esses três projetos possuem testes JUnit escritos por desenvolvedores, o que é benéfico para gerar e compilar casos de teste sem se preocupar com a configuração do ambiente Abordagem experimental e acadêmica, validada por meio de estudos empíricos comparativos Evolução clara em relação a abordagens anteriores baseadas apenas em LLM:  Supera ChatTester e AthenaTest em taxa de testes corretos e cobertura de linhas.  Introduz melhorias incrementais por meio de módulos especializados (PD e VR). Comparada também com ferramentas tradicionais (EvoSuite), mostrando:  Menor desempenho em branch coverage.  Desempenho superior em line coverage Ainda não é apresentada como ferramenta industrial consolidada (nível protótipo de pesquisa) Protótipo acadêmico com validação empírica controlada","Cobertura de branches inferior quando comparada a ferramentas de geração baseadas em busca, como EvoSuite Taxa de compilação ainda não ideal:  Mesmo com melhorias, cerca de 27% dos testes gerados não compilam no total agregado Avaliação restrita a:  Apenas três projetos Java.  Apenas linguagem Java (limitação de generalização) Dependência de múltiplas execuções e amostragem com diferentes temperaturas, aumentando custo computacional. Não há discussão sobre:  Tempo de execução.  Custos financeiros do uso de LLMs.  Integração contínua em pipelines industriais (CI/CD) Filtragem de testes que compilam mas falham na execução pode reduzir diversidade de casos de teste","Para avaliar minuciosamente o desempenho do AgentTester, selecionamos vários modelos amplamente reconhecidos como linhas de base, incluindo técnicas tradicionais (EvoSuite), baseadas em aprendizado (AthenaTest) e baseadas em LLM (ChatTester) AgentTester apresenta ganho de até 22,5% na taxa de testes corretos em comparação com ChatTester O módulo Prompt Distillation (PD) é o principal responsável pela melhoria de qualidade:  Aumentos significativos nas taxas de compilação e correção (até +26,4% em jInstagram) O módulo Prompt Distillation (PD) é o principal responsável pela melhoria de qualidade:  Aumentos significativos nas taxas de compilação e correção (até +26,4% em jInstagram) O módulo Validation-Repair (VR) contribui com cerca de +20% de melhoria ao corrigir testes com erros Demonstra que LLMs, quando combinados com agentes e validação automática, podem superar abordagens LLM “diretas” Evidência empírica de que estratégias híbridas (LLM + validação programática) são mais eficazes para teste automático",,,Communications in Computer and Information Science,,2574,,114 - 126,"Chen, Honghui and Chen, Kaiqing and Zhang, Fanlong and Wang, Tao and Cheng, Lianglun",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013062510&doi=10.1007%2F978-981-95-0011-6_10&partnerID=40&md5=b7408785d11617d826eacb243fc81dd8,,,,,Cited by: 0,10.1007/978-981-95-0011-6_10,Automatic test pattern generation; Error correction; Software reliability; Software testing; Auto...,,,Advanced_Intelligent_Computing_Technology_and_Applications.pdf
rayyan-394626716,Comprehensive Study on Integrating AI-Powered Threat Intelligence Using Large Language Models,2025,Automated Penetration Testing (APT) Mapeamento de Rede (Host Discovery) Análise de Vulnerabilidades,Gemini 1.5 Pro GPT-4 (avaliado como alternativa),Hierarchical AI Agent System (Multi-agent) LangChain JS Docker/Kubernetes para orquestração de ferramentas,"O sistema utiliza um Master Supervisor que coordena três times de agentes especializados: Pentesting, Cybersecurity Research e Report Making A ""atualização autônoma"" do conhecimento da rede é feita via algoritmo Bellman-Ford modificado, que descobre caminhos incrementalmente, simulando descoberta em tempo real, enquanto agentes acionam ferramentas (Nmap, sqlmap) via API",PoC Acadêmica / Experimental Testado em laboratório usando hardware de borda (Raspberry Pi 5 Model B) para provar eficiência de recursos Validado através da varredura bem-sucedida de URLs reais (ex: google.com) e geração de logs,"Janela de Contexto: Resultados de scans extensos estouram o limite do LLM, exigindo chunking Alucinação: Recomendações de segurança imprecisas ou desatualizadas Custo Computacional: Exige otimização para rodar em hardware limitado","O algoritmo simula processos de descoberta em tempo real atualizando caminhos incrementalmente à medida que novas informações de rede ficam disponíveis"" Destaque para a arquitetura de Microserviços + Agentes para escalabilidade",,,,,,,2141 - 2146,"Nishith, P. and Ratnam, S. Ajay and Bhaskaran, Sreebha",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012111569&doi=10.1109%2FICCSAI64074.2025.11063731&partnerID=40&md5=0ec7b8043470ba4929b72c5dbf36ce97,,,,,Cited by: 0,10.1109/ICCSAI64074.2025.11063731,Automation; Cybersecurity; Integration testing; Intelligent agents; Network security; Algorithmic...,,,Comprehensive_Study_on_Integrating_AIPowered_VuJ.pdf
rayyan-394626721,A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs,2025,REST API Testing (Black-box) Geração de Entradas de Teste (Input Generation) Inferência de Dependências entre Operações,GPT-3.5 Turbo,"AutoRestTest (Framework proprietário baseada em Multi-Agent Reinforcement Learning - MARL). Possui 4 agentes especializados: Operation, Dependency, Parameter, Value.","Abordagem híbrida onde o LLM é acionado apenas pelo Value Agent através de few-shot prompting para gerar valores que exigem conformidade semântica (ex: e-mails, IDs específicos) A ""atualização autônoma"" da estratégia de teste é feita via Reinforcement Learning, atualizando tabelas-Q e pesos em um grafo de dependência (SPDG) com base nos códigos de resposta HTTP (2xx, 4xx, 5xx).",Alta (Acadêmica - ICSE 2025) Validado em 12 serviços REST reais (incluindo Spotify e OhSome). Superou 4 ferramentas estado-da-arte (incluindo RESTler e EvoMaster) em cobertura de código (+15-26%) e detecção de falhas Detectou 42 erros internos de servidor (status 500) contra 33 da segunda melhor ferramenta,"Data Leakage: O modelo pode ter sido treinado com dados das APIs públicas testadas, inflando resultados Qualidade da Especificação: A eficácia depende da completude da especificação OpenAPI fornecida Latência de Rede: Testes em APIs reais sofrem com comportamento ""flaky"" devido à rede","""AutoRestTest trata o teste de API REST como um problema separável [...] O LLM lida com a geração de valores específicos do domínio, enquanto o modelo SPDG simplifica o espaço de busca."" A remoção do componente LLM na ablação reduziu a cobertura em ~10-12%",,,Proceedings - International Conference on Software Engineering,,,,1409 - 1421,"Kim, Myeongsoo and Stennett, Tyler and Sinha, Saurabh and Orso, Alessandro",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010327327&doi=10.1109%2FICSE55347.2025.00179&partnerID=40&md5=4727c4956022848d4318383703af88cb,,,,,Cited by: 0,10.1109/ICSE55347.2025.00179,Application programming interfaces (API); Intelligent agents; Machine learning; Multi agent syste...,,,A_MultiAgent_Approach_for_REST_API_Testing_with_Semantic_Graphs_and_LLMDriven_Inputs.pdf
rayyan-394626722,NIODebugger: A Novel Approach to Repair Non-Idempotent-Outcome Tests with LLM-Based Agent,2025,Reparação de Flaky Tests (especificamente do tipo NIO - Non-Idempotent-Outcome),GPT-4 (melhor desempenho) GPT-3.5 Qwen 2.5 DeepSeek-Coder,NIODebugger (Agente baseado em LLM) Implementado como um plugin Maven para Java,"Utiliza um sistema de três fases (deteção, exploração e correção) O agente de IA planeia e executa ações de forma autónoma para extrair código-fonte relevante fora do método de teste, simulando um programador humano para resolver ""poluição de estado""",Alta (ICSE 2025) Testado em 20 projetos open-source de larga escala Gerou patches corretos para 101 de 172 testes NIO 58 patches foram fundidos (merged) em repositórios reais,Janela de Contexto: A capacidade de incluir código fonte relevante é limitada pelo tamanho da janela do LLM Dependência de Análise Dinâmica: Requer múltiplas execuções para identificar padrões de falha,"Primeiro framework a usar um agente autónomo para corrigir flaky tests. É capaz de ""limpar"" o estado poluído de forma autónoma através de instruções que o próprio LLM gera para procurar métodos de limpeza no código",,,Proceedings - International Conference on Software Engineering,,,,1014 - 1025,"Ke, Kaiyao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010297534&doi=10.1109%2FICSE55347.2025.00226&partnerID=40&md5=9fae623678ae69408c15f101a9b493d6,,,,,Cited by: 1,10.1109/ICSE55347.2025.00226,Codes (symbols); Nickel oxide; Open source software; Open systems; Repair; Software agents; Conte...,,,NIODebugger_A_Novel_Approach_to_Repair_NonIdempotentOutcome_Tests_with_LLMBased_Agent.pdf
rayyan-394626726,Automated Bug Discovery in Cloud Infrastructure-as-Code Updates with LLM Agents,2025,Teste de Atualizações de Infraestrutura (IaC) Descoberta de bugs em operações de atualização (Update logic) Geração de programas Terraform,GPT-4o,"IaC-BugFinder (Sistema multi-agente). Inclui agentes: Generator, Executor e Analyzer","Utiliza agentes para gerar programas IaC iniciais e, em seguida, gerar de forma autónoma sequências de atualização (mudar parâmetros, relações) O Analyzer compara o estado final da nuvem com o estado desejado para detetar discrepâncias (bugs)","PoC Acadêmica (AIOps 2025). Testado contra o provedor Terraform da AWS Descobriu 4 bugs críticos (3 no provedor AWS e 1 no Terraform core), todos confirmados pelos desenvolvedores",Custo de Token: Sequências longas de atualização aumentam o custo Oráculos de Teste: Dificuldade em distinguir se uma falha é do provedor de nuvem ou da ferramenta de teste,"""IaC-BugFinder automatiza a descoberta de bugs em atualizações de infraestrutura... um domínio onde o teste manual é impraticável devido ao vasto espaço de estados."" [pág. 1, 5]",,,,,,,20 - 25,"Xiang, Yiming and Yang, Zhenning and Peng, Jingjia and Bauer, Hermann and Kon, Patrick Tser Jern and Qiu, Yiming and Chen, Ang",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009458915&doi=10.1109%2FAIOps66738.2025.00011&partnerID=40&md5=22fec64a714f3a2c99b17a030e2ddc74,,,,,Cited by: 1,10.1109/AIOps66738.2025.00011,Cloud computing; Cloud platforms; Codes (symbols); Program debugging; Software reliability; Cloud...,,,Automated Bug Discovery in Cloud Infrastructure-as-Code Updates with LLM Agents_msW.pdf
rayyan-394626728,Human-In-The-Loop Software Development Agents: Challenges and Future Directions,2025,"Testes unitários: testes FAIL_TO_PASS e testes PASS_TO_PASS para verificar a resolução de problemas e manter a funcionalidade existente. Análise estática usando SonarQube para avaliar métricas de qualidade de código, como cheiros de código, complexidade e duplicação.",GPT-4 (as part of AppMap Navie + GPT 4o),Not mentioned,Avaliando patches de agentes de desenvolvimento de software em problemas reais do GitHub para avaliar seu impacto na qualidade do código,"Método de avaliação: Comparação de patches gerados por agentes com ""patches dourados"" de desenvolvedores de repositórios. Métricas de desempenho: precisão, recall, pontuação F1 para alinhamento com patches dourados; SonarQube para confiabilidade, segurança e manutenibilidade. Testes estatísticos: teste de postos sinalizados de Wilcoxon e teste U de Mann-Whitney para mudanças significativas na qualidade do código e resolução de problemas. Principais conclusões: Nenhum agente único dominou; os agentes mantiveram confiabilidade e segurança, mas variaram em complexidade e duplicação; melhor desempenho em tarefas mais simples.",Limitação na avaliação do SWE-Bench: Os patches gerados pelo agente podem não ser totalmente cobertos pelos casos de teste atuais. Possíveis problemas de viés de coleta de dados e confiabilidade de medição. Generalizabilidade limitada para outras linguagens de programação ou tipos de projetos. As métricas podem não capturar totalmente todos os aspectos da qualidade do código ou do desempenho do agente. A suposição de que as manchas de ouro são ótimas pode nem sempre ser precisa. Necessidade de pesquisas futuras para melhorar o tratamento de cenários complexos e questões propensas à vulnerabilidade.,"O estudo fornece a primeira avaliação abrangente dos patches dos agentes de desenvolvimento de software sobre problemas reais do GitHub, destacando que nenhum agente domina e sugerindo que dividir tarefas complexas em tarefas mais simples pode melhorar a eficácia. A maioria dos agentes mantém a confiabilidade e a segurança do código, mas precisa de melhorias para minimizar a complexidade e a duplicação do código",,,,,,,756 - 757,"Pasuksmit, Jirat and Takerngsaksiri, Wannita and Thongtanunam, Patanamon Pick and Tantithamthavorn, Kla (kla) and Zhang, Ruixiong and Wang, Shiyan and Jiang, Fan and Li, Jing and Cook, Evan and Chen, Kun and Wu, Ming",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009162123&doi=10.1109%2FMSR66628.2025.00112&partnerID=40&md5=698142c669aae605243d9a432638bec7,,,,,Cited by: 0,10.1109/MSR66628.2025.00112,Information systems; Intelligent agents; Multi agent systems; Software quality; Software testing;...,,,Human-In-The-Loop_Software_Development_Agents_Challenges_and_Future_Directions.pdf
rayyan-394626731,Special Session: ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification,2025,"Modelagem de Ameaças de Segurança (Threat Modeling) e Geração de Planos de Teste de Segurança Foco específico em vulnerabilidades de hardware exploráveis por software (ex: escalonamento de privilégios, corrupção de memória) e ataques à cadeia de suprimentos.",GPT-4o Utilizou OpenAI embeddings para a representação semântica no RAG,"ThreatLens (Framework Multi-agente) Composto por agentes especializados: Threat Identification Agent, Security Policy Generator Agent e Test Plan Generator Agent Tecnologias base: LangChain, RAG (Retrieval-Augmented Generation) e FAISS (para busca de similaridade)","RAG: Extrai conhecimento de segurança de papers acadêmicos e manuais de instruções (ISA) para contextualizar o modelo Fluxo Multi-Agente: Um agente identifica a ameaça, outro extrai a política de segurança do manual (ex: RISC-V ISA), e um terceiro gera o plano de teste Refinamento: O sistema interage com o engenheiro apenas para validar suposições iniciais, atualizando dinamicamente seu ""banco de perguntas""","Estudo de Caso em SoC Real Resultado: A ferramenta gerou automaticamente 854 políticas de segurança únicas, cobrindo vulnerabilidades críticas como violações de PMP (Physical Memory Protection) Validado através de estudos de caso onde a falha na verificação destas políticas levou a hacks reais","Dependência de Modelo Fechado: O uso do GPT-4o implica custos computacionais elevados e dependência de API externa Falta de Extração de Ativos: O sistema ainda não extrai automaticamente todos os ""security assets"" do design, o que poderia reduzir consultas redundantes","Eficiência na Atualização: O artigo destaca que métodos manuais ""lutam para escalar"" com a evolução das metodologias de ataque. A abordagem agêntica permite atualizar o Test Plan apenas ingerindo novos papers de segurança na base RAG, sem reescrever o código do agente Autonomia: A capacidade de gerar 854 políticas de forma autónoma demonstra um ganho de eficiência massivo sobre a verificação manual",,,Proceedings of the IEEE VLSI Test Symposium,,,,,"Saha, Dipayan and Al-Shaikh, Hasan and Tarek, Shams and Farahmandi, Farimah",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008498031&doi=10.1109%2FVTS65138.2025.11022932&partnerID=40&md5=7aa515b66bd36cec92dc68c0e6f83d34,,,,,Cited by: 0,10.1109/VTS65138.2025.11022932,Computer hardware; Human computer interaction; Verification; Hardware security and trust; LLM; Pl...,,,Special Session ThreatLens LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification_8OZ.pdf
rayyan-394626732,CKGFuzzer: LLM-Based Fuzz Driver Generation Enhanced By Code Knowledge Graph,2025,Fuzz testing automatizado geração automática de fuzz drivers geração de input seeds mutação guiada por cobertura análise automática de crashes,DeepSeek-V2-Coder (geração e repair) DeepSeek-V2-Chat (agentes auxiliares) LLMs para sumarização e raciocínio,CKGFuzzer – sistema multiagente integrado a Code Knowledge Graph + RAG customizado + libFuzzer/OSS-Fuzz,Geração autônoma de fuzz drivers a partir de APIs reparo automático de erros de compilação geração inicial de seeds via LLM mutação de combinações de APIs baseada em cobertura classificação e análise de crashes via cadeia de raciocínio,"Protótipo acadêmico avançado, avaliado empiricamente em 8 bibliotecas open-source métricas quantitativas (branch coverage, taxa de compilação, bugs reais encontrados) comparação com OSS-Fuzz e PromptFuzz",Dependência forte da qualidade do Code Knowledge Graph avaliado apenas em bibliotecas C/C++ alto custo computacional; risco de alucinações do LLM generalização para outras linguagens ainda não validada,#ERROR!,,,Proceedings - International Conference on Software Engineering,,,,243 - 254,"Xu, Hanxiang and Ma, Wei and Zhou, Ting and Zhao, Yanjie and Chen, Kai and Hu, Qiang and Liu, Yang and Wang, Haoyu",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008497196&doi=10.1109%2FICSE-Companion66252.2025.00079&partnerID=40&md5=3f96e9b2e02faa23fe1edaa25aa1a65b,,,,,Cited by: 0,10.1109/ICSE-Companion66252.2025.00079,Accidents; Application programming interfaces (API); Codes (symbols); Computer software selection...,,,CKGFuzzer LLM-Based Fuzz Driver Generation Enhanced By Code Knowledge Graph_d2B.pdf
rayyan-394626734,AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL,2025,"Teste automatizado de REST APIs geração automática de sequências de operações geração de parâmetros, valores e headers exploração de dependências entre operações detecção de erros 4xx/5xx fuzzing leve por mutação de requisições","LLMs da OpenAI (ex.: GPT-4o, GPT-4o-mini, o1, o1-mini) usados para geração de valores realistas e headers foco exclusivo em REST APIs LLM restrito à geração de valores (não gera lógica de teste completa) dependência de OAS 3.0 custos associados ao uso de LLMs","AutoRestTest – framework híbrido com Multi-Agent Reinforcement Learning (MARL) + Semantic Property Dependency Graph (SPDG) + agentes especializados (operation, parameter, value, dependency, header)","O LLM é usado principalmente para gerar valores de parâmetros e headers MARL seleciona operações, dependências e combinações execução iterativa com feedback baseado em respostas HTTP (2xx, 4xx, 5xx) atualização contínua das Q-tables","Protótipo acadêmico funcional, avaliado empiricamente em 4 APIs REST reais (FDIC, OMDb, OhSome, Spotify) métricas quantitativas (operações exercitadas, erros únicos, status codes) comparação direta com RESTler, EvoMaster, ARAT-RL e MoRest",Avaliação preliminar (tempo fixo de 1h),unica ferramenta a obter respostas 2xx no serviço OhSome detectou erro 5xx inédito no Spotify,,,Proceedings - International Conference on Software Engineering,,,,21 - 24,"Stennett, Tyler and Kim, Myeongsoo and Sinha, Saurabh and Orso, Alessandro",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008493507&doi=10.1109%2FICSE-Companion66252.2025.00015&partnerID=40&md5=6b424c86446186db5a71163dacbdd1aa,,,,,Cited by: 0,10.1109/ICSE-Companion66252.2025.00015,Application programming interfaces (API); Error detection; Fault detection; Intelligent agents; M...,,,2501.08600v2.pdf
rayyan-394626736,Towards Architectural Pen Test Case Generation and Attack Surface Analysis to Support Secure Design,2025,Geração de casos de teste de penetração (architectural penetration test cases) análise de superfície de ataque priorização de testes de segurança suporte a security testing na fase de design,"LLMs (não especificados), planejados para geração de casos de teste e apoio à threat modeling","Framework conceitual proposto (baseado em modelos arquiteturais como PCM, threat modeling, CWE/CAPEC/CVE, com futura integração de LLMs)","Uso planejado de LLMs para gerar casos de teste de penetração a partir de modelos arquiteturais, priorizá-los com base em severidade e apoiar arquitetos com feedback de segurança ainda na fase de design",Proposta de pesquisa / plano conceitual sem implementação nem avaliação empírica no momento,Não há implementação ausência de avaliação experimental modelo GenAI não definido abordagem ainda hipotética foco restrito à fase de design,LLMs são citados como tecnologia habilitadora futura,,,,,,,143 - 148,"Sarvejahani, Mahdi Jafari",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007880639&doi=10.1109%2FICSA-C65153.2025.00027&partnerID=40&md5=c705d9b1be50927d023e0e9155558783,,,,,Cited by: 0,10.1109/ICSA-C65153.2025.00027,Computer operating systems; Computer software selection and evaluation; Embedded software; Intell...,,,Towards_Architectural_Pen_Test_Case_Generation_and_Attack_Surface_Analysis_to_Support_Secure_Design.pdf
rayyan-394626737,Evaluation of the Choice of LLM in a Multi-Agent Solution for GUI-Test Generation,2025,"Teste de GUI Exploratório Automatizado (Automated Exploratory GUI Testing) Foco em aplicações web (e-commerce), com o objetivo de realizar tarefas complexas de ponta a ponta (ex: ""fazer uma compra online"") sem scripts pré-gravados.","Llama 3.1, Gemma 2, Mistral-Nemo. Nota: Todos utilizados em versões quantizadas (4-bit) para execução local (Local LLMs), visando privacidade e baixo custo",PathFinder (Framework Multi-Agente Proprietário) Arquitetura composta por 4 agentes especializados: 1. Perceptron: Coleta e resume o HTML/DOM. 2. System 1: Toma decisões de navegação (clicar/digitar) 3. EntryBot: Gerencia dados de entrada (preenche formulários com dados de usuários fictícios). 4. Oracle: Valida se o teste passou ou falhou.,"O sistema não usa scripts (ex: Selenium IDE). Ele recebe uma URL e um objetivo (Prompt: ""Compre um item"") Os agentes operam num ciclo Observe-Reason-Act: - O Perceptron converte a página em JSON limpo. - O System 1 decide a ação com base no histórico. - O Oracle verifica o sucesso a cada 5 passos. O estudo testou 27 permutações diferentes de modelos entre os agentes.","Maturidade Acadêmica (Experimento Empírico). Cenário: 4 sites de e-commerce reais. Métricas: Eficácia (F1-Score) e Eficiência (Tempo de execução). - O Llama 3.1 foi o modelo mais robusto individualmente. - Curiosamente, a hipótese de que ""misturar modelos especializados é melhor"" foi parcialmente refutada; usar um modelo forte (Llama 3.1) em todos os agentes gerou resultados mais consistentes devido à melhor coordenação.","Coordenação entre Agentes: Usar modelos diferentes em agentes diferentes causou discrepâncias na comunicação (um modelo não entendia bem o output do outro). Alucinação de Seletores: O modelo às vezes inventa IDs de elementos (mitigado no paper usando Fuzzy String Matching). Dependência de Contexto: O agente Perceptron exige janela de 8k tokens, o que limita o uso de modelos muito pequenos ou antigos.","Relevância para Updates Autônomos: Este é um exemplo perfeito de Self-Healing implícito. Como não há script ""hard-coded"" (apenas o objetivo em linguagem natural), se a UI mudar (botão mudar de lugar), o agente adapta-se automaticamente, resolvendo o problema de manutenção de testes de GUI. Privacidade: Destaca-se por provar que é possível rodar agentes de teste complexos localmente (sem enviar dados para OpenAI), um requisito chave para muitas empresas.",,,,,,,487 - 497,"Tomic, Stevan and Alégroth, Emil and Isaac, Maycel",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007519090&doi=10.1109%2FICST62969.2025.10989038&partnerID=40&md5=a9c1278607d06e5157ef49503bf355f4,,,,,Cited by: 0; All Open Access; Green Accepted Open Access; Green Open Access,10.1109/ICST62969.2025.10989038,Ability testing; Autonomous agents; C (programming language); Intelligent agents; Model checking;...,,,Evaluation of the Choice of LLM in a Multi-Agent Solution for GUI-Test Generation_QNd.pdf
rayyan-394626738,"Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios",2025,Teste de correção funcional usando o conjunto de dados SWE-bench Pontuação de similaridade baseada em GPT usando GPT-4 e GPT-4o,GPT-4 GPT-4o,HULA (Human-In-The-Loop LLM-based Software Development Agents Framework),Desenvolvimento de software e resolução de problemas usando agentes de desenvolvimento de software humanos no loop para resolver itens de trabalho do Jira,"Métodos de avaliação: Teste de correção funcional usando conjunto de dados SWE-bench, pontuação de similaridade baseada em GPT. Métricas de desempenho: taxa de resolução de 37,2% no conjunto de dados verificado do SWE-bench, pontuação de similaridade alta de 38,5% para itens de trabalho. Validação: Forte concordância com avaliações humanas (coeficiente de correlação: 0,7), pontuação F1: 0,67 para representação de testes unitários.",Altos custos computacionais de testes unitários. Variabilidade nas avaliações baseadas em LLLM. Criação de conjuntos de dados que exigem muito trabalho para testes unitários. Resultados binários de aprovação/reprovação em testes unitários. Execução de testes cara e demorada. Dificuldade em avaliar pequenas melhorias incrementais devido aos resultados flutuantes do LLM.,----,,,,,,,657 - 668,"Chen, Zhi and Jiang, Lingxiao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007302779&doi=10.1109%2FSANER64311.2025.00068&partnerID=40&md5=1e5568549f4eba6213f35f8ccaa4be56,,,,,Cited by: 0,10.1109/SANER64311.2025.00068,Application programs; Computer operating systems; Computer software maintenance; Computer softwar...,,,2410.12468v2_dGu.pdf
rayyan-394626739,Approach to Forming Vulnerability Datasets for Fine-Tuning AI Agents,2025,Detecção de vulnerabilidades (security testing) via análise estática de código suporte indireto a testes de segurança durante desenvolvimento e testes geração de dados para treinamento e atualização de agentes de teste,CodeQwen 2.5 (7B) fine-tuned uso de ChatGPT-4o para geração de amostras sintéticas de vulnerabilidades raras,"Pipeline de curadoria de datasets para fine-tuning de agentes de IA (não é um agente de teste em si); scripts em Python + Polars integração com CVE, GitHub Advisory e repositórios OSS",GenAI é usada para (i) fine-tuning de modelos de detecção de vulnerabilidades e (ii) geração sintética de exemplos para balanceamento do dataset; objetivo é criar agentes de segurança continuamente atualizáveis,"Protótipo experimental avaliado dataset real (2013–2025) fine-tuning realizado e avaliado com métricas clássicas (Precision, Recall, F1, FPR) resultados quantitativos reportados, porém desempenho ainda limitado",Foco exclusivo em Python análise apenas estática baixa capacidade de generalização inicial do modelo recall baixo para várias CWE dependências externas não analisadas testes não são executados no SUT,284 vulnerabilidades sintéticas geradas com ChatGPT-4o (custo ≈ US$9),,,,,,,771 - 776,"Gladkikh, Kirill and Zakharov, Alexander A.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007163730&doi=10.1109%2FSmartIndustryCon65166.2025.10986048&partnerID=40&md5=c17a17e425a33f43983fe72168611c09,,,,,Cited by: 0,10.1109/SmartIndustryCon65166.2025.10986048,Computer software selection and evaluation; Data curation; Data flow analysis; Model checking; Op...,,,14259.pdf
rayyan-394626746,Adaptive Test Healing using LLM/GPT and Reinforcement Learning,2025,Test healing automático; manutenção e atualização de testes funcionais adaptação de testes a mudanças no SUT identificação de falhas por mudanças na UI/fluxo,GPT (LLM da OpenAI) usado para sugerir correções de testes; modelo RL (Q-learning) para seleção de ações,"Framework híbrido LLM + Reinforcement Learning para manutenção de testes agentes responsáveis por detectar falhas, propor correções e aprender estratégias de reparo","Quando testes falham devido a mudanças no sistema, o LLM sugere modificações nos scripts de teste o agente RL escolhe e aplica a melhor ação feedback da execução atualiza a política, permitindo aprendizado contínuo","Protótipo acadêmico / estudo experimental avaliação em cenários controlados de testes automatizados métricas qualitativas e quantitativas (taxa de sucesso de healing, redução de esforço manual)",Avaliação limitada em escala foco em testes funcionais/UI ependência de LLM proprietário ausência de estudo industrial de longo prazo possíveis erros do LLM exigem validação humana,demonstra redução significativa de manutenção manual de testes,,,,,,,9 - 16,"Mani, Nariman and Attaranasl, Salma",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004735212&doi=10.1109%2FICSTW64639.2025.10962516&partnerID=40&md5=b70259ee11a7c7ada5d2d2cab21e9645,,,,,Cited by: 1,10.1109/ICSTW64639.2025.10962516,C (programming language); Computer operating systems; Computer software selection and evaluation;...,,,Adaptive_Test_Healing_using_LLM_GPT_and_Reinforcement_Learning.pdf
rayyan-394626752,Multi-Agent hierarchical workflow for autonomous code generation with Large Language Models,2025,Geração de Testes Unitários (Unit Test Development) Depuração Autônoma (Automated Debugging) Validação de Código Gerado,GPT-4o,"Multi-Agent Hierarchical Workflow Integra AlphaCodium, LangChain e LangGraph Agentes específicos: Programmer, Unit Test, Executor, e Debugging","O fluxo utiliza uma abordagem hierárquica onde, após a geração do código (usando a técnica Skeleton-of-Code para paralelismo) um Unit Test Agent verifica o código e um Debugging Agent resolve falhas identificadas pelo Executor Agent. Os agentes têm acesso a ferramentas externas (Wolfram Alpha, Web Search) para validar lógica e sintaxe","PoC Acadêmica (Conferência de Estudantes IEEE) Avaliado em 3 datasets clássicos (ex: California Housing) Comparado com ChatGPT, Claude e Perplexity. Atingiu 100% de precisão funcional nos testes realizados e pontuação máxima em legibilidade Execução rápida (3.4s - 5.7s)","Escopo Limitado: O protótipo atual foca apenas em análise de dados via arquivos CSV. Escalabilidade: Precisa evoluir para suportar formatos complexos (JSON, XML) e dados em tempo real Risco de Segurança: O artigo cita a necessidade de supervisão para evitar vulnerabilidades em código gerado por IA","""O sistema opera analisando o conjunto de dados... atribuindo agentes que trabalham sequencialmente: um agente programador..., um agente de teste unitário verifica o código, e um agente executor executa o código."". Destaque para a técnica Skeleton-of-Code para reduzir latência",,,,,,,,"Akilesh, S. and Sekar, Rajeev and Om Kumar, C. U. and Prakalya, D. and Suguna, M.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002712410&doi=10.1109%2FSCEECS64059.2025.10940635&partnerID=40&md5=82551e1af9a6048e627580f4f80faab8,,,,,Cited by: 1,10.1109/SCEECS64059.2025.10940635,Ada (programming language); Application programs; Autonomous agents; C (programming language); Co...,,,Multi-Agent_hierarchical_workflow_for_autonomous_code_generation_with_Large_Language_Models.pdf
rayyan-394626754,Using LLM-Based Deep Reinforcement Learning Agents to Detect Bugs in Web Applications,2025,Teste de GUI Black-Box (Aplicativos Web) Teste Exploratório Detecção de Bugs,Gemma-7b (Modelo local),Agente DRL (Deep Reinforcement Learning) baseado em PPO (Proximal Policy Optimization) usando Stable Baselines3 e Selenium.,"O LLM é usado como um sensor de inferência de estado Em vez de depender de APIs de navegador (que variam entre Chrome/Safari), o agente extrai o HTML cru e pergunta ao LLM: ""Este elemento é clicável?"". A resposta (0 ou 1) é adicionada ao vetor de estado do agente RL para guiar a exploração","PoC Acadêmica (ICAART 2025). Validado numa aplicação web customizada (Vue.js) O agente com auxílio do LLM atingiu a recompensa máxima em 5 épocas, empatando com o agente que tinha acesso aos dados reais do navegador, e superando largamente o agente sem essa informação (11 épocas) Acurácia de inferência do LLM foi de 81.5% em elementos reais extraídos da web.","Latência de Inferência: Executar o LLM a cada passo é lento; mitigado via caching Complexidade da App: Testado apenas numa app simples; apps complexas podem aumentar o ruído na inferência Generalização: Não validado em cenários onde a ""clicabilidade"" não é o fator crítico","""Nossa hipótese é que combinar as capacidades inferenciais de LLMs com a robustez do DRL pode igualar a acurácia de métodos que dependem de coleta direta de dados"" Abordagem focada em Cross-Browser Testing eficiente.",,,International Conference on Agents and Artificial Intelligence,,3,,1001 - 1008,"Sakai, Yuki and Tahara, Yasuyuki and Ohsuga, Akihiko and Sei, Yuichi",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001979448&doi=10.5220%2F0013248800003890&partnerID=40&md5=e11343925c0bfbc45c2e1839fd45504a,,,,,Cited by: 0,10.5220/0013248800003890,,,,132488.pdf
rayyan-394626756,Agentic AI for Behavior-Driven Development Testing Using Large Language Models,2025,Geração automática de testes BDD (Gherkin) apoio à especificação de testes funcionais/aceitação correção sintática e semântica de testes ligação entre linguagem natural e implementação de testes,LLM open-source fine-tuned (Llama 3.1 8B) uso de GPT-4 apenas para geração sintética de dados de treino,"BDDTestAIGen – framework Agentic AI com LLM + NLP clássico (POS, SRL) + RAG + human-in-the-loop, integrado ao Behave / Gherkin","O agente guia o usuário na criação de testes BDD em linguagem natural, mapeia passos (Given/When/Then) para implementações existentes, corrige erros e solicita intervenção humana quando há ambiguidade foco em reduzir esforço manual e incluir stakeholders não técnicos","Protótipo acadêmico com avaliação empírica avaliação quantitativa (1.983 testes sintéticos, taxa de matching, tipos de erro) e qualitativa (estudo com desenvolvedores e não programadores em jogos comerciais)",Dependência de human-in-the-loop não há geração totalmente autônoma de testes foco exclusivo em BDD problemas com conversão de unidades e tipos não atualiza automaticamente o SUT,"“first study to combine LLMs, NLP, human-in-the-loop and Agentic AI to automate BDD test creation” matching correto em >50% dos casos com modelo 8B fine-tuned",,,International Conference on Agents and Artificial Intelligence,,2,,805 - 815,"Päduraru, Ciprian Ionut and Zavelca, Miruna and Ştefǎnescu, Alin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001687420&doi=10.5220%2F0013374400003890&partnerID=40&md5=9a5f5ecb6df9a0851aa031db5d4e7894,,,,,Cited by: 0,10.5220/0013374400003890,,,,133744.pdf
rayyan-394626759,FlexFL: Flexible and Effective Fault Localization With Open-Source Large Language Models,2025,"Localização de falhas (Fault Localization) para suporte a debugging e testes identificação de métodos defeituosos a partir de testes falhos, relatórios de bugs ou ambos apoio direto à atividade de análise de falhas em testes automatizados",LLMs open-source (principalmente Llama 3-8B-Instruct) também avaliado com Qwen2-7B-Instruct e Mistral-Nemo-12B-Instruct,"FlexFL, framework em duas fases com agentes LLM (Agent4SR e Agent4LR) + técnicas clássicas de FL (SBFL, IRFL, HybridFL) uso de ReAct + function calls simuladas","O sistema usa GenAI para reduzir o espaço de busca e depois refinar a localização de falhas, analisando código, testes falhos e bug reports suporta múltiplas fontes de informação e executa análise quase totalmente automática","Alta maturidade acadêmica avaliação extensa em Defects4J v1.0 e v2.0.0 omparação com SOTA (AutoFL, AgentFL, SBIR, Ochiai) métricas Top-1/3/5, MAP, MRR código e pacote de replicação públicos",Não executa testes nem corrige defeitos depende da qualidade dos testes/relatórios disponíveis desempenho ainda limitado pela capacidade do LLM base; falhas em bugs complexos ou ambíguos,O FlexFL supera as técnicas existentes de localização de falhas e pode localizar 93 bugs que não podem ser localizados por técnicas não baseadas em LLM” primeira abordagem de FL com LLMs de código aberto,,,IEEE Transactions on Software Engineering,,51,5,1455 - 1471,"Xu, Chuyang and Liu, Zhongxin and Ren, Xiaoxue and Zhang, Gehao and Liang, Ming and Lo, David",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000368545&doi=10.1109%2FTSE.2025.3553363&partnerID=40&md5=fb2b1f9a800980a644f4ff5a2d40e048,,,,,Cited by: 0,10.1109/TSE.2025.3553363,Computer debugging; Computer software selection and evaluation; Open source software; Outages; Pr...,,,FlexFL Flexible and Effective Fault Localization With Open-Source Large Language Models_0Qq.pdf
rayyan-394626764,Self-Collaboration Code Generation via ChatGPT,2024,Debugging localização de falhas análise de falhas em testes geração de testes unitários compreensão e explicação de código suporte geral a atividades de V&V,"LLMs proprietários e open-source (ex.: GPT-3.5/4, Codex, LLaMA) avaliados em zero-shot",Não propõe um framework específico uso de prompting direto e chain-of-thought como mecanismo cognitivo,"LLMs são usados como reasoners gerais para resolver tarefas de SE sem treinamento específico, incluindo explicar falhas, localizar defeitos a partir de código e gerar testes unitários simples",Estudo experimental amplo avaliação em múltiplos benchmarks de SE métricas de acurácia e sucesso por tarefa não há integração em pipelines reais de teste,Não há autonomia operacional tarefas são isoladas desempenho sensível a prompting ausência de integração contínua ou aprendizado incremental,“LLMs demonstrate strong zero-shot reasoning capabilities across a wide range of software engineering tasks” evidencia que LLMs podem apoiar testing mesmo sem fine-tuning,,,ACM Transactions on Software Engineering and Methodology,,33,7,,"Dong, Yihong and Jiang, Xue and Jin, Zhi and LI, Ge",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198255497&doi=10.1145%2F3672459&partnerID=40&md5=c103ee9b9813f3e4926767fd4a5695f6,,,,,Cited by: 50,10.1145/3672459,Benchmarking; Computer software selection and evaluation; Intelligent agents; Intelligent virtual...,,,2304.07590v3_qfq.pdf
rayyan-394626766,First Experiments on Automated Execution of Gherkin Test Specifications with Collaborating LLM Agents,2024,Execução automática de testes de aceitação (BDD) automação de testes baseados em Gherkin geração dinâmica de código de teste web exploração automática do SUT avaliação de resultados de execução,GPT-3.5-turbo-0125 GPT-4o,"AutoGen multi-agent framework com agentes colaborativos (Coordinator, Coder, Executor, Analyst) integrados a Playwright para testes web","A partir de cenários Gherkin (Given-When-Then), os agentes exploram autonomamente o sistema, geram scripts Python de teste, executam ações no navegador, analisam o HTML retornado e decidem próximos passos até concluir o cenário ou abortar","Work-in-progress / estudo experimental inicial avaliação empírica em 15 cenários Gherkin (simples, complexos e negativos) no sistema PetClinic; métricas detalhadas (taxa de sucesso, tempo, número de interações, tokens, exceções) comparação GPT-3.5 vs GPT-4o","Escala limitada forte dependência do modelo LLM problemas de hallucinação, especialmente em cenários negativos detecção de falhas ainda fraca custos elevados (GPT-4o) ausência de aprendizado persistente entre execuções","“LLM agent system is able to automatically run the given test scenarios by autonomously exploring the system under test, generating executable test code on the fly, and evaluating execution results” GPT-4o executou 100% dos cenários simples e complexos com sucesso",,,,,,,12 - 15,"Bergsmann, Severin and Schmidt, Alexander and Fischer, Stefan and Ramler, Rudolf",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207104093&doi=10.1145%2F3678719.3685692&partnerID=40&md5=96e8a10edaf283adc4a4c1910d96fd0e,,,,,Cited by: 1,10.1145/3678719.3685692,Autonomous agents; Intelligent agents; Model checking; Specification languages; Domains specific ...,,,3678719.3685692.pdf
rayyan-394626767,AutoCodeRover: Autonomous Program Improvement,2024,Atividades de Teste\tModelo GenAI\tFramework / Agente\tUtilização\tAvaliação / Maturidade\tLimitações\tNotas / Citações Localização de falhas (fault localization) validação baseada em testes suporte a depuração teste de regressão implícito via execução de suites existentes apoio indireto a program repair testing,GPT-4 (LLM comercial) modelo usado como agente de raciocínio e geração de patches,"AutoCodeRover – framework multiagente com: (i) agente de recuperação de contexto (AST-based code search), (ii) agente de geração de patch integração opcional com SBFL (Spectrum-Based Fault Localization)","Uso de LLMs para resolver issues reais do GitHub, combinando busca estruturada em AST, análise de issues em linguagem natural e execução de testes para validar patches testes existentes guiam localização de falhas e validação automática","Alta maturidade experimental ferramenta implementada, open-source, avaliada em larga escala (SWE-bench / SWE-bench-lite) métricas quantitativas (pass@1, pass@3, custo, tempo) comparada com Swe-agent e Devin",Dependência de testes existentes para melhor desempenho possibilidade de patches plausíveis mas incorretos (overfitting) dependência de modelo fechado (GPT-4) falhas quando issue não contém “hints” claros cobertura limitada quando não há suíte de testes,"“AutoCodeRover can leverage debugging techniques such as spectrum-based fault localization using tests” 19% de sucesso em SWE-bench-lite (pass@1), custo médio US$0.43; testes usados como oráculo de validação",,,,,,,1592 - 1604,"Zhang, Yuntong and Ruan, Haifeng and Fan, Zhiyu and Roychoudhury, Abhik",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203182652&doi=10.1145%2F3650212.3680384&partnerID=40&md5=310c02174e2875183e70cc48042048fa,,,,,Cited by: 27; All Open Access; Gold Open Access,10.1145/3650212.3680384,Computer debugging; Computer software maintenance; Computer software selection and evaluation; Co...,,,AutoCodeRover Autonomous Program Improvement_cga.pdf
rayyan-394626771,A New Generation of Intelligent Development Environments,2024,"Orquestração de Desenvolvimento e Testes (Development & Test Orchestration). O foco não é uma atividade isolada, mas a redefinição do papel do humano como ""Gerente"" que supervisiona agentes de IA que codificam e testam.","Conceitual (GenAI Agents em geral). O paper não se prende a um modelo específico (como GPT-4), mas assume o uso de LLMs capazes de raciocínio simbólico e geração de código.",Intelligent Development Environment (IDE 2.0). Propõe uma arquitetura onde o IDE deixa de ser um editor de texto e vira uma plataforma de comando para agentes. Integra tecnologias como Bosque Language (linguagem focada em verificação formal) e agentes autônomos.,"Programação Orientada a Intenção (Intent-Driven Programming): 1. O humano define a ""intenção"" ou especificação em alto nível. 2. Agentes de IA geram a implementação. 3. Ferramentas de Verificação Simbólica validam a correção (não apenas testes unitários, mas prova matemática de que o código faz o que a intenção pediu). 4. O IDE apresenta uma visualização estruturada (não apenas texto) para o humano aprovar.","Baixa (Proposta Visionária / Teórica). Não apresenta métricas de avaliação (F1-score, Coverage). É um paper de posição que argumenta sobre o futuro da engenharia de software baseada em IA. Baseia-se em princípios de linguagens formais e experiências prévias com ferramentas da Microsoft Research.","Determinismo: Critica a natureza não-determinística dos LLMs atuais (""alucinações""). Argumenta que para autonomia real, precisamos de Neuro-Symbolic AI (IA generativa + Verificação Lógica Rígida), pois LLMs sozinhos nunca serão confiáveis para sistemas críticos. Legado: A dificuldade de adaptar essa visão para bases de código legadas (Java/C++) que não foram desenhadas para serem facilmente analisadas por máquinas.","Autonomia vs. Confiabilidade: Esta é a citação chave para sua tese: ""We must move from probabilistic generation to provable correctness."" O autor argumenta que ""atualizações autônomas eficientes"" só serão possíveis quando o IDE puder provar que a alteração da IA não quebrou nada, sem depender apenas de rodar 1000 testes que podem ser falhos.",,,,,,,43 - 46,"Marron, Mark",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202433134&doi=10.1145%2F3643796.3648452&partnerID=40&md5=a3b21d5959d1802461780485e0036d84,,,,,Cited by: 0; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access,10.1145/3643796.3648452,Computer debugging; Intelligent agents; Software testing; AI assisted programming; Automated tool...,,,2406.09577v1.pdf
rayyan-394626774,Coverage-based Strategies for the Automated Synthesis of Test Scenarios for Conversational Agents,2024,Geração de Cenários de Teste (Conversation Flow Testing) para Chatbots Orientados a Tarefas Definição de Critérios de Cobertura,N/A (Não utiliza GenAI) Utiliza algoritmos determinísticos de travessia de grafos e combinação de parâmetros,Asymob (Ferramenta baseada em Model-Driven Engineering). Integra-se com Botium para execução Usa a linguagem neutra CONGA,"A ferramenta faz a análise estática do desenho do chatbot (intents, fluxos) e sintetiza scripts de teste para o Botium garantindo critérios de cobertura (Path coverage, Intent coverage) Propõe estratégias de redução de testes (""Factoring"", ""Single-literal"") para otimizar o tempo de execução sem perder cobertura significativa","Acadêmica (AST 2024) Avaliado em 6 agentes open-source (Dialogflow e Rasa) A estratégia exaustiva garantiu 100% de cobertura e corretude (todos os testes passaram), superando a ferramenta industrial Botium Crawler s estratégias de redução diminuíram o tempo de execução em até 96%","Dependência do Modelo: Exige acesso à especificação interna do design do bot (White-box/Grey-box), não funcionando em caixa-preta pura sem conversão prévia. Escalabilidade: A estratégia exaustiva gera milhares de casos de teste, tornando a execução lenta (>6h)","Artigo de Controle/Baseline Útil para sua revisão como contraponto: mostra como gerar testes de forma autônoma sem IA, focando em métricas de cobertura rigorosas que muitas vezes faltam em abordagens com LLMs ""Test suite reduction is one of the open challenges... we propose strategies... oriented to test case reduction""",,,,,,,23 - 33,"Cañizares, Pablo C. and Ávila, Daniel and Perez-Soler, Sara and Guerra, Esther and Lara, Juan De",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196398493&doi=10.1145%2F3644032.3644456&partnerID=40&md5=1a07cb9731740db2bace5b78bda5d552,,,,,Cited by: 5; All Open Access; Gold Open Access,10.1145/3644032.3644456,Open source software; Software agents; Software testing; Automated synthesis; Chatbots; Conversat...,,,3644032.3644456.pdf
rayyan-394626779,Unit Test Generation Multi-Agent AI System for Enhancing Software Documentation and Code Coverage,2024,Geração de Testes Unitários e Geração de Documentação (User Stories). A abordagem conecta a documentação de requisitos (BDD) diretamente à criação do teste para garantir cobertura funcional.,"ChatGPT-4o-mini (OpenAI) O estudo escolheu explicitamente este modelo ""mini"" com temperatura zero para maximizar a eficiência de custo e determinismo.","AutoGen (Microsoft). Arquitetura ""Triple-Agent"" composta por: 1. User Story Writer Agent: Cria cenários Gherkin. 2. Unit Test Writer Agent: Escreve o código de teste (Python unittest) baseado nas stories. 3. Code Executor Agent: Roda os testes num ambiente seguro e fornece o traceback de erro como feedback","Fluxo BDD com Feedback Loop: Diferente de gerar o teste direto do código (""Code-to-Test""), o sistema faz: Code -> User Story (BDD) -> Unit Test. A inclusão da etapa intermediária de User Stories obriga o modelo a ""explicar"" o comportamento antes de testar, ajudando a identificar edge cases (casos de borda). Se o teste falha na execução, o Unit Test Agent recebe o erro e corrige o código autonomamente.",Maturidade Acadêmica (Experimento em Dataset Padrão). Cenário: 100 problemas do dataset MBPP (Mostly Basic Python Problems) que tinham baixa cobertura. Resultados: A Cobertura de Ramos (Branch Coverage) média subiu de 67% para 83%. A taxa de sucesso (Pass Rate) dos testes gerados foi de 85% .,"Eficiência: Custo total de menos de $0.20 USD para gerar testes para 100 programas, executando em menos de 5 minutos. Confiabilidade (Pass Rate < 100%): 15% dos testes falharam ou geraram erros (incluindo um caso de loop infinito). Complexidade do Dataset: O MBPP contém problemas simples/algorítmicos. O artigo não avaliou o desempenho em sistemas corporativos complexos com dependências externas. Ausência de Humano: A falta de supervisão humana impediu a correção de erros sutis onde o modelo ""confundiu funções built-in""","Eficiência vs. Custo: Este artigo é a melhor evidência para sua tese de que ""Eficiência"" não exige supercomputadores. Com uma arquitetura inteligente (Agentes + BDD), modelos low-cost superam a geração de testes simples. Autonomia de Correção: O feedback loop autônomo corrigiu a maioria dos erros sintáticos sem intervenção humana, demonstrando Self-Healing em tempo de desenvolvimento.",,,,,,,,"Stojanovic, Dimitrije and Pavković, Bogdan and Četić, Nenad B. and Krunić, Momčilo V. and Vidakovic, Luka",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216854650&doi=10.1109%2FTELFOR63250.2024.10819096&partnerID=40&md5=590d88c939c87c1b052534a891819d4c,,,,,Cited by: 1,10.1109/TELFOR63250.2024.10819096,Distribution transformers; Electric transformer testing; Model checking; Problem oriented languag...,,,Unit_Test_Generation_Multi-Agent_AI_System_for_Enhancing_Software_Documentation_and_Code_Coverage.pdf
rayyan-394626782,Automated test generation to evaluate tool-augmented LLMs as conversational AI agents,2024,Pipeline de geração de testes Geração de cenários usando gráficos intermediários Estudo de ablação Teste funcional usando conjunto de dados ALMITA Benchmarking,GPT-4 GPT4-o Claude3-sonnet Mistral-NeMo-Instruct Llama3.1-8b-Instruct,"O artigo propõe uma estrutura para gerar conjuntos de dados de avaliação para LLMs aumentados por ferramentas como agentes de IA conversacionais, usando estruturas gráficas intermediárias para melhorar a qualidade e a abrangência dos testes. Ele não especifica uma estrutura de software ou arquitetura de agente específica como LangChain, LangGraph ou AutoGen.",Customer Support,"Método de avaliação: Benchmarking de vários LLMs no conjunto de dados ALMITA, avaliando o desempenho em cenários de suporte ao cliente. Dimensões avaliadas: Recuperação de resposta, resposta correta, recuperação de API, API correta, parâmetros de API corretos, correção de teste e correção de conversação. Principais descobertas: Os LLMs têm bom desempenho em interações individuais, mas têm dificuldades com conversas completas. Limitação destacada: Os LLMs atuais têm dificuldade em manter conversas corretas durante as interações do usuário.",Falta de avaliação quantitativa da diversidade de testes. Número limitado de anotações humanas. Uso de um único LLM (GPT-4) para geração de testes. Avaliação de vários LLMs usando um único prompt. As métricas podem ser muito rígidas. Necessidade de métricas conversacionais mais avançadas para lidar com variações de resposta.,"O estudo apresenta um novo método para gerar conjuntos de dados de avaliação para LLMs aumentados por ferramentas como agentes de IA conversacional, destacando que, embora esses modelos tenham bom desempenho em interações únicas, eles têm dificuldade em lidar com conversas completas.",,,,,,,54 - 68,"Arcadinho, Samuel and Aparício, David and Almeida, Mariana S.C.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216591803&partnerID=40&md5=eeb0044155d867548dffcb3f87a276bb,,,,,Cited by: 0,,Automatic test pattern generation; Computational linguistics; Am generals; Automated test generat...,,,Automated test generation to evaluate tool-augmented LLMs as conversational AI agents_ZLU.pdf
rayyan-394626784,RGD: Multi-LLM Based Agent Debugger via Refinement and Generation Guidance,2024,Geração e Depuração de Código (Code Generation & Debugging) Refinamento Iterativo de Código Análise de Falhas (Failure Analysis),GPT-4o GPT-4o-mini,"RGD (Refinement and Guidance Debugging) Arquitetura Multi-Agente com 3 papéis: Guide Agent, Debug Agent, Feedback Agent","Utiliza um Guide Agent que gera um ""plano"" (guia) antes de codificar e recupera guias de tarefas similares de um Memory Pool (RAG) O Feedback Agent analisa não apenas o erro, mas também por que os testes passaram, para evitar regressão O Debug Agent corrige o código com base nessas instruções","Alta (arXiv 2024) Avaliado em benchmarks padrão: HumanEval, MBPP e suas versões estendidas (ET) O RGD (com GPT-4o) atingiu 97.6% de acurácia (Pass@1) no HumanEval, superando o estado da arte (LDB) e métodos de Self-Debugging (+9.8% vs Baseline) A ablação mostrou que remover o Guide Agent reduz a acurácia em 4-6%.",Custo Computacional: A arquitetura multi-agente com RAG e iterações de feedback consome muitos tokens e tempo Dependência de Casos de Teste: A eficácia depende da qualidade dos testes visíveis fornecidos no prompt.,"""RGD decompõe a tarefa de geração de código... permitindo refinamento iterativo baseado em autorreflexão e feedback."". Destaque para o uso de Memory Pool para armazenar ""guias de sucesso"" passados, aprendendo com a experiência.",,,,,,,136 - 141,"Jin, Haolin and Sun, Zechao and Chen, Huaming",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215607472&doi=10.1109%2FICA63002.2024.00037&partnerID=40&md5=bad4ee6cce20c207147b12cb02bf5210,,,,,Cited by: 0,10.1109/ICA63002.2024.00037,Automatic programming; Autonomous agents; Behavioral research; Computer debugging; Error correcti...,,,RGD_MultiLLM_Based_Agent_Debugger_via.pdf
rayyan-394626785,Test-Agent: A Multimodal App Automation Testing Framework Based on the Large Language Model,2024,"Mobile App Automation Testing (Android, iOS, HarmonyOS) Teste de GUI Geração e Execução de Casos de Teste a partir de Linguagem Natural","LLM não especificado (referido genericamente como ""Large Language Model"" e ""ChatGPT"" nos diagramas) Integra modelos de Deep Learning (DQN) e Computer Vision","Test-Agent (Framework Multimodal) Módulos: Visual Perception, Interaction Analysis, Test Execution Usa ADB para execução","O framework elimina scripts pré-escritos. O usuário fornece uma instrução em linguagem natural (ex: ""fazer login""). O agente captura a tela (screenshot), usa Visão Computacional (OCR/Detecção de Borda) para identificar elementos, e o LLM/Agente planeja a ação (clique/input) Utiliza Reinforcement Learning (DQN) para otimizar a sequência de ações.","PoC Acadêmica (IEEE DTPI 2024) Avaliado em 7 dispositivos reais (Pixel, iPhone, Huawei) e simuladores Comparado com Appium, Espresso e XCUITest Reduziu o tempo de criação de testes de ~3 horas (Appium) para 0.1 hora Atingiu taxa de sucesso de 96-97% em tarefas como login e compras.","Dependência de Latência: O processamento visual + inferência do LLM em cada passo pode ser mais lento que scripts nativos (embora o artigo foque na eficiência de criação) Generalização: Avaliado em apps padrão (e-commerce, social); apps com UI não-padrão (jogos) podem ser desafiadores.","""Essa abordagem inovadora elimina a necessidade de scripts de teste pré-escritos... dependendo apenas de screenshots... reduzindo significativamente a carga de trabalho de escrita de casos de teste."" Destaque para a abordagem Multimodal (Visão + Texto)",,,,,,,609 - 614,"Li, Youwei and Li, Yangyang and Yang, Yangzhao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214923908&doi=10.1109%2FDTPI61353.2024.10778901&partnerID=40&md5=2df3aabdcab54e9e039471ef43a47e60,,,,,Cited by: 2,10.1109/DTPI61353.2024.10778901,Application programs; Computer debugging; Computer operating systems; Mobile agents; Model checki...,,,Test_Agent_A_Multimodal_App_Automation_Testing_Framework_Based_on_the_Large_Language_Model.pdf
rayyan-394626787,Fight Fire With Fire: How Much Can We Trust ChatGPT on Source Code-Related Tasks?,2024,"Autoverificação de Código (Self-Verification), Geração de Relatórios de Teste e Validação de Segurança. O estudo avalia se a IA consegue atuar como ""Developer"" e ""Tester"" simultaneamente para verificar Geração de Código, Completude de Código e Reparação de Bugs.",GPT-3.5-turbo (Experimentos principais) e GPT-4 (Validação em menor escala). Acesso via API da OpenAI.,"Simulação de Colaboração Multi-Agente (Conceitual). Testou três estratégias de prompting para simular o ""Agente Testador"": 1. Direct Question (DQ): Pergunta direta (""Este código está correto?""). 2. Guiding Question (GQ): Pergunta indutiva (""Você concorda que há um erro X?""). 3. Test Report (TR): Solicita a geração de um relatório de testes completo.","Ciclo de Auto-Crítica (Self-Correction Loop): O modelo gera o código (papel Developer) e depois é alimentado com o próprio código para verificar erros ou vulnerabilidades (papel Tester). O estudo investiga se ""combater fogo com fogo"" (usar IA para testar IA) funciona na prática.","Estudo Empírico Rigoroso (Datasets: HumanEval, MBXP, QuixBugs). - Falha na Autonomia: O ChatGPT falhou em identificar seus próprios erros em 39% dos casos de geração de código e 28% dos reparos. - Test Reports: O uso de Test Reports ajudou a identificar 77% mais vulnerabilidades de segurança, mas as explicações textuais sobre por que o código estava errado foram imprecisas em 75% dos casos.","Alucinações Autocontraditórias: O modelo frequentemente sofre de inconsistência lógica (ex: gera um código dizendo que é seguro, mas no passo de verificação diz que é vulnerável, ou vice-versa). Sycophancy (Viés de Concordância): Na estratégia Guiding Question, o modelo tende a concordar com o humano (ou prompt) de que existe um erro, mesmo que o código esteja correto (aumentando Falsos Positivos).","Golpe na Autonomia Total: O artigo conclui taxativamente que ""O ChatGPT deve ser visto como uma ferramenta de assistência, e não um substituto para desenvolvedores e testadores autônomos"". Imprecisão do Oráculo: Para sua tese, isso prova que Agentes de Teste Puramente LLM (sem execução de código real/sandbox) não são confiáveis como oráculos, pois a IA não consegue distinguir confiavelmente entre um bug real e uma alucinação.",,,IEEE Transactions on Software Engineering,,50,12,3435 - 3453,"Yu, Xiao and Liu, Lei and Hu, Xing and Keung, Jacky Wai and Liu, Jin and Xia, Xin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208721822&doi=10.1109%2FTSE.2024.3492204&partnerID=40&md5=11df2cbefd5bdd1d5eed10afaaccef29,,,,,Cited by: 2,10.1109/TSE.2024.3492204,C (programming language); Chatbots; Computer debugging; Computer software maintenance; Computer s...,,,Fight_Fire_With_Fire_How_Much_Can_We_Trust_ChatGPT_on_Source_CodeRelated_Tasks.pdf
rayyan-394626789,Extending the Frontier of ChatGPT: Code Generation and Debugging,2024,"Geração de Código (Soluções) e Depuração Automatizada (Automated Debugging/Repair). O estudo avalia a capacidade da IA de passar em ""testes de aceitação"" (casos de teste do LeetCode) e de corrigir o código quando falha.","ChatGPT (O artigo menciona que o ChatGPT é ""powered by GPT-4"" na introdução, mas os experimentos refletem o uso da interface conversacional disponível em Maio de 2023).","Prompting Direto Interativo. Não utilizou frameworks de agentes (como LangChain). O método foi: Prompt com o problema -> Geração -> Teste no LeetCode -> Se falhar, novo Prompt com a mensagem de erro (Feedback Loop Simples).","Ciclo de Feedback Humano-Máquina: 1. Geração: O problema (descrição + estrutura de código) é enviado ao chat. 2. Validação: O código é submetido ao LeetCode. 3. Depuração: Se ocorrer erro (Runtime Error, Time Limit Exceeded, ou falha lógica), a mensagem de erro do compilador é colada de volta no chat para pedir uma correção.","Estudo Acadêmico Empírico. Cenário: 128 problemas do LeetCode (Fácil, Médio, Difícil) cobrindo Árvores, Grafos, DP, etc. - Taxa de Sucesso Inicial: 71.9% dos problemas foram resolvidos corretamente de primeira. - Taxa de Sucesso na Depuração: Apenas 36.7% dos problemas que falharam inicialmente foram corrigidos após o feedback de erro","Falha na Auto-Correção: O modelo mostrou ""adaptabilidade limitada"" ao feedback. Muitas vezes, mesmo recebendo o erro, não conseguia consertar a lógica Dificuldade com Complexidade: Desempenho pior em problemas de Programação Dinâmica e Algoritmos Gulosos (Greedy), onde o raciocínio de múltiplos passos é necessário. Data de Corte: O conhecimento do modelo era limitado a dados pré-2021 (na época do estudo).","Evolução da Autonomia: Este paper é a evidência perfeita de que Prompting simples não é suficiente para manutenção autônoma. O fato de ele corrigir apenas 36% dos erros mostra a necessidade das arquiteturas de Agentes (vistas nos seus outros artigos) que usam ferramentas externas e RAG para melhorar essa taxa. Eficiência: O estudo analisou também tempo de execução e memória, notando que a IA às vezes gera soluções funcionalmente corretas, mas ineficientes (O(n²) vs O(n)).",,,,,,,,"Sakib, Fardin Ahsan and Khan, Saadat Hasan and Karim, A. H.M.Rezaul",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207460221&doi=10.1109%2FICECET61485.2024.10698405&partnerID=40&md5=9061172122ad4b9fa410d2c10d273c63,,,,,Cited by: 8,10.1109/ICECET61485.2024.10698405,Acceptance tests; Computer debugging; Program debugging; Structured programming; ChatGPT; Code de...,,,Extending the Frontier of ChatGPT_ Code Generation and Debugging.pdf
rayyan-394626790,"PENTEST-AI, an LLM-Powered Multi-Agents Framework for Penetration Testing Automation Leveraging Mitre Attack",2024,"Automação de Testes de Penetração (Pentesting) cobrindo as fases de Pré-exploração (Reconhecimento, Desenvolvimento de Recursos) Exploração (Validação de Vulnerabilidades, Simulação de Exploit), Pós-exploração e Geração de Relatórios","GPT-4.0 (utilizado na Prova de Conceito). O framework teórico propõe o uso de modelos especializados/finetuned (ex: SecurityBERT, CyBERT, Falcon LLM) através de um ""LLM Registry""","PENTESTAI (Framework proposto) implementado utilizando CrewAI (que se baseia no LangChain) Arquitetura Multi-Agente composta por agentes trabalhadores (Scan & Search, Exploit Validation, Exploit Simulation, Post-Exploitation, Reporting, Detection) e agentes de controle (Configuration, Saga Controller, Zookeeper)","Implementação de agentes autônomos que utilizam ferramentas customizadas em Python (ex: ScanAndSearchTool, ExploitValidationTool baseadas em Nmap) para executar ações A orquestração é feita via CrewAI, onde agentes recebem instruções em linguagem natural para analisar arquivos JSON e gerar relatórios O ambiente de teste foi implantado na AWS (EC2) contra alvos públicos.","Prova de Conceito (PoC) oi implementado um fluxo simplificado com 3 agentes (Scan, Validation, Reporting) que validou os conceitos centrais e a capacidade do GPT-4.0 em gerar recomendações de segurança corretas sem ferramentas de relatório customizadas","Alucinações: O GPT-4.0 gerou alucinações em alguns resultados durante os testes Cobertura de Ferramentas: Necessidade de desenvolver bibliotecas para cobrir as cerca de 405 técnicas do MITRE ATT&CK Zero-day: O framework atual não descobre vulnerabilidades zero-day (exigiria um agente de Engenharia Reversa) Implementação Parcial: O ""Plano de Controle"" (Control Plane) descrito na arquitetura não foi implementado na PoC.","O artigo propõe um nível de autonomia de ""User-Guided Adaptation"" (Adaptação Guiada pelo Usuário) para garantir alinhamento com objetivos humanos A abordagem visa mitigar a escassez de profissionais qualificados em cibersegurança, habilitando ""citizen penetration testers""",,,,,,,763 - 770,"Bianou, Stanislas G. and Batogna, Rodrigue G.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206186144&doi=10.1109%2FCSR61664.2024.10679480&partnerID=40&md5=31791a7ca25673d064f6b1d90e42bb04,,,,,Cited by: 10,10.1109/CSR61664.2024.10679480,Model checking; Multi agent systems; AI agent; Citizen penetration tester; Cyber security; Langua...,,,PENTEST-AI_an_LLM-Powered_Multi-Agents_Framework_for_Penetration_Testing_Automation_Leveraging_Mitre_Attack.pdf
rayyan-394626795,CODEAGENT: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges,2024,"Geração e Verificação de Código a Nível de Repositório (Repo-level Code Generation & Verification) O framework integra ""Code Testing"" como uma etapa fundamental, onde o agente gera casos de teste e utiliza um Code Interpreter para executar o código e validar a correção funcional (Self-debugging baseada em feedback de execução). Inclui também verificação de formato (linting)",GPT-4 GPT-3.5-Turbo Claude-2 Llama 2 (70B) Code Llama (34B) WizardCoder DeepSeekCoder Vicuna-13B O foco principal do agente foi com modelos da família GPT.,CODEAGENT. Um framework de agente baseado em LLM que integra 5 ferramentas externas. A implementação utiliza a biblioteca LangChain,"O agente emprega estratégias de planeamento e execução (ReAct, Tool-Planning, OpenAIFunc e Rule-based) para orquestrar o uso de ferramentas Information Retrieval: WebSearch (DuckDuckGo) e DocSearch (BM25) Implementation: SymbolSearch (Navegação de código via Tree-sitter). Code Testing: FormatCheck (Black) e PythonREPL (Interpretador para execução e teste).","Experimento/Benchmark Próprio Os autores criaram o CODEAGENTBENCH (101 tarefas extraídas de 5 repositórios Python reais: numpy-ml, tinydb, etc.) Utilizaram a métrica Pass@1. Resultados: O CODEAGENT melhorou o Pass@1 entre 2.0% e 15.8% em comparação com LLMs sem agentes. Comparação: Superou o GitHub Copilot em precisão nos testes realizados","Capacidade do Modelo: Modelos menores ou menos capazes (como Vicuna-13B) não conseguiram aproveitar as ferramentas, apresentando desempenho fraco mesmo com o framework. Estratégia de Planeamento: A estratégia ""Tool-Planning"" (planejar antes de executar) mostrou-se menos eficaz do que abordagens mais diretas como Rule-based ou ReAct para este tipo de tarefa As avaliações foram limitadas pelos recursos computacionais disponíveis.","""To the best of our knowledge, CODEAGENT is the first agent framework specifically for repo-level code generation."". O estudo destaca que mais de 70% das funções em projetos open-source não são ""autónomas"" (standalone), justificando a necessidade de agentes que compreendam o contexto do repositório inteiro, algo que ferramentas anteriores falhavam em fazer",,,Proceedings of the Annual Meeting of the Association for Computational Linguistics,,1,,13643 - 13658,"Zhang, Kechi and Li, Jia and LI, Ge and Shi, Xianjie and Jin, Zhi",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204422336&doi=10.18653%2Fv1%2F2024.acl-long.737&partnerID=40&md5=99fd7c9dd58ad15390110ca57961ce7c,,,,,Cited by: 3,10.18653/v1/2024.acl-long.737,Autonomous agents; Benchmarking; Computational linguistics; Intelligent agents; Search engines; S...,,,CODEAGENT Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges_aeu.pdf
rayyan-394626796,Towards LLM-Assisted System Testing for Microservices,2024,"Teste de Sistema End-to-End (Black-box System Testing) para aplicações baseadas em Microsserviços. O foco é validar funcionalidades completas (ex: ""adicionar item ao carrinho"") através da interação com a interface web, sem acesso ao backend.","GPT-4 (Melhor desempenho) e GPT-3.5-turbo. Também testaram CodeLlama, mas este falhou sistematicamente devido a recusas éticas (o modelo interpretou os comandos de teste como ataques/hacking).",Kashef (Ferramenta baseada em Agentes Comunicativos). Arquitetura Multi-Agente com papéis definidos: 1. Test Engineer (TE): Gera o código de automação (Python/Selenium). 2. Code Executor (CE): Executa o código num ambiente sandbox. 3. HTML Interpreter (HI): Analisa o HTML retornado para verificar se o estado da página mudou conforme esperado (verificação de oráculo).,"Colaboração e Auto-Correção: 1. O usuário dá um prompt de tarefa (ex: ""Teste o checkout no site X""). 2. O TE gera o script. 3. O CE executa. Se falhar (ex: erro de seletor CSS), o erro retorna ao TE para re-geração (Loop de Feedback). 4. Se rodar, o HI analisa o resultado visual/HTML para confirmar o sucesso do teste de negócio.","Maturidade Acadêmica (Trabalho em Progresso/Short Paper). Cenario: 4 aplicações web (incluindo E-commerce e Pastebin). - GPT-4: Taxa de sucesso de 100% em tarefas simples, mas caiu para 30% em fluxos complexos de e-commerce. - GPT-3.5: Falhou em quase todas as tarefas complexas (0% de sucesso no e-commerce), incapaz de lidar com contextos longos de HTML","Recusas Éticas (Safety Filters): O CodeLlama recusou-se a gerar scripts de teste, classificando-os como ""atividades maliciosas"", o que é uma barreira real para uso de modelos open-source em testes de segurança/penetração. Janela de Contexto: O GPT-3.5 perdeu-se ao tentar processar o HTML completo da página para verificação. Estabilidade: Mesmo com GPT-4, a ferramenta exigiu múltiplas regenerações de código para acertar seletores dinâmicos.","Desafio da Avaliação: O artigo destaca a dificuldade de criar um ""Oráculo"" confiável em testes de sistema. A inovação do Kashef foi usar um agente dedicado (HTML Interpreter) apenas para ler a tela e dizer se o teste passou, em vez de depender apenas de asserções de código. Arquitetura de Microsserviços: Ressalta que, em microsserviços, testes unitários não bastam; a complexidade está na integração, e agentes autônomos são promissores para cobrir essa lacuna de testes E2E que hoje é feita manualmente.",,,,,,,29 - 34,"Almutawa, Mustafa and Ghabrah, Qusai and Canini, Marco",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204295455&doi=10.1109%2FICDCSW63686.2024.00011&partnerID=40&md5=c288614757b12066e8a8ed4ab7ec145e,,,,,Cited by: 2,10.1109/ICDCSW63686.2024.00011,Ability testing; Autonomous agents; Black-box testing; Computer debugging; Computer software sele...,,,Towards_LLMAssisted_System_Testing_for_Microservices.pdf
rayyan-394626798,Intent-Driven Mobile GUI Testing with Autonomous Large Language Model Agents,2024,"Teste de GUI Móvel (Android) com foco em ""Intent-Driven Testing"" (Teste Orientado a Intenção). O sistema gera e executa autonomamente cenários de teste de alto nível (ex: ""criar uma segunda conta e adicionar a primeira como amigo"") em vez de apenas explorar telas aleatoriamente.",GPT-3.5 (utilizado principalmente pelo agente Actor para seleção de ações) GPT-4 (utilizado para o mecanismo de Self-critique e tarefas de planeamento mais complexas),"DROIDAGENT. Uma arquitetura de agente autônomo composta por quatro módulos principais: Planner (planeador de tarefas), Actor (executor de ações), Observer (observador de estado) e Reflector (reflexão e memória). Implementado utilizando LangChain e ChromaDB (para base de dados vetorial de memória).","O framework opera através de uma colaboração multi-agente: Planner: Define metas de teste em linguagem natural baseadas no histórico e numa ""Persona"" (ex: usuário ""Jade Green"") Memória: Utiliza três tipos: Curta (contexto imediato), Longa (histórico de tarefas e reflexões) e Espacial (conhecimento sobre widgets específicos) Execução: O agente Actor utiliza function calling para interagir com o app (via ADB), suportando ações como ""touch"", ""set_text"", ""wait"" e ""back"" eedback: Inclui um loop de Self-critique onde o GPT-4 analisa se o agente está ""preso"" e sugere planos de contorno","Experimento Comparativo Avaliado em 15 aplicações Android (do benchmark Themis e F-Droid). Comparação: DroidBot, Humanoid, Monkey e GPTDroid. Resultados: DROIDAGENT alcançou 61% de cobertura de atividade (superando os 51% do estado da arte). Gerou 374 tarefas únicas, das quais 85% foram consideradas relevantes e 59% foram concluídas com sucesso.","Representação Visual: O agente baseia-se numa representação textual (JSON) da hierarquia de widgets, o que pode perder nuances puramente visuais da interface (embora seja melhor que abordagens anteriores baseadas apenas em texto plano). Custo e Latência: O uso de múltiplos agentes e chamadas frequentes a modelos como GPT-4 implica custos operacionais e tempo de execução mais elevados (avaliado na RQ4 do estudo). Dependência de APIs: A exclusão de algumas apps do benchmark original deveu-se a servidores depreciados, indicando a fragilidade de testar apps dependentes de backend vivo","""To the best of our knowledge, DROIDAGENT is the first Android GUI testing technique that can automatically generate high level testing scenarios based on sequences of identified tasks."" O estudo motiva-se no fato de que desenvolvedores preferem testes que cobrem funcionalidades específicas (""usage model"") em vez de métricas de cobertura estrutural cega",,,,,,,129 - 139,"Yoon, Juyeon and Feldt, Robert and Yoo, Shin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203242246&doi=10.1109%2FICST60714.2024.00020&partnerID=40&md5=da75e662900ea316debff970ce334a1b,,,,,Cited by: 14,10.1109/ICST60714.2024.00020,Autonomous agents; Benchmarking; Graphical user interfaces; High level languages; Mobile agents; ...,,,Intent-Driven Mobile GUI Testing with Autonomous Large Language Model Agents.pdf
rayyan-394626800,A Generative Adversarial Imitation Learning Method for Continuous Integration Testing,2024,Priorização de Casos de Teste (TCP) em ambientes de Integração Contínua (CI) O foco é ordenar os testes para detetar falhas o mais cedo possível,"GAN (Generative Adversarial Networks) utilizada dentro de uma abordagem GAIL (Generative Adversarial Imitation Learning). ""Gerador"" utiliza o algoritmo de Reinforcement Learning PPO (Proximal Policy Optimization) Este artigo utiliza GenAI no sentido de redes adversárias para aprendizagem por imitação, diferindo dos LLMs (Large Language Models) focados em texto presentes nos outros artigos","GAIL-based TCP. O sistema atua como um agente que aprende uma política de ordenação (Gerador) tentando enganar um discriminador que distingue entre a ordenação do agente e a ""experiência especialista""","Aprendizagem por Imitação: Ao contrário do Reinforcement Learning tradicional, o agente não depende de uma função de recompensa manual (difícil de desenhar e propensa a sparsity); ele aprende diretamente de ""experiência especialista"" derivada de ordenações ótimas de ciclos de CI anteriores. Estratégia de Ranking: Utiliza o Método de Copeland para pairwise ranking (comparação par a par de testes) para determinar a ordem final. * Features: O modelo recebe tuplos contendo veredito de execução, tempo, histórico e contagem de ciclos.","Datasets: Avaliado em 6 datasets industriais (Apache Drill, IOF/ROL, Paint Control, Compress, IO, Math). Métricas: APFD (Average Percentage of Faults Detected) e uma nova métrica proposta APFDET (baseada em tempo de execução). Resultados: Superou métodos baseados em RL tradicional em 5 dos 6 datasets em termos de capacidade de deteção de falhas",Custo Computacional: O tempo de treino e priorização é superior ao de métodos RL tradicionais (embora a diferença seja de apenas alguns segundos) Sensibilidade aos Dados: O desempenho varia conforme o dataset (ex: no projeto IOF/ROL a melhoria foi menos significativa). Hiperparâmetros: Necessidade de ajustar hiperparâmetros dos algoritmos de RL/GAN.,"""Designing a proper reward function is challenging... GAIL allows agents to learn directly from the expert experience rather than through potentially biased reward functions."". O artigo ataca o problema de ""sparse rewards"" comum em testes industriais onde a taxa de falha é muito baixa (ex: 0.01%)",,,,,,,1084 - 1089,"Huang, Luosen and Liu, Hengyuan and Liu, Yong and Shang, Ying and Li, Zheng",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199171129&doi=10.1109%2FAINIT61980.2024.10581812&partnerID=40&md5=8c4501d6057031be3cb889fffcbf208b,,,,,Cited by: 2,10.1109/AINIT61980.2024.10581812,Efficiency; Failure analysis; Integration; Integration testing; Learning systems; Reinforcement l...,,,A_Generative_Adversarial_Imitation_Learning_Method_for_Continuous_Integration_Testing_tVU.pdf
rayyan-394626802,ChatDev: Communicative Agents for Software Development,2024,"Revisão de código (teste estático) Teste de sistema (teste dinâmico) Resolução de erros: ModuleNotFound, NameError, ImportError Mecanismo de desalucinação comunicativa para resolver alucinações de codificação",ChatGPT-3.5,ChatDev,"Desenvolvimento de software, integrando especificamente múltiplas fases do ciclo de vida de desenvolvimento de software através da comunicação cooperativa entre diferentes funções.","Métricas de avaliação: Completude, Executabilidade, Consistência, Qualidade Comparação de desempenho: ChatDev supera GPT-Engineer e MetaGPT Avaliação humana: ChatDev preferido a outros métodos Estratégia de avaliação: Dividir o desenvolvimento de software em subtarefas menores e avaliar a qualidade com base em métricas","As capacidades dos agentes autônomos na produção de software podem ser superestimadas, pois eles geralmente implementam lógica simples e enfrentam requisitos pouco claros. Automatizar a avaliação de software de uso geral é altamente complexo e impraticável para grandes conjuntos de dados. Vários agentes exigem mais tokens e tempo, aumentando as demandas computacionais e o impacto ambiental. Pesquisas futuras devem considerar fatores adicionais, como funcionalidades, robustez, segurança e facilidade de uso. Pesquisas futuras devem ter como objetivo aprimorar as capacidades dos agentes com menos interações.","O estudo apresenta o ChatDev, uma estrutura de desenvolvimento de software alimentada por bate-papo que usa comunicação linguística para integrar fases fragmentadas do modelo em cascata, demonstrando melhor qualidade de software por meio de comunicações multi-turno entre agentes LLM.",,,Proceedings of the Annual Meeting of the Association for Computational Linguistics,,1,,15174 - 15186,"Qian, Chen and Liu, Wei and Liu, Hongzhang and Chen, Nuo and Dang, Yufan and Li, Jiahao and Yang, Cheng and Chen, Weize and Su, Yusheng and Cong, Xin and Xu, Juyuan and Li, Dahai and Liu, Zhiyuan and Sun, Maosong",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197091676&doi=10.18653%2Fv1%2F2024.acl-long.810&partnerID=40&md5=c71c0c92f0115ee34a983a62e5d9a761,,,,,Cited by: 75,10.18653/v1/2024.acl-long.810,Autonomous agents; Computational linguistics; Computer debugging; Program debugging; Software des...,,,ChatDev Communicative Agents for Software Development_Xyw.pdf
rayyan-394626805,Cloud-Based System for Source Code Analysis of Microservices with LLM Agents,2024,"Análise Estática de Código focada em microsserviços. Inclui atividades específicas de: Revisão de Código: Identificação de bugs e áreas de melhoria. Verificação de Confiabilidade: Análise de tolerância a falhas, resiliência e tratamento de erros. Verificação de Confiabilidade: Análise de tolerância a falhas, resiliência e tratamento de erros. Avaliação de Design de Sistema: Verificação de padrões de arquitetura, modularidade e escalabilidade.",GPT-4o (referido como GPT-4.0/4o no texto) utilizado para inferência. Também utiliza modelos de embedding da OpenAI,Arquitetura de Nuvem Própria com 5 Agentes Especializados: 1. Code Summarizer Agent 2. Code Reviewer Agent 3. Reliability Reviewer Agent 4. Code Search Agent 5. System Design Agent Utiliza Neo4j (Graph Database) para armazenar relações de código e MongoDB Atlas para busca vetorial,"O sistema opera numa arquitetura orientada a eventos (Event-driven), integrada ao fluxo de CI/CD (acionada via Git Push Webhooks) Utiliza RAG (Retrieval-Augmented Generation) combinando base vetorial e base em grafo para dar contexto aos agentes. Os agentes analisam módulos (arquivos) individuais e as suas relações, gerando relatórios acessíveis via Web UI.","Prova de Conceito (PoC) / Protótipo Validado através de testes simulados localmente (Apple M1) e implantado na nuvem (Microsoft Azure). Estudo de caso realizado com um microsserviço Node.js desenvolvido pelo utilizador (""Microservice 1"") Métricas focaram em escalabilidade, latência e usabilidade","Validação Humana: Os resultados ainda requerem verificação manual por um desenvolvedor para validar a correção e integrar as sugestões. Custo e Performance: O artigo nota que a escolha do modelo LLM impacta diretamente a qualidade, velocidade de inferência e custos operacionais. Dependência de Contexto: Embora melhor que a análise estática tradicional, depende da qualidade dos dados indexados no grafo/vetor para evitar falsos positivos.","""The combination of LLM agents and cloud technologies offers scalability that sets the stage for future innovations in automated code analysis."" O sistema propõe resolver a complexidade da análise de microsserviços distribuídos, onde ferramentas tradicionais falham por falta de contexto do sistema completo",,,International Scientific and Technical Conference on Computer Sciences and Information Technologies,,,,,"Chaplia, Oleh and Klym, Halyna I.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005826698&doi=10.1109%2FCSIT65290.2024.10982613&partnerID=40&md5=aa79d5bead960eeab495f82530874986,,,,,Cited by: 0,10.1109/CSIT65290.2024.10982613,Computer operating systems; Computer software maintenance; Software design; Software prototyping;...,,,Cloud-Based_System_for_Source_Code_Analysis_of_Microservices_with_LLM_Agents.pdf
rayyan-394626808,AI-Powered Multi-Agent Framework for Automated Unit Test Case Generation: Enhancing Software Quality through LLM's,2024,"Geração de Testes Unitários (Java) e Refinamento de Código. O sistema não apenas gera os testes, mas também reescreve o código-fonte original se encontrar falhas (ex: falta de tratamento de exceção para divisão por zero).",Mistral-Large. O artigo cita explicitamente o uso deste modelo para a avaliação e geração nos experimentos.,"LangGraph (Implicitamente descrito como fluxo de grafo). Arquitetura ""Dual-Agent"" cíclica: 1. Reviewer Agent: Analisa o código Java em busca de falhas lógicas, violações de normas e casos de borda ausentes. 2. Coder Agent: Reescreve o código e gera os testes baseados no feedback do Reviewer. 3. Decision Making Agent: Valida se o código final atende aos critérios de qualidade.","Fluxo de Revisão por Pares Simulado (Simulated Peer Review): O processo imita dois engenheiros humanos trabalhando juntos. O Reviewer critica (""Você esqueceu o teste negativo para a soma"") e o Coder conserta. Diferencial: O sistema opera em loop até que o Reviewer esteja satisfeito, garantindo que o código final seja robusto.","Prova de Conceito (Proof of Concept). Cenário: Classes Java isoladas (ex: Sample1.java com operações matemáticas). Resultados: Atingiu 100% de cobertura de código nos exemplos testados, demonstrando capacidade de tratar edge cases (como números negativos e exceções) que frameworks tradicionais costumam perder.","Escopo Limitado: A avaliação foi feita em códigos de exemplo simples (""Toy examples""), não em sistemas legados complexos. Custo do Loop: O processo iterativo (Reviewer <-> Coder) consome mais tokens e tempo do que uma geração direta (Zero-shot).","Autonomia de ""Self-Healing"": Este artigo é crucial para o seu tema de ""Autonomous Updates"". Ele mostra que a eficiência vem de remover o humano do loop de revisão inicial, deixando que agentes especializados debatam entre si para limpar erros óbvios antes da validação final.",,,,,,,,"Garlapati, Anusha and Parmesh, M. N.V.Satya Sai Muni and Savitha, null and Jaisri, S.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002210499&doi=10.1109%2FGCAT62922.2024.10923987&partnerID=40&md5=5ab5972bdb1effde4abdc467aec1d3bb,,,,,Cited by: 0,10.1109/GCAT62922.2024.10923987,Application programs; Automatic test pattern generation; Computer software selection and evaluati...,,,AI-Powered_Multi-Agent_Framework_for_Automated_Unit_Test_Case_Generation_Enhancing_Software_Quality_through_LLMs.pdf
rayyan-394626813,SWT-Bench: Testing and Validating Real-World Bug-Fixes with Code Agents,2024,"Geração de Testes para Reprodução de Problemas (Issue Reproduction) e Validação de Correções de Bugs O objetivo principal é gerar casos de teste que formalizem uma descrição de problema em linguagem natural, garantindo que o teste falhe no código original e passe após a correção (fail-to-pass) Também utiliza estes testes gerados como filtro para validar correções de código propostas por agentes","GPT-4 (utilizado como modelo subjacente para todas as abordagens avaliadas no estudo principal, incluindo os agentes e baselines ZeroShot) O artigo também menciona Claude 3 Opus no contexto do SWE-Agent, mas os experimentos focam no GPT-4","Avalia múltiplos agentes e abordagens no novo benchmark SWT-BENCH SWE-AGENT e SWE-AGENT+ (Agente adaptado com ferramentas específicas para geração de testes). AutoCodeRover. Aider. LIBRO (Abordagem baseline de estado da arte para reprodução de problemas). O próprio SWT-BENCH é proposto como um framework de avaliação baseado em repositórios Python reais (Django, Scikit-learn, Flask, etc.)","Os agentes recebem a descrição de uma GitHub Issue e o repositório de código. Utilizam uma Interface de Computador de Agente (ACI) para navegar, ler arquivos e executar comandos (como pytest) para tentar criar um teste que reproduza a falha O SWE-AGENT+ foi modificado para ter ferramentas específicas de teste e um prompt focado em reprodução em vez de correção A validação é feita verificando se o teste gerado é ""Fail-to-Pass"" ($F \\rightarrow P$) ao aplicar o ""Golden Patch"" (correção real do desenvolvedor)6","Benchmark e Estudo Empírico Dataset: SWT-BENCH contém mais de 1.900 instâncias de problemas reais de 12 repositórios Python populares Métricas: Taxa de Sucesso (S) na geração de testes $F \\rightarrow P$ e Cobertura de Mudança (Change Coverage)8888 Resultados: O SWE-AGENT+ superou métodos não-agentes e outros agentes, resolvendo 51 instâncias (o melhor resultado individual). A combinação (ensemble) dos 4 melhores métodos resolveu 87 instâncias. * O uso de testes gerados para filtrar correções dobrou a precisão do SWE-AGENT (de ~20% para 47.8%)","Linguagem: Limitado a repositórios Python Contaminação de Dados: A maioria das issues foi criada antes do ""Knowledge Cutoff"" do GPT-4, existindo risco do modelo já ter visto as soluções durante o treino. Escopo: Foca apenas em testes de reprodução de bugs, não cobrindo detecção de edge cases ou aumento global de cobertura Erros de Agentes: Agentes por vezes geram testes que passam sem reproduzir o bug, entram em loops ou geram erros de sintaxe","""Code Agents designed for code repair exceeding the performance of systems designed specifically for test generation."" O estudo destaca que reproduzir um problema via teste e corrigi-lo são tarefas distintas com dificuldades diferentes, e que testes gerados são especificações formais valiosas para validar correções automáticas.",,,Advances in Neural Information Processing Systems,,37,,,"Mündler, Niels and Müller, Mark Niklas and He, Jingxuan and Vechev, Martin T.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000529637&partnerID=40&md5=64830080c1fd8ab3a15e5f855dd9811b,,,,,Cited by: 2,,,,,SWT-Bench Testing and Validating Real-World Bug-Fixes with Code Agents_Yuz.pdf
rayyan-394626820,Meet C4SE: Your New Collaborator for Software Engineering Tasks,2023,"Geração de Testes Unitários e de Aceitação, Sugestão de Código, Revisão de Código e Execução de Tarefas no GitHub (via API).",GPT-3.5.,C4SE (Framework Proprietário Open-Source) Arquitetura baseada em LangChain (para orquestração de agentes) e Pinecone (Vector Database para memória de longo prazo).,"Agente Conversacional com Memória de Longo Prazo: 1. O usuário interage via chat (Slack/Teams). 2. O BL Manager classifica a intenção e aciona um Agente especializado (ex: ""Test Agent""). 3. O sistema consulta o Vector DB para recuperar contextos de conversas passadas ou documentos técnicos carregados, permitindo que a IA ""lembre"" de decisões anteriores. 4. O agente gera o teste ou código usando esse contexto aumentado (RAG).","Prova de Conceito / Estudo Preliminar. Cenário: Estudo com participantes realizando 4 tarefas (incluindo gerar testes unitários e de aceitação para um caso de uso do GitHub) Resultados: Reporta resultados preliminares encorajadores sobre o aumento de produtividade, mas não apresenta métricas quantitativas robustas (como % de cobertura ou taxa de acerto) neste short paper","Escopo Fixo: O bot é limitado a um conjunto pré-definido de tarefas e agentes, não conseguindo generalizar para atividades fora do seu script. Idioma: Atualmente suporta apenas inglês. Validação: Necessita de estudos com amostras maiores para comprovar a eficácia real na indústria.","Memória Persistente: O grande diferencial para sua tese é o uso de Vector Databases para ""Long-Term Memory"".  Isso resolve o problema de ""Context Loss"" (perda de contexto) que impede atualizações autônomas em projetos longos. Agentes sem memória não conseguem manter testes de forma consistente ao longo de meses.",,,,,,,235 - 238,"De Vito, Gabriele and Lambiase, Stefano and Palomba, Fabio and Ferrucci, Filomena",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183322950&doi=10.1109%2FSEAA60479.2023.00044&partnerID=40&md5=ade60021c71ddbad55702599f7a6f037,,,,,Cited by: 7,10.1109/SEAA60479.2023.00044,Life cycle; Software agents; Software design; Automated tasks; Chatbots; Conversational agents; D...,,,Meet_C4SE_Your_New_Collaborator_for_Software_Engineering_Tasks.pdf
rayyan-394626822,Towards Autonomous Testing Agents via Conversational Large Language Models,2023,"Conversational Testing (Teste Conversacional). O foco é a colaboração entre Humano (Domain Expert) e IA (Testing Expert) para: esclarecimento de especificações, geração de casos de teste (ex: testes de unidade em Julia) e exploração de edge cases.",GPT-4 (via interface ChatGPT). Utilizado para os exemplos ilustrativos de interação socrática.,SOCRATEST (Framework Proposto/Visionário). Define uma taxonomia de 3 níveis: 1. Conversational Testing: Apenas chat (sem ferramentas). 2. Conversational Testing with Tools: Chat + acesso a compiladores/analisadores. 3. Conversational Testing Agents: Autonomia total para planear e executar testes via Middleware (inspirado no AutoGPT).,"Diálogo Socrático: Em vez de apenas ""pedir o teste"", o humano e a IA debatem. Exemplo: Ao testar uma função clamp (em Julia), a IA gerou um caso de teste errado (alucinação) para um limite. O humano corrigiu, e essa interação revelou uma ambiguidade na especificação. O paper argumenta que a IA deve agir como um ""Testador Júnior"" que faz perguntas (ou erros) que forçam o ""Sério"" (humano) a refinar os requisitos.","Baixa (Proposta Teórica + Exemplo Ilustrativo). Não é um estudo empírico com métricas quantitativas. É um artigo de fundamentação que justifica por que devemos mover-nos para agentes autônomos, usando exemplos qualitativos para demonstrar o valor do diálogo.","Planeamento (Planning): LLMs atuais têm dificuldade em manter planos de longo prazo (necessário para testes complexos). Custo: O treino e inferência de modelos grandes para tarefas triviais pode ser proibitivo. Alucinações: Vistas aqui sob uma ótica dupla: perigosas se não verificadas, mas úteis para ""provocar"" o humano a pensar em casos de borda.","Reframing da Alucinação: Uma citação excelente para sua Discussão: ""The often criticized 'hallucination' of LLMs can be beneficial for testing"". O erro da IA serve como mutação de teste que valida a robustez da especificação humana. Taxonomia de Autonomia: Utilize a classificação deles (Nível 1, 2 e 3) para organizar os outros 14 artigos da sua revisão. Por exemplo, o WaitGPT seria Nível 2 (Com Ferramentas), enquanto o ThreatLens seria Nível 3 (Agente).",,,,,,,1688 - 1693,"Feldt, Robert and Kang, Sungmin and Yoon, Juyeon and Yoo, Shin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179005153&doi=10.1109%2FASE56229.2023.00148&partnerID=40&md5=a280bae3f3cc3d999608c16f706082cd,,,,,Cited by: 19,10.1109/ASE56229.2023.00148,Autonomous agents; Computational linguistics; Learning systems; Machine learning; Artificial inte...;test automation; Development cycle; Intelligence tests; Language model; Large language model; Lev...,,,2306.05152v2.pdf