key,title,year,Test Activities,GenAI Model,Framework/Agent,Usage,Evaluation / Maturity,Limitations,Notes / References,month,day,journal,issn,volume,issue,pages,authors,url,language,publisher,location,abstract,notes,doi,keywords,pubmed_id,pmc_id,PDF files
rayyan-394626652,Test Amplification for REST APIs via Single and Multi-agent LLM Systems,2026,Casos de teste da API REST,OpenAI’s GPT-4o mini model,LangGraph LangChain,REST API,"Traditional tools often lack the ability to perform dynamic and iterative refinement based on execution feedback. Our agent-based LLM systems for REST API amplification address these gaps by increasing coverage with only a few targeted test cases, enabling a more qualitative and automated CI/CD pipeline.","There are still opportunities to improve the results. Prompting plays a crucial role; better-designed prompts can produce even stronger outcomes. The quality of the OpenAPI documentation is another important factor influencing result accuracy. It serves as the primary knowledge base of our approach, and more comprehensive OpenAPI documentation can lead to improved results.","Similar to the way APITestGenie validated its approach, we validated our method using PetStore and LangSmith. There are several promising directions for future research building on current findings and insights from related work. An important avenue is exploring the use of open-source models such as LLaMA 3.3, which have demonstrated competitive performance compared to GPT-4o in recent evaluations. Leveraging open-source models can enhance security by enabling fully local deployment while also reducing costs.",,,Lecture Notes in Computer Science,,16107,,161 - 177,"Nooyens, Robbe and Bardakci, Tolgahan and Beyazit, Mutlu and Demeyer, Serge",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016905732&doi=10.1007%2F978-3-032-05188-2_11&partnerID=40&md5=99a684064135afb0a18884b210cdff0c,,,,,Cited by: 0,10.1007/978-3-032-05188-2_11,Amplification; Application programming interfaces (API); Intelligent agents; Interface states; Mo...,,,Test Amplification for REST APIs via Single and Multi-agent LLM Systems.pdf
rayyan-394626653,Extracting Threats from System Descriptions with LLMs Comparing One and Two Agents Strategies,2026,automação da modelagem de ameaças,"OpenAI o3-mini, OpenAI o1, and Claude 3.7 Sonnet",-,the use of cybersecurity techniques can help testers identify key risks earlier and focus testing efforts more effectively,"The evaluation compared three language models (o1, o3, and Sonnet) under two operational configurations: single-agent and two-agent setups, using precision, recall, and F1-score as evaluation metrics. The results reveal a clear trade-off between precision and recall.

The single-agent configuration achieved higher recall, indicating better threat coverage, but at the cost of lower precision and more false positives. In contrast, the two-agent configuration consistently improved precision but reduced recall, resulting in fewer detected threats.

Among the models, Sonnet demonstrated the best overall performance in both configurations, achieving the highest F1-scores and maintaining a more balanced trade-off between precision and recall. The o1 model achieved the highest precision but suffered from very low recall, limiting its overall effectiveness. The o3 model showed more balanced results, though still inferior to Sonnet.

In summary, the single-agent configuration is more suitable when comprehensive threat coverage is the priority, whereas the two-agent configuration is preferable in scenarios requiring higher precision. In both cases, Sonnet proved to be the most reliable model for supporting cybersecurity testing through automated threat identification.","The quality of these models did not consistently surpass that of threat models created by human experts. LLM-generated results often lacked depth, omitted certain threats, or contained flawed reasoning.","STRIDE framework (Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege).

The dataset used in this study was compiled from several publicly available threat modeling examples. To facilitate analysis, the collected documents were preprocessed and divided into two structured datasets:
– System Description Dataset: includes textual descriptions of 24 different systems.
– Threat List Dataset: contains a total of 745 identified threats associated with these systems, with an average of approximately 31 threats per system.

Another important finding is that the LLMs suggested several novel attack methods that were not included in the dataset. These attack ideas were not previously observed in the training data but are logically plausible and could potentially be exploited by adversaries. This indicates that LLMs may help identify future threats before they become real-world issues, making them useful tools for cybersecurity research and defensive planning.

DevSecOps methodology. PYTM model.",,,Lecture Notes in Computer Science,,16107,,231 - 247,"Zelenskiy, Leonid and Sadovykh, Andrey",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016904785&doi=10.1007%2F978-3-032-05188-2_15&partnerID=40&md5=f99ae9370a58abd4366247580d9c8511,,,,,Cited by: 0,10.1007/978-3-032-05188-2_15,Cybersecurity; Industrial management; Information systems; Information use; Network security; Cyb...,,,978-3-032-05188-2.pdf
rayyan-394626662,Query-efficient and dataset-independent red teaming for LLMs content safety evaluation,2025,"Automated Red Teaming (Adversarial Testing) and Content Safety Evaluation. The objective is to generate attack prompts that expose vulnerabilities in the target model, forcing it to produce toxic or illegal content.",Llama-2-7b-chat and Vicuna-7b-v1.5 (target models). Uses a “Generator” LLM to create the initial attacks.,"RAPT (Reinforcement Learning-based Adaptive Prompt Testing). Cyclical architecture composed of:

Generator: an LLM that creates candidate test cases (attacks).

Selector: a reinforcement learning agent (Contextual Multi-Armed Bandit) that learns which attacks are more effective and selects only the best ones to send to the target model.","Adaptive Test Optimization: Unlike frameworks that generate thousands of random tests (blind fuzzing), RAPT:

Generates a batch of attacks.

The Selector estimates the probability of success based on historical data.

Executes only high-probability tests.

Uses the outcome (success/failure) to update the agent’s policy (Autonomous Strategy Update).","High maturity level (published in a Q1 journal). Metrics: Attack Success Rate (ASR), Query Efficiency (number of queries required to find a vulnerability), and Diversity.

Results: RAPT outperformed state-of-the-art baselines (such as PEZ and GBDA), achieving higher ASR with fewer model queries, thereby validating the efficiency hypothesis.","Generator Dependency: The creativity of the attacks is still limited by the vocabulary of the initial generator LLM.

Text-Only Focus: The study is limited to textual attacks and does not consider multimodal injections (e.g., images), which are emerging trends in 2025.","Efficiency through Intelligent Selection: For your thesis, this serves as the technical argument for “Efficiency”: it is not sufficient to autonomously generate tests; a mechanism (in this case, reinforcement learning) is required to filter and prioritize tests before execution. This reduces computational costs and CI/CD execution time.",,,Knowledge-Based Systems,,329,,,"Liu, Shuo and Cheng, Xiang and Su, Sen",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015138753&doi=10.1016%2Fj.knosys.2025.114404&partnerID=40&md5=71877d405c7b4e49a76a50db48ef3ed7,,,,,Cited by: 0,10.1016/j.knosys.2025.114404,Computational linguistics; Markov processes; Natural language processing systems; Query processin...,,,Query-efficient and dataset-independent red teaming for LLMs content safety evaluation.pdf
rayyan-394626667,DCA-Bench: A Benchmark for Dataset Curation Agents,2025,test cases. Each test case typically contains multiple files designed to create a minimal environment for uncovering hidden data quality issues.,"baseline curation agent based on the OpenAI Assistant API with GPT-4-0125-preview equipped with the Code Interpreter tool.

To develop a reliable and cost-effective evaluator, we tested the following models as backends: GPT-4o (2024-11-20); GPT-4o (2025-05-13); o3-mini (2025-01-31); GPT-4 (preview 0125); GPT-3.5-Turbo; Llama 3.3 70B Instruct; Llama 3 70B Instruct; DeepSeek-R1; DeepSeek-V3.",SGLang LangChain,The Dataset Curation Agent Benchmark collection of representative cases of data quality issues from popular dataset platforms.,"Dataset curation is a complex and broad problem, and the test cases we collected may not fully cover the entire spectrum of data quality issues. Future research may focus on developing more sophisticated LLM-based agent systems and establishing best practices for managing multimodal information in dataset curation.","Due to the complexity of the dataset files, we cannot guarantee that all issues within the DCA-Bench dataset files are labeled.",Dataset Quality Management,,,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,2,,5482 - 5492,"Huang, Benhao and Yu, Yingzhuo and Huang, Jin and Zhang, Xingjian and Ma, Jiaqi W.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014362039&doi=10.1145%2F3711896.3737422&partnerID=40&md5=fe0bf44c620b538b3308c99a81c94e05,,,,,Cited by: 0; All Open Access; Gold Open Access,10.1145/3711896.3737422,Artificial intelligence; Data curation; Human computer interaction; Intelligent agents; Large dat...,,,2406.07275v2_40_.pdf
rayyan-394626670,Mutation-Guided LLM-based Test Generation at Meta,2025,Mutation testing,Llama 3.1 70Bn,TestGen-LLM,Meta’s Llama team,"Large-scale industrial evaluation: the approach was implemented and evaluated in a real industrial environment (Meta), indicating a high level of experimental maturity.

Advanced proof of concept / pre-industrial adoption: the ACH system demonstrates practical feasibility by integrating mutant generation with LLM-based test generation.

Promising empirical results, providing evidence that LLMs reduce historical barriers to the industrial adoption of mutation testing.

Not fully generalized: despite positive results, the maturity of the approach still depends on validation across other contexts (programming languages, domains, and fault types).","Uncertain generalizability: results may be specific to Kotlin, Android, Meta’s internal context, or simulated privacy-related faults.

Mutant relevance: difficulty in ensuring that generated mutants represent specific instances of real faults rather than only the general class of the problem.

Lack of formal similarity metrics between faults, making it difficult to consistently evaluate mutant relevance.

Regression oracle dependency: the approach protects against future regressions but does not detect pre-existing faults in the codebase.

Unresolved oracle problem: the absence of high-precision automatic oracle inference may lead to false positives and wasted engineering effort.

Need for greater precision in test and oracle generation to avoid overburdening engineers.

LLM workflows remain exploratory: further research is needed in fine-tuning, prompt engineering, re-prompting, and Chain-of-Thought techniques to ensure relevance and reliability.",The single language model Llama 3.1 70Bn [42] was used across all reported agents. The prompts used by the three LLM agents,,,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,,,180 - 191,"Foster, Christopher and Gulati, Abhishek and Harman, Mark and Harper, Inna and Mao, Ke and Ritchey, Jillian and Robert, Hervé and Sengupta, Shubho",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013964900&doi=10.1145%2F3696630.3728544&partnerID=40&md5=72e4cc0d7327e32e3ebb61d1e2662a5f,,,,,Cited by: 1,10.1145/3696630.3728544,Automatic test pattern generation; Engineers; Software testing; Automated test generations; Equiv...,,,Mutation-Guided LLM-based Test Generation at Meta_r3t.pdf
rayyan-394626672,ProphetAgent: Automatically Synthesizing GUI Tests from Test Cases in Natural Language for Mobile Apps,2025,GUI test generation from test cases,"GPT-4o. To address RQ2, we conducted experiments using a different LLM, Doubao-pro-128k.",ProphetAgent,"Evaluation of the method on real Android applications, including two large-scale industrial apps (Douyin and Doubao, developed by ByteDance) and six open-source Android applications, aiming to validate the effectiveness and generalizability of the approach in real-world functional testing scenarios.","Extensive empirical evaluation: the method was evaluated on 120 test cases, achieving a test execution completion rate of 78.1% and a low false-positive rate (6.8%).

Validation on real industrial applications (e.g., Douyin), increasing the credibility and practical relevance of the results.

Partial human validation: manual verification of semantic accuracy performed by professionals (88% accuracy).

Indirect comparison with related work, indicating superior performance, although without direct comparison due to the unavailability of prior tools.

Advanced prototype stage / pre-industrial adoption, demonstrating clear productivity gains and practical feasibility.","Limited abstraction-level support: ProphetAgent handles only low-level test cases, requiring each sentence to represent a single action and not supporting high-level user intentions.

Dependency on the knowledge graph (CUTG): executable tests can only be generated for scenarios previously explored and included in the graph.

Coverage constrained by automated exploration: reliance on basic exploration techniques (e.g., Droidbot), which limits the reach of more complex or rare scenarios.

Sensitivity to input format: requires carefully structured textual descriptions to ensure correct parsing and execution.

Threats to external validity: results may depend on the representativeness of the selected applications.

Threats to internal validity: errors in semantic annotation may affect the method’s effectiveness, despite the relatively high reported accuracy (88%).

Generalization depends on future advancements in exploration techniques and knowledge graph enrichment.","The primary objective of ProphetAgent is to enable developers and testers to automatically execute natural language test steps.

The SemanticAgent annotates each transition with explicit semantic information related to user interface (UI) pages and UI events.

The GenerationAgent is responsible for identifying a path in the CUTG that aligns with the natural language test case and generating executable code for execution.

We deployed a GUI Explorer to explore the target application and record GUI transition information after each UI event execution.

The Graph Builder leverages the GUI transition data collected by the GUI Explorer to cluster pages and UI events, constructing a CUTG enriched with semantic information.

Our experiment aims to answer the following research questions:
• RQ1: How effective and efficient is ProphetAgent in synthesizing GUI tests from natural language test steps, and how does it compare to state-of-the-art techniques?
• RQ2: What is the impact of different LLM agents on the proposed method?

We compared our approach with two main techniques for converting natural language into executable GUI tests: a more established method (AppAgent [31]) and a recent state-of-the-art technique (AutoDroid [28]), both of which use LLMs to generate executable GUI tests for Android applications from task descriptions.",,,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,,,174 - 179,"Kong, Qichao and Lv, Zhengwei and Xiong, Yiheng and Sun, Jingling and Su, Ting and Wang, Dingchun and Li, Letao and Yang, Xu and Huo, Gang",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013961463&doi=10.1145%2F3696630.3728543&partnerID=40&md5=b5c6eee38a63a745a4434ad68f42cac5,,,,,Cited by: 0,10.1145/3696630.3728543,Application programs; Computer software selection and evaluation; Graphic methods; Graphical user...,,,fse2025-ProphetAgent.pdf
rayyan-394626673,From Overload to Insight: Bridging Code Search and Code Review with LLMs,2025,"Support for code review. Change set analysis.

Acts indirectly without guaranteeing quality, and does not generate or execute tests.

Testing-related activities: support for code review / indirect quality analysis.

Proposes a human-in-the-loop LLM-based assistant to integrate code search results into code review, aiming to reduce cognitive overload and improve reviewer effectiveness.","The article does not explicitly specify concrete models (e.g., GPT-4, Claude).","LLM-based Interactive Assistant (Human-in-the-Loop).

Does not use explicit frameworks such as LangChain, AutoGen, or LangGraph.","Support for code review.

Primary use cases:
– Reduce reviewers’ cognitive overload.
– Aggregate and contextualize results from multiple tools.
– Enable context-aware interactions guided by reviewer queries.","Exploratory / conceptual stage with a prototype.

The work proposes a new research direction by integrating code search and LLM-mediated code review.

There is no large-scale validation or formal quantitative evaluation.

The focus is on system design, human-in-the-loop interaction, and potential impact rather than industrial maturity.","Lack of quantitative empirical evaluation.

No study of:
– Precision
– Recall
– Measurable impact on code quality

Dependency on:
– The quality of existing search tools
– The LLM’s ability to correctly synthesize heterogeneous information

Does not address:
– Computational costs
– Security or privacy concerns

Potential risks:
– Cognitive overload if poorly designed
– Overreliance on LLM-generated responses","The system operates as:
– An interactive assistant for code review
– An orchestration and summarization layer over search tool outputs

Conceptual architecture centered on continuous human–LLM interaction.",,,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,,,656 - 660,"Rao, Nikitha and Vasilescu, Bogdan and Holmes, Reid",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013959386&doi=10.1145%2F3696630.3728518&partnerID=40&md5=44b507a779648293d9b152108a61218b,,,,,Cited by: 0; All Open Access; Gold Open Access,10.1145/3696630.3728518,Automation; Computer software selection and evaluation; Software quality; Software testing; Stati...,,,From_Overload_to_Insight_Bridging_Code_Search_and_Code_Review_with_LLMs.pdf
rayyan-394626679,"AI-DRIVEN TOOLS IN MODERN SOFTWARE QUALITY ASSURANCE: AN ASSESSMENT OF BENEFITS, CHALLENGES, AND FUTURE DIRECTIONS",2025,"The article covers virtually the entire spectrum of Quality Assurance (QA), including:
– Static code analysis
– Functional test case generation
– Test case validation
– Unit and integration test generation
– Test suite optimization
– Mutation testing
– Automated end-to-end testing
– Exploratory testing
– Equivalence partitioning
– Metamorphic testing
– Validation of AI-based applications","Multiple generative AI models are evaluated:

OpenAI: GPT-4.5, GPT-4o, GPT-4o-mini
Google: Gemini-2.5-Pro, Gemini-2.0-Flash-Lite
Mistral: Mistral-Large, Ministral-8B
Specialized transformers: CodeBERT (for static analysis)

The article also compares large versus small models, analyzing cost, performance, and flakiness.","The article does not propose a single proprietary framework but describes a conceptual architecture composed of multiple agents and components, including:

– LLM-as-a-Generator (for test case and unit test generation)
– LLM-as-a-Judge for test case validation
– ReAct agents for end-to-end execution (reasoning + acting)
– Integration with existing tools (e.g., SonarQube, CodeBERT, Playwright, BrowserUse)
– Pipelines with Retrieval-Augmented Generation (RAG) for contextual enrichment
– LLM-guided mutation testing

Therefore, it represents a hybrid, agent-based architectural framework oriented toward QA tasks.","The primary use case is modern Quality Assurance in distributed systems and web/enterprise applications, with a focus on:
– Accelerating test creation from textual requirements
– Reducing manual QA effort and cost
– Automating end-to-end regression testing in a manner more resilient to UI changes
– Supporting shift-left testing
– Improving test coverage and reliability
– Supporting CI/CD pipelines with intelligent agents

The work demonstrates advanced practical and experimental usage, indicating real-world industrial applicability, although still requiring human supervision.","The work represents a consolidated evolution in the use of AI for QA, moving from isolated applications (e.g., test generation or standalone static analysis) toward an integrated perspective across the entire SDLC.

Unlike earlier studies focused on a single technique, the article demonstrates the progressive combination of:
– Transformer-based static analysis
– Automated test case generation
– Structural test generation (unit and integration tests)
– Optimization via mutation testing
– End-to-end automation with LLM-based agents

Furthermore, it advances the state of the art by evaluating practical maturity, costs, flakiness, and industrial feasibility, indicating a clear transition from exploratory research toward semi-industrial / advanced experimental adoption.","The study identifies clear and relevant limitations for practical adoption:

– Inconsistency in format and quality, especially in smaller models
– Tendency of agents to “correct” negative test cases, leading to false negatives
– Generation of semantically redundant coverage
– Low explainability of LLMs (black-box nature)
– Risk of reasoning loops in less capable agents
– Dependence on external APIs and computational costs
– Need for human verification of results
– Potential deskilling effect on QA professionals

These limitations indicate that the technology still requires governance, guardrails, and rigorous validation.","The models are used in multiple roles:
– Test generation
– Quality judgment (LLM-as-a-Judge)
– Agentic end-to-end execution
– Semantic analysis
– Support for mutation testing

Code, data, and logs are publicly available on GitHub.

The article includes extensive references to mutation testing, ReAct, metamorphic testing, and LLM-as-a-Judge.",,,Technology Audit and Production Reserves,,3,2,44 - 54,"Pysmennyi, Ihor and Kyslyi, Roman and Kleshch, Kyrylo",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011843831&doi=10.15587%2F2706-5448.2025.330595&partnerID=40&md5=25baf85fa1312707ac7952b86bd77ad4,,,,,Cited by: 0; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access,10.15587/2706-5448.2025.330595,,,,"AI-DRIVEN TOOLS IN MODERN SOFTWARE QUALITY ASSURANCE AN ASSESSMENT OF BENEFITS, CHALLENGES, AND FUTURE DIRECTIONS_8u9.pdf"
rayyan-394626697,Beyond Test Cases: Multi-Agent Collaboration for Detecting Defects in Full-Score Code Implementations,2025,Functional code evaluation. Semantic defect detection. Counterexample generation. Formal behavior validation. Analysis beyond traditional test cases. Specification compliance verification. Goes beyond testing: semantic analysis and LLM-guided formal verification.,"The article does not specify a single model, focusing on the functional role of the LLM rather than the provider. Use of LLMs as reasoning and synthesis agents, not as a final oracle. Large Language Models (LLMs) used for: formal specification generation, semantic code analysis, reasoning about potential defects.","Maveric: a multi-agent framework composed of four specialized agents. Template Generator Agent: Derives formal specifications from the problem description. Consistency Checker Agent: Verifies semantic alignment between the generated specification and the original problem. Code Analyzer Agent: Analyzes the code, identifies potential defects, and generates counterexamples. Counterexample Validator Agent: Formally validates counterexamples using formal verification techniques. Multi-agent architecture + formal methods, highly modular and verification-oriented.",Automated code evaluation on educational platforms. Detection of hidden defects in codes that pass all tests. Especially useful where test cases are insufficient to guarantee correctness.,"Advances the state-of-the-art by going beyond test-case-based evaluation, explicitly addressing the problem of correctness false positives. Evolves from LLM-only approaches to a hybrid LLM + formal verification architecture. Introduces a specialized multi-agent collaboration, where each agent acts in a distinct stage of the evaluation process. Represents an important step towards complete semantic correctness evaluation, especially in educational and competitive programming environments.","Dependence on the quality of the formal specification automatically generated by the LLM. Potential generalization limitation for domains outside well-specified algorithmic programming. Evaluation focused on 100 full-score submissions, which may limit scalability for large industrial codebases. Requires formal verification infrastructure, which can increase adoption complexity. Primarily aimed at functional defects, not covering non-functional aspects (performance, security, usability).","Empirical evaluation with 100 full-score codes from 10 real tasks on a widely used educational platform. Manual review identified 32 codes with functional defects. Maveric correctly detected 31 defects, with no false positives. Average evaluation time: < 1 minute per program. LLM-only baseline: 25 defects detected + 6 false positives. Demonstrates a clear advantage of multi-agent collaboration with formal verification.",,,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",,,,124 - 129,"Li, Yiwei and Liu, Jiaxin and Hu, Yanfeng and Liu, Chen and Zhang, Yating and Yin, Liangze and Dong, Wei",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018743838&doi=10.18293%2FSEKE2025-053&partnerID=40&md5=6b4813dad78e2b4f3340c1ac6b4a3fe8,,,,,Cited by: 0,10.18293/SEKE2025-053,Codes (symbols); Computer programming languages; Computer systems programming; Defects; E-learnin...,,,Beyond_Test_Cases_MultiAgent_Collaboration_for.pdf
rayyan-394626698,Comparative Study on Test Case generation using Generative AI,2025,"Unit Test Generation. The focus is on creating tests that ensure the software meets requirements and standards, measuring coverage and quality.","Closed Source: GPT-4o (Best performance), GPT-3.5, OpenAI Codex. Open Source: Llama 3.1 (8B, 70B, 405B), DeepSeek-Coder V2 (16B), CodeLlama (7B to 70B), Codestral 22B, Gemma 27B.","Utilized the TestGenEval benchmark (based on 11 real Python repositories) and HumanEval. Execution environment via Docker and automated Python scripts. The study discusses the future use of ""AI Agents"" and ""RAG"" (Retrieval-Augmented Generation), but the main experiment was via direct prompting.",The solution uses direct prompting to the models via API (for closed models) or local inference (for open models). The flow is: Model Selection -> Dataset Selection -> Prompting -> Statistical Evaluation. The study suggests the future use of Chain of Thought (CoT) and Role-playing to improve quality.,"Metrics: Code Coverage and Mutation Score. Results: GPT-4o achieved 35.2% coverage and 18.8% Mutation Score. The best Open Source was Llama 3.1 70B with 30.6% coverage. Maturity: Academic comparative study. Concludes that current models ""are not yet at the level of human QA teams"".","Hallucinations/Errors: Tests generated with incorrect imports, undefined variables, or incomplete code. Context Window: Difficulty in understanding the full scope of the code in large projects. Hardware: Large models (e.g., Llama 3.1 405B) are difficult to run locally. Business Logic: Models fail to capture specific business rules and edge cases.","Efficiency: The study highlights the DeepSeek-Coder V2 16B model as a viable option to run locally (""home setting"") with 28.2% coverage, balancing cost and performance. Autonomy/Updates: The article explicitly suggests for future work the use of AI Agents that can ""create files and alter code or configurations automatically while maintaining the context of the entire project"". Context Strategy: Proposes ""Dynamic Scope"" to keep only important parts of the code in context during generation in large projects.",,,,,,,366 - 369,"Azzam, Adham and Hany, Omar and Mansour, Hesham",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018464135&doi=10.1109%2FIMSA65733.2025.11166964&partnerID=40&md5=b86914aaa102a4a2761613b1734aa6aa,,,,,Cited by: 0,10.1109/IMSA65733.2025.11166964,Artificial intelligence; Open source software; Open systems; Closed source; Comparatives studies;...,,,Comparative_Study_on_Test_Case_generation_using_Generative_AI_vSm.pdf
rayyan-394626699,An LLM-based software developer agent demonstrated through a port-logistic optimization case study,2025,Automatic unit test generation; indirect support for Software Requirements Specification (SRS) validation and code review.,"GPT-4o, Claude 3.7 Sonnet (proprietary LLMs).",Custom agent based on LangGraph (multi-step architecture with validation and competition between models).,"The agent generates code and, in the final stage, automatically generates unit tests for the selected implementations; tests are part of an agentic development pipeline.",Experimental prototype; evaluation via case studies (Snake game and logistic optimization framework) without formal test quality metrics. Far from real industrial use for autonomous testing.,Generated unit tests are dependent on the quality of the generated code; difficulties in complex contexts; lack of specific empirical evaluation regarding test quality/coverage; strong need for human intervention.,"""the agent … is capable of generating … function implementations, and corresponding unit tests""; tests appear as a byproduct of development, not as the main focus.",,,,,,,,"Dulai, Tibor and Kiss, Gábor",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018454710&doi=10.1109%2FACDSA65407.2025.11166656&partnerID=40&md5=07beea4a4eddd6e7f441df7515005770,,,,,Cited by: 0,10.1109/ACDSA65407.2025.11166656,Computer programming; Intelligent agents; Logistics; Ports and harbors; Software testing; Specifi...,,,An_LLMbased_software_developer_agent_demonstrated_through_a_portlogistic_optimization_case_study.pdf
rayyan-394626700,"Multi-Agent LLM Collaboration for Adaptive Code Review, Debugging, and Security Analysis",2025,Automated code review (quality). Defect detection (debugging). Security analysis (vulnerabilities). Continuous QA support.,"Pre-trained LLMs (e.g., GPT-4, CodeLlama – exact models may vary).",Custom multi-agent framework with three specialized agents + FAISS (RAG/long-term memory).,"Code is automatically analyzed by parallel agents (review, debugging, security), with collaborative refinement and adaptation based on the developer's history; applicable in CI/CD and IDEs.","Advanced experimental prototype; quantitative evaluation with controlled experiments (accuracy, latency, user adaptation).",Does not explicitly generate test cases; focus on static/semantic analysis; dependence on proprietary models; results based on code snippets rather than large industrial systems.,"“multi-agent LLM framework for adaptive code review, debugging, and security analysis”; demonstrates a reduction in redundant feedback and accuracy improvement over time.",,,,,,,541 - 546,"Sharanarthi, Tanush and Polineni, Sreenidhi",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017962329&doi=10.1109%2FMRAI65197.2025.11135756&partnerID=40&md5=c1c8dcd7efc5a31fdf3f2f8723e6caf1,,,,,Cited by: 0,10.1109/MRAI65197.2025.11135756,Codes (symbols); Computer programming languages; Computer software selection and evaluation; Dist...,,,MultiAgent_LLM_Collaboration_for_Adaptive_Code_Review_Debugging_and_Security_Analysis.pdf
rayyan-394626702,Enhancing LLM-based Quantum Code Generation with Multi-Agent Optimization and Quantum Error Correction,2025,Implicit Test-Driven Development (TDD). Syntactic and semantic validation. Use of test suites to evaluate generated code. Experimental tests under quantum noise; reliability evaluation via QEC (Quantum Error Correction).,StarCoder-3B (fine-tuned). GPT-4o used for CoT/SCoT (Chain of Thought/Structured Chain of Thought) prompt generation.,"Custom multi-agent framework (3 agents: Code Generator, Semantic Analyzer, QEC Decoder) with multi-pass inference, CoT, SCoT, RAG.",GenAI generates quantum code iteratively; a custom test suite is used to validate syntactic and semantic correctness. Results are evaluated using test metrics (pass@k) and experimental execution with and without error correction.,"Advanced academic prototype. Extensive quantitative evaluation (pass@k, % of valid tests, experiments under noise). Specific domain (quantum).",Does not explicitly generate test cases; focus on static/semantic analysis; dependence on proprietary models; results based on code snippets rather than large industrial systems.,Demonstrates a reduction in redundant feedback and accuracy improvement over time.,,,,,,,,"Campbell, Charlie and Chen, Mark and Luk, Wayne W.C. and Fan, Hongxiang",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017605997&doi=10.1109%2FDAC63849.2025.11133316&partnerID=40&md5=27976ae3a148261af6d3b69c8ea47b27,,,,,Cited by: 0,10.1109/DAC63849.2025.11133316,Automatic programming; Computer programming languages; Error correction; Intelligent agents; Iter...,,,Enhancing_LLMbased_Quantum_Code_Generation_with_MultiAgent_Optimization_and_Quantum_Error_Correction.pdf
rayyan-394626707,OpenROAD Agent: An Intelligent Self-Correcting Script Generator for OpenROAD,2025,"Automatic validation based on execution tests; failure detection (invalid scripts); indirect functional verification via design metrics (DRC, timing, area, power).",LLM (not explicitly named; proprietary model via API).,OpenROAD Agent – GenAI agent with a self-correcting loop integrated into the OpenROAD EDA flow.,"The agent generates Tcl scripts, executes the OpenROAD flow, uses execution failures and metrics as a test oracle, and automatically corrects the script until valid criteria are met.","Advanced academic prototype; empirical evaluation with multiple designs and quantitative metrics (success rate, number of iterations, QoR [Quality of Results]).",No explicit generation of test cases; tests are specific to the EDA domain; strong dependence on the OpenROAD environment; absence of longitudinal industrial evaluation.,Execution failures act as a testing mechanism.,,,,,,,16 - 22,"Wu, Bingyue and Sharma, Utsav and Rovinski, Austin and Chhabria, Vidya A.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015871212&doi=10.1109%2FICLAD65226.2025.00039&partnerID=40&md5=163d4d6230f67a28f31669c32c0f1cfa,,,,,Cited by: 0,10.1109/ICLAD65226.2025.00039,Computational linguistics; Integrated circuit design; Open source software; Open systems; Personn...,,,OpenROAD_Agent_An_Intelligent_SelfCorrecting_Script_Generator_for_OpenROAD.pdf
rayyan-394626709,Toward Generative 6G Simulation: An Experimental Multi-Agent LLM and ns-3 Integration,2025,Automatic generation of test cases; automatic test execution; functional and performance validation; failure-based debugging; stress tests and edge cases; results analysis.,"LLMs via ChatOpenAI (e.g., GPT-4o / gpt-4o-mini); OpenAI embeddings.","Multi-agent framework based on LangChain + LangGraph, integrated with ns-3 (Simulation Generation Agent, Test Designer Agent, Test Executor Agent, Result Interpretation Agent).","Tests are automatically generated by the Test Designer Agent, executed by the Test Executor Agent; results (logs, metrics) are analyzed by the LLM and used to automatically update the simulation code in an iterative loop.","Advanced academic prototype, with detailed quantitative evaluation (pass@k, average iterations, response time, syntactic error rate, simulation performance metrics).",Specific domain (5G/6G network simulation); tests depend on ns-3 frameworks; absence of real industrial validation; need for specialized knowledge to interpret metrics.,“the Test Designer Agent generates comprehensive automated test suites”; complete generation–test–execution–interpretation pipeline.,,,,,,,,"Rezazadeh, Farhad and Gargari, Amir Ashtari and Lagen, Sandra and Song, Houbing and Niyato, Dusit (Tao) and Liu, Lingjia",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015738145&doi=10.1109%2FMeditCom64437.2025.11104374&partnerID=40&md5=d97a85dffc69ab925ee5e4de28c33ce6,,,,,Cited by: 0,10.1109/MeditCom64437.2025.11104374,Chains; Codes (symbols); Computational linguistics; Computer simulation languages; Computer syste...,,,Toward Generative 6G Simulation An Experimental Multi-Agent LLM and ns-3 Integration_oho.pdf
rayyan-394626714,AgentTester: An LLM-Based Tool for Unit Test Generation with Automatically Generated Prompts,2025,"Automatic test case generation consisting of AutoPrompting, Prompt Distillation, and Validation-Repair modules.","ChatGLM API, glm-4 model, gpt-3.5-turbo. The ChatTester model and the experimental setup of its original paper serve as a comparison baseline for AgentTester.",The ChatTester model and experimental configuration from your original article serve as a basis for comparison with AgentTester.,"AgentTester, which consists of three main modules: AutoPrompting, Prompt Distillation, and Validation-Repair. Automatic generation of unit test cases for Java projects using LLMs. Quality evaluation of generated tests in terms of: Syntactic correctness. Compilation rate. Correct test rate. Coverage (line, method, class, and branch). Applied to three real-world Java projects (jInstagram, TabulaPDF, Zappos).","Three representative Java projects, sourced from GitHub, serve as reference projects with over 15,000 lines of code and more than 1,000 main methods. These three projects have JUnit tests written by developers, which is beneficial for generating and compiling test cases without worrying about environment configuration. This is an experimental and academic approach, validated through comparative empirical studies. It shows a clear evolution compared to previous LLM-based approaches: it surpasses ChatTester and AthenaTest in correct test rate and line coverage. It introduces incremental improvements through specialized modules (PD and VR). Compared to traditional tools (EvoSuite), it shows: lower performance in branch coverage; superior performance in line coverage. It is not yet presented as a consolidated industrial tool (research prototype level). It is an academic prototype with controlled empirical validation.","Lower branch coverage compared to search-based test generation tools like EvoSuite. Compilation rate still not ideal: Even with improvements, approximately 27% of generated tests do not compile in total. Evaluation restricted to: Only three Java projects. Only Java language (generalization limitation). Dependence on multiple executions and sampling with different temperatures, increasing computational cost. No discussion on: Execution time. Financial costs of using LLMs. Continuous integration in industrial pipelines (CI/CD). Filtering tests that compile but fail to execute can reduce the diversity of test cases.","To thoroughly evaluate AgentTester's performance, we selected several widely recognized models as baselines, including traditional techniques (EvoSuite), machine learning-based techniques (AthenaTest), and LLM-based techniques (ChatTester). AgentTester shows up to a 22.5% gain in the correct test rate compared to ChatTester. The Prompt Distillation (PD) module is primarily responsible for the quality improvement: Significant increases in compilation and correction rates (up to +26.4% on jInstagram). The Validation-Repair (VR) module contributes approximately +20% improvement by correcting tests with errors. Demonstrates that LLMs, when combined with agents and automated validation, can outperform ""direct"" LLM approaches. Empirical evidence that hybrid strategies (LLM + programmatic validation) are more effective for automated testing.",,,Communications in Computer and Information Science,,2574,,114 - 126,"Chen, Honghui and Chen, Kaiqing and Zhang, Fanlong and Wang, Tao and Cheng, Lianglun",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013062510&doi=10.1007%2F978-981-95-0011-6_10&partnerID=40&md5=b7408785d11617d826eacb243fc81dd8,,,,,Cited by: 0,10.1007/978-981-95-0011-6_10,Automatic test pattern generation; Error correction; Software reliability; Software testing; Auto...,,,Advanced_Intelligent_Computing_Technology_and_Applications.pdf
rayyan-394626716,Comprehensive Study on Integrating AI-Powered Threat Intelligence Using Large Language Models,2025,Automated Penetration Testing (APT). Network Mapping (Host Discovery). Vulnerability Analysis.,Gemini 1.5 Pro. GPT-4 (evaluated as an alternative),Hierarchical AI Agent System (Multi-agent). LangChain JS. Docker/Kubernetes for tool orchestration.,"The system uses a Master Supervisor that coordinates three specialized agent teams: Pentesting, Cybersecurity Research, and Report Making. The ""autonomous update"" of network knowledge is done via a modified Bellman-Ford algorithm, which incrementally discovers paths, simulating real-time discovery, while agents trigger tools (Nmap, sqlmap) via API.","Academic / Experimental PoC (Proof of Concept). Tested in a laboratory using edge hardware (Raspberry Pi 5 Model B) to prove resource efficiency. Validated through successful scanning of real URLs (e.g., google.com) and log generation.","Context Window: Extensive scan results exceed the LLM limit, requiring chunking. Hallucination: Inaccurate or outdated security recommendations. Computational Cost: Requires optimization to run on limited hardware.","""The algorithm simulates real-time discovery processes by updating paths incrementally as new network information becomes available."" Highlights the Microservices + Agents architecture for scalability.",,,,,,,2141 - 2146,"Nishith, P. and Ratnam, S. Ajay and Bhaskaran, Sreebha",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012111569&doi=10.1109%2FICCSAI64074.2025.11063731&partnerID=40&md5=0ec7b8043470ba4929b72c5dbf36ce97,,,,,Cited by: 0,10.1109/ICCSAI64074.2025.11063731,Automation; Cybersecurity; Integration testing; Intelligent agents; Network security; Algorithmic...,,,Comprehensive_Study_on_Integrating_AIPowered_VuJ.pdf
rayyan-394626721,A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs,2025,REST API Testing (Black-box). Test Input Generation. Inference of Dependencies between Operations.,GPT-3.5 Turbo,"AutoRestTest (proprietary framework based on Multi-Agent Reinforcement Learning - MARL). Features 4 specialized agents: Operation, Dependency, Parameter, Value.","Hybrid approach where the LLM is triggered only by the Value Agent through few-shot prompting to generate values requiring semantic conformity (e.g., emails, specific IDs). The ""autonomous update"" of the testing strategy is done via Reinforcement Learning, updating Q-tables and weights in a dependency graph (SPDG) based on HTTP response codes (2xx, 4xx, 5xx).",High (Academic - ICSE 2025). Validated on 12 real REST services (including Spotify and OhSome). Outperformed 4 state-of-the-art tools (including RESTler and EvoMaster) in code coverage (+15-26%) and fault detection. Detected 42 internal server errors (status 500) against 33 from the second-best tool.,"Data Leakage: The model may have been trained with data from the tested public APIs, inflating results. Specification Quality: Effectiveness depends on the completeness of the provided OpenAPI specification. Network Latency: Tests on real APIs suffer from ""flaky"" behavior due to the network.","""AutoRestTest treats REST API testing as a separable problem [...] The LLM handles the generation of domain-specific values, while the SPDG model simplifies the search space."" The removal of the LLM component in the ablation study reduced coverage by ~10-12%.",,,Proceedings - International Conference on Software Engineering,,,,1409 - 1421,"Kim, Myeongsoo and Stennett, Tyler and Sinha, Saurabh and Orso, Alessandro",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010327327&doi=10.1109%2FICSE55347.2025.00179&partnerID=40&md5=4727c4956022848d4318383703af88cb,,,,,Cited by: 0,10.1109/ICSE55347.2025.00179,Application programming interfaces (API); Intelligent agents; Machine learning; Multi agent syste...,,,A_MultiAgent_Approach_for_REST_API_Testing_with_Semantic_Graphs_and_LLMDriven_Inputs.pdf
rayyan-394626722,NIODebugger: A Novel Approach to Repair Non-Idempotent-Outcome Tests with LLM-Based Agent,2025,Flaky Test Repair (specifically NIO - Non-Idempotent-Outcome type).,"GPT-4 (best performance), GPT-3.5, Qwen 2.5, DeepSeek-Coder.",NIODebugger (LLM-based Agent). Implemented as a Maven plugin for Java.,"Uses a three-phase system (detection, exploration, and correction). The AI agent autonomously plans and executes actions to extract relevant source code outside the test method, simulating a human programmer to resolve ""state pollution"".",High (ICSE 2025). Tested on 20 large-scale open-source projects. Generated correct patches for 101 out of 172 NIO tests. 58 patches were merged into real repositories.,Context Window: The ability to include relevant source code is limited by the LLM's window size. Dynamic Analysis Dependency: Requires multiple executions to identify failure patterns.,"First framework to use an autonomous agent to fix flaky tests. It is capable of autonomously ""cleaning"" the polluted state through instructions that the LLM itself generates to search for cleaning methods in the code.",,,Proceedings - International Conference on Software Engineering,,,,1014 - 1025,"Ke, Kaiyao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010297534&doi=10.1109%2FICSE55347.2025.00226&partnerID=40&md5=9fae623678ae69408c15f101a9b493d6,,,,,Cited by: 1,10.1109/ICSE55347.2025.00226,Codes (symbols); Nickel oxide; Open source software; Open systems; Repair; Software agents; Conte...,,,NIODebugger_A_Novel_Approach_to_Repair_NonIdempotentOutcome_Tests_with_LLMBased_Agent.pdf
rayyan-394626726,Automated Bug Discovery in Cloud Infrastructure-as-Code Updates with LLM Agents,2025,Infrastructure-as-Code (IaC) Update Testing. Bug discovery in update operations (Update logic). Generation of Terraform programs.,GPT-4o,"IaC-BugFinder (Multi-agent system). Includes agents: Generator, Executor, and Analyzer.","Uses agents to generate initial IaC programs and then autonomously generate update sequences (changing parameters, relationships). The Analyzer compares the final cloud state with the desired state to detect discrepancies (bugs).","Academic PoC (AIOps 2025). Tested against the AWS Terraform provider. Discovered 4 critical bugs (3 in the AWS provider and 1 in the Terraform core), all confirmed by developers.",Token Cost: Long update sequences increase the cost. Test Oracles: Difficulty in distinguishing whether a failure is from the cloud provider or the testing tool.,"""IaC-BugFinder automates bug discovery in infrastructure updates... a domain where manual testing is impractical due to the vast state space."" [pages 1, 5].",,,,,,,20 - 25,"Xiang, Yiming and Yang, Zhenning and Peng, Jingjia and Bauer, Hermann and Kon, Patrick Tser Jern and Qiu, Yiming and Chen, Ang",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009458915&doi=10.1109%2FAIOps66738.2025.00011&partnerID=40&md5=22fec64a714f3a2c99b17a030e2ddc74,,,,,Cited by: 1,10.1109/AIOps66738.2025.00011,Cloud computing; Cloud platforms; Codes (symbols); Program debugging; Software reliability; Cloud...,,,Automated Bug Discovery in Cloud Infrastructure-as-Code Updates with LLM Agents_msW.pdf
rayyan-394626728,Human-In-The-Loop Software Development Agents: Challenges and Future Directions,2025,"Unit tests: FAIL_TO_PASS and PASS_TO_PASS tests to verify issue resolution and maintain existing functionality. Static analysis using SonarQube to evaluate code quality metrics, such as code smells, complexity, and duplication.",GPT-4 (as part of AppMap Navie + GPT-4o).,Not mentioned,Evaluating patches from software development agents on real GitHub issues to assess their impact on code quality.,"Evaluation method: Comparison of agent-generated patches with ""golden patches"" from repository developers. Performance metrics: precision, recall, F1-score [...] Statistical tests: Wilcoxon signed-rank test and Mann-Whitney U test [...] Key findings: No single agent dominated; agents maintained reliability and security but varied in complexity and duplication; better performance on simpler tasks.",Limitations in SWE-Bench evaluation: Patches generated by the agent may not be fully covered by current test cases. Potential data collection bias and measurement reliability issues. Limited generalizability to other programming languages ​​or project types. Metrics may not fully capture all aspects of code quality or agent performance. The assumption that gold patches are optimal may not always be accurate. Need for future research to improve the handling of complex scenarios and vulnerability-prone issues.,"The study provides the first comprehensive evaluation of software development agent patches on real GitHub issues, highlighting that no single agent dominates and suggesting that breaking down complex tasks into simpler ones can improve effectiveness. Most agents maintain code reliability and security but need improvements to minimize code complexity and duplication.",,,,,,,756 - 757,"Pasuksmit, Jirat and Takerngsaksiri, Wannita and Thongtanunam, Patanamon Pick and Tantithamthavorn, Kla (kla) and Zhang, Ruixiong and Wang, Shiyan and Jiang, Fan and Li, Jing and Cook, Evan and Chen, Kun and Wu, Ming",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009162123&doi=10.1109%2FMSR66628.2025.00112&partnerID=40&md5=698142c669aae605243d9a432638bec7,,,,,Cited by: 0,10.1109/MSR66628.2025.00112,Information systems; Intelligent agents; Multi agent systems; Software quality; Software testing;...,,,Human-In-The-Loop_Software_Development_Agents_Challenges_and_Future_Directions.pdf
rayyan-394626731,Special Session: ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification,2025,"Security Threat Modeling and Security Test Plan Generation. Specific focus on software-exploitable hardware vulnerabilities (e.g., privilege escalation, memory corruption) and supply chain attacks.",GPT-4o. Used OpenAI embeddings for semantic representation in RAG.,"ThreatLens (Multi-agent Framework). Composed of specialized agents: Threat Identification Agent, Security Policy Generator Agent, and Test Plan Generator Agent. Base technologies: LangChain, RAG (Retrieval-Augmented Generation), and FAISS (for similarity search).","RAG: Extracts security knowledge from academic papers and instruction manuals (ISA) to contextualize the model. Multi-Agent Flow: One agent identifies the threat, another extracts the security policy from the manual (e.g., RISC-V ISA), and a third generates the test plan. Refinement: The system interacts with the engineer only to validate initial assumptions, dynamically updating its ""question bank"".","Case Study on a Real SoC (System on a Chip). Result: The tool automatically generated 854 unique security policies, covering critical vulnerabilities such as PMP (Physical Memory Protection) violations. Validated through case studies where failure to verify these policies led to real hacks.","Closed Model Dependency: The use of GPT-4o implies high computational costs and dependence on an external API. Lack of Asset Extraction: The system does not yet automatically extract all ""security assets"" from the design, which could reduce redundant queries.","Update Efficiency: The article highlights that manual methods ""struggle to scale"" with the evolution of attack methodologies. The agentic approach allows updating the Test Plan merely by ingesting new security papers into the RAG base, without rewriting the agent's code. Autonomy: The ability to autonomously generate 854 policies demonstrates a massive efficiency gain over manual verification.",,,Proceedings of the IEEE VLSI Test Symposium,,,,,"Saha, Dipayan and Al-Shaikh, Hasan and Tarek, Shams and Farahmandi, Farimah",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008498031&doi=10.1109%2FVTS65138.2025.11022932&partnerID=40&md5=7aa515b66bd36cec92dc68c0e6f83d34,,,,,Cited by: 0,10.1109/VTS65138.2025.11022932,Computer hardware; Human computer interaction; Verification; Hardware security and trust; LLM; Pl...,,,Special Session ThreatLens LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification_8OZ.pdf
rayyan-394626732,CKGFuzzer: LLM-Based Fuzz Driver Generation Enhanced By Code Knowledge Graph,2025,Automated fuzz testing. Automatic generation of fuzz drivers. Input seed generation. Coverage-guided mutation. Automatic crash analysis.,DeepSeek-V2-Coder (generation and repair). DeepSeek-V2-Chat (auxiliary agents). LLMs for summarization and reasoning.,CKGFuzzer – multi-agent system integrated with a Code Knowledge Graph + custom RAG + libFuzzer/OSS-Fuzz.,Autonomous generation of fuzz drivers from APIs; automatic repair of compilation errors; initial seed generation via LLM; coverage-based mutation of API combinations; crash classification and analysis via chain of reasoning.,"Advanced academic prototype, empirically evaluated on 8 open-source libraries. Quantitative metrics (branch coverage, compilation rate, real bugs found). Comparison with OSS-Fuzz and PromptFuzz.",Strong dependence on the quality of the Code Knowledge Graph. Evaluated only on C/C++ libraries. High computational cost. Risk of LLM hallucinations. Generalization to other languages not yet validated.,"
8.73% average coverage; 11 real bugs detected (9 new); 84.4% reduction in manual crash analysis effort.",,,Proceedings - International Conference on Software Engineering,,,,243 - 254,"Xu, Hanxiang and Ma, Wei and Zhou, Ting and Zhao, Yanjie and Chen, Kai and Hu, Qiang and Liu, Yang and Wang, Haoyu",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008497196&doi=10.1109%2FICSE-Companion66252.2025.00079&partnerID=40&md5=3f96e9b2e02faa23fe1edaa25aa1a65b,,,,,Cited by: 0,10.1109/ICSE-Companion66252.2025.00079,Accidents; Application programming interfaces (API); Codes (symbols); Computer software selection...,,,CKGFuzzer LLM-Based Fuzz Driver Generation Enhanced By Code Knowledge Graph_d2B.pdf
rayyan-394626734,AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL,2025,"Automated REST API testing. Automatic generation of operation sequences. Generation of parameters, values, and headers. Exploration of dependencies between operations. Detection of 4xx/5xx errors. Lightweight fuzzing by request mutation.","OpenAI LLMs (e.g., GPT-4o, GPT-4o-mini, o1, o1-mini).","AutoRestTest – hybrid framework with Multi-Agent Reinforcement Learning (MARL) + Semantic Property Dependency Graph (SPDG) + specialized agents (operation, parameter, value, dependency, header).","The LLM is primarily used to generate parameter values and headers. MARL selects operations, dependencies, and combinations. Iterative execution with feedback based on HTTP responses (2xx, 4xx, 5xx). Continuous updating of Q-tables.","Functional academic prototype, empirically evaluated on 4 real REST APIs (FDIC, OMDb, OhSome, Spotify). Quantitative metrics (exercised operations, unique errors, status codes). Direct comparison with RESTler, EvoMaster, ARAT-RL, and MoRest.",Preliminary evaluation (fixed time of 1h). Exclusive focus on REST APIs. LLM restricted to value generation (does not generate complete test logic). Dependence on OAS 3.0 (OpenAPI Specification). Costs associated with LLM usage.,The only tool to obtain 2xx responses in the OhSome service. Detected an unprecedented 5xx error in Spotify.,,,Proceedings - International Conference on Software Engineering,,,,21 - 24,"Stennett, Tyler and Kim, Myeongsoo and Sinha, Saurabh and Orso, Alessandro",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008493507&doi=10.1109%2FICSE-Companion66252.2025.00015&partnerID=40&md5=6b424c86446186db5a71163dacbdd1aa,,,,,Cited by: 0,10.1109/ICSE-Companion66252.2025.00015,Application programming interfaces (API); Error detection; Fault detection; Intelligent agents; M...,,,2501.08600v2.pdf
rayyan-394626736,Towards Architectural Pen Test Case Generation and Attack Surface Analysis to Support Secure Design,2025,Penetration test case generation (architectural penetration test cases). Attack surface analysis. Security test prioritization. Support for security testing in the design phase.,"LLMs (unspecified), planned for test case generation and threat modeling support.","Proposed conceptual framework (based on architectural models such as PCM, threat modeling, CWE/CAPEC/CVE, with future LLM integration).","Planned use of LLMs to generate penetration test cases from architectural models, prioritize them based on severity, and support architects with security feedback during the design phase.",Research proposal / conceptual plan with no implementation or empirical evaluation at the moment.,No implementation. Absence of experimental evaluation. GenAI model not defined. Approach is still hypothetical. Restricted focus on the design phase.,LLMs are cited as a future enabling technology.,,,,,,,143 - 148,"Sarvejahani, Mahdi Jafari",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007880639&doi=10.1109%2FICSA-C65153.2025.00027&partnerID=40&md5=c705d9b1be50927d023e0e9155558783,,,,,Cited by: 0,10.1109/ICSA-C65153.2025.00027,Computer operating systems; Computer software selection and evaluation; Embedded software; Intell...,,,Towards_Architectural_Pen_Test_Case_Generation_and_Attack_Surface_Analysis_to_Support_Secure_Design.pdf
rayyan-394626737,Evaluation of the Choice of LLM in a Multi-Agent Solution for GUI-Test Generation,2025,"Automated Exploratory GUI Testing. Focus on web applications (e-commerce), aiming to perform complex end-to-end tasks (e.g., ""make an online purchase"") without pre-recorded scripts.","Llama 3.1, Gemma 2, Mistral-Nemo. Note: All used in quantized versions (4-bit) for local execution (Local LLMs), aiming at privacy and low cost.",PathFinder (Proprietary Multi-Agent Framework). Architecture composed of 4 specialized agents: 1. Perceptron: Collects and summarizes the HTML/DOM. 2. System 1: Makes navigation decisions (click/type). 3. EntryBot: Manages input data (fills forms with dummy user data). 4. Oracle: Validates whether the test passed or failed.,"The system does not use scripts (e.g., Selenium IDE). It receives a URL and a goal (Prompt: ""Buy an item""). The agents operate in an Observe-Reason-Act cycle: - Perceptron converts the page into clean JSON. - System 1 decides the action based on history. - Oracle verifies success every 5 steps. The study tested 27 different model permutations among the agents.","Academic Maturity (Empirical Experiment). Scenario: 4 real e-commerce sites. Metrics: Effectiveness (F1-Score) and Efficiency (Execution time). - Llama 3.1 was the most robust model individually. - Interestingly, the hypothesis that ""mixing specialized models is better"" was partially refuted; using a strong model (Llama 3.1) across all agents generated more consistent results due to better coordination.","Agent Coordination: Using different models in different agents caused communication discrepancies (one model did not understand the other's output well). Selector Hallucination: The model sometimes invents element IDs (mitigated in the paper using Fuzzy String Matching). Context Dependency: The Perceptron agent requires an 8k token window, which limits the use of very small or older models.","Relevance for Autonomous Updates: This is a perfect example of implicit Self-Healing. Since there is no hard-coded script (only the natural language goal), if the UI changes (e.g., a button moves), the agent adapts automatically, solving the GUI test maintenance problem. Privacy: Stands out for proving it is possible to run complex testing agents locally (without sending data to OpenAI), a key requirement for many companies.",,,,,,,487 - 497,"Tomic, Stevan and Alégroth, Emil and Isaac, Maycel",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007519090&doi=10.1109%2FICST62969.2025.10989038&partnerID=40&md5=a9c1278607d06e5157ef49503bf355f4,,,,,Cited by: 0; All Open Access; Green Accepted Open Access; Green Open Access,10.1109/ICST62969.2025.10989038,Ability testing; Autonomous agents; C (programming language); Intelligent agents; Model checking;...,,,Evaluation of the Choice of LLM in a Multi-Agent Solution for GUI-Test Generation_QNd.pdf
rayyan-394626738,"Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios",2025,Functional correctness testing using the SWE-bench dataset. GPT-based similarity scoring using GPT-4 and GPT-4o.,GPT-4 GPT-4o,HULA (Human-In-The-Loop LLM-based Software Development Agents Framework).,Software development and problem-solving using human-in-the-loop software development agents to resolve Jira work items.,"Evaluation methods: Functional correctness testing using the SWE-bench dataset, GPT-based similarity scoring. Performance metrics: 37.2% resolution rate on the verified SWE-bench dataset, high similarity score of 38.5% for work items. Validation: Strong agreement with human evaluations (correlation coefficient: 0.7), F1 score: 0.67 for unit test representation.",High computational costs of unit testing. Variability in LLM-based evaluations. Labor-intensive dataset creation for unit tests. Binary pass/fail outcomes in unit testing. Expensive and time-consuming test execution. Difficulty in evaluating small incremental improvements due to fluctuating LLM results.,----,,,,,,,657 - 668,"Chen, Zhi and Jiang, Lingxiao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007302779&doi=10.1109%2FSANER64311.2025.00068&partnerID=40&md5=1e5568549f4eba6213f35f8ccaa4be56,,,,,Cited by: 0,10.1109/SANER64311.2025.00068,Application programs; Computer operating systems; Computer software maintenance; Computer softwar...,,,2410.12468v2_dGu.pdf
rayyan-394626739,Approach to Forming Vulnerability Datasets for Fine-Tuning AI Agents,2025,Vulnerability detection (security testing) via static code analysis. Indirect support for security testing during development and testing. Data generation for training and updating testing agents.,CodeQwen 2.5 (7B) fine-tuned. Use of ChatGPT-4o for generating synthetic samples of rare vulnerabilities.,"Dataset curation pipeline for fine-tuning AI agents (not a testing agent itself); Python scripts + Polars. Integration with CVE, GitHub Advisory, and OSS repositories.",GenAI is used for (i) fine-tuning vulnerability detection models and (ii) synthetic generation of examples for dataset balancing; the goal is to create continuously updatable security agents.,"Evaluated experimental prototype. Real dataset (2013–2025). Fine-tuning performed and evaluated with classic metrics (Precision, Recall, F1, FPR). Quantitative results reported, but performance is still limited.",Exclusive focus on Python. Static analysis only. Low initial model generalization capacity. Low recall for several CWEs. External dependencies not analyzed. Tests are not executed on the SUT (System Under Test).,284 synthetic vulnerabilities generated with ChatGPT-4o (cost ≈ US$9).,,,,,,,771 - 776,"Gladkikh, Kirill and Zakharov, Alexander A.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007163730&doi=10.1109%2FSmartIndustryCon65166.2025.10986048&partnerID=40&md5=c17a17e425a33f43983fe72168611c09,,,,,Cited by: 0,10.1109/SmartIndustryCon65166.2025.10986048,Computer software selection and evaluation; Data curation; Data flow analysis; Model checking; Op...,,,14259.pdf
rayyan-394626746,Adaptive Test Healing using LLM/GPT and Reinforcement Learning,2025,"Automatic test healing; maintenance and updating of functional tests, adaptation of tests to changes in the SUT, identification of failures due to UI/flow changes.",GPT (OpenAI LLM) used to suggest test corrections; RL model (Q-learning) for action selection.,"Hybrid LLM + Reinforcement Learning framework for test maintenance, agents responsible for detecting failures, proposing corrections, and learning repair strategies.","When tests fail due to system changes, the LLM suggests modifications to the test scripts, the RL agent chooses and applies the best action, execution feedback updates the policy, allowing continuous learning.","Academic prototype / experimental study, evaluation in controlled automated testing scenarios, qualitative and quantitative metrics (healing success rate, manual effort reduction).","Limited scale evaluation, focus on functional/UI tests, dependency on proprietary LLM, absence of long-term industrial study, possible LLM errors require human validation.",Demonstrates significant reduction in manual test maintenance.,,,,,,,9 - 16,"Mani, Nariman and Attaranasl, Salma",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004735212&doi=10.1109%2FICSTW64639.2025.10962516&partnerID=40&md5=b70259ee11a7c7ada5d2d2cab21e9645,,,,,Cited by: 1,10.1109/ICSTW64639.2025.10962516,C (programming language); Computer operating systems; Computer software selection and evaluation;...,,,Adaptive_Test_Healing_using_LLM_GPT_and_Reinforcement_Learning.pdf
rayyan-394626752,Multi-Agent hierarchical workflow for autonomous code generation with Large Language Models,2025,Unit Test Generation (Unit Test Development). Autonomous Debugging (Automated Debugging). Generated Code Validation.,GPT-4o,"Multi-Agent Hierarchical Workflow. Integrates AlphaCodium, LangChain, and LangGraph. Specific agents: Programmer, Unit Test, Executor, and Debugging.","The workflow uses a hierarchical approach where, after code generation (using the Skeleton-of-Code technique for parallelism), a Unit Test Agent verifies the code and a Debugging Agent resolves failures identified by the Executor Agent. Agents have access to external tools (Wolfram Alpha, Web Search) to validate logic and syntax.","Academic PoC (IEEE Student Conference). Evaluated on 3 classic datasets (e.g., California Housing). Compared with ChatGPT, Claude, and Perplexity. Achieved 100% functional accuracy in the tests performed and maximum score in readability. Fast execution (3.4s - 5.7s).","Limited Scope: The current prototype focuses only on data analysis via CSV files. Scalability: Needs to evolve to support complex formats (JSON, XML) and real-time data. Security Risk: The article cites the need for supervision to avoid vulnerabilities in AI-generated code.","""The system operates by analyzing the dataset... assigning sequentially working agents: a programmer agent..., a unit test agent verifies the code, and an executor agent executes the code."" Highlight for the Skeleton-of-Code technique to reduce latency.",,,,,,,,"Akilesh, S. and Sekar, Rajeev and Om Kumar, C. U. and Prakalya, D. and Suguna, M.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002712410&doi=10.1109%2FSCEECS64059.2025.10940635&partnerID=40&md5=82551e1af9a6048e627580f4f80faab8,,,,,Cited by: 1,10.1109/SCEECS64059.2025.10940635,Ada (programming language); Application programs; Autonomous agents; C (programming language); Co...,,,Multi-Agent_hierarchical_workflow_for_autonomous_code_generation_with_Large_Language_Models.pdf
rayyan-394626754,Using LLM-Based Deep Reinforcement Learning Agents to Detect Bugs in Web Applications,2025,Black-Box GUI Testing (Web Applications). Exploratory Testing. Bug Detection.,Gemma-7b (Local model).,DRL (Deep Reinforcement Learning) Agent based on PPO (Proximal Policy Optimization) using Stable Baselines3 and Selenium.,"The LLM is used as a state inference sensor. Instead of relying on browser APIs (which vary between Chrome/Safari), the agent extracts the raw HTML and asks the LLM: ""Is this element clickable?"". The response (0 or 1) is added to the RL agent's state vector to guide exploration.","Academic PoC (ICAART 2025). Validated on a custom web application (Vue.js). The LLM-assisted agent reached maximum reward in 5 epochs, tying with the agent that had access to real browser data, and vastly outperforming the agent without this information (11 epochs). LLM inference accuracy was 81.5% on real web-extracted elements.","Inference Latency: Running the LLM at each step is slow; mitigated via caching. App Complexity: Tested only on a simple app; complex apps may increase inference noise. Generalization: Not validated in scenarios where ""clickability"" is not the critical factor.","""Our hypothesis is that combining the inferential capabilities of LLMs with the robustness of DRL can match the accuracy of methods that rely on direct data collection."" Approach focused on efficient Cross-Browser Testing.",,,International Conference on Agents and Artificial Intelligence,,3,,1001 - 1008,"Sakai, Yuki and Tahara, Yasuyuki and Ohsuga, Akihiko and Sei, Yuichi",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001979448&doi=10.5220%2F0013248800003890&partnerID=40&md5=e11343925c0bfbc45c2e1839fd45504a,,,,,Cited by: 0,10.5220/0013248800003890,,,,132488.pdf
rayyan-394626756,Agentic AI for Behavior-Driven Development Testing Using Large Language Models,2025,Automatic generation of BDD tests (Gherkin). Support for functional/acceptance test specification. Syntactic and semantic correction of tests. Linking between natural language and test implementation.,Fine-tuned open-source LLM (Llama 3.1 8B). Use of GPT-4 only for synthetic training data generation.,"BDDTestAIGen – Agentic AI framework with LLM + classic NLP (POS, SRL) + RAG + human-in-the-loop, integrated with Behave / Gherkin.","The agent guides the user in creating BDD tests in natural language, maps steps (Given/When/Then) to existing implementations, corrects errors, and requests human intervention when there is ambiguity. Focus on reducing manual effort and including non-technical stakeholders.","Academic prototype with empirical evaluation. Quantitative evaluation (1,983 synthetic tests, matching rate, error types) and qualitative evaluation (study with developers and non-programmers on commercial games).",Dependence on human-in-the-loop. There is no fully autonomous test generation. Exclusive focus on BDD. Problems with unit and type conversion. Does not automatically update the SUT (System Under Test).,"“First study to combine LLMs, NLP, human-in-the-loop and Agentic AI to automate BDD test creation.” Correct matching in >50% of cases with the fine-tuned 8B model.",,,International Conference on Agents and Artificial Intelligence,,2,,805 - 815,"Päduraru, Ciprian Ionut and Zavelca, Miruna and Ştefǎnescu, Alin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001687420&doi=10.5220%2F0013374400003890&partnerID=40&md5=9a5f5ecb6df9a0851aa031db5d4e7894,,,,,Cited by: 0,10.5220/0013374400003890,,,,133744.pdf
rayyan-394626759,FlexFL: Flexible and Effective Fault Localization With Open-Source Large Language Models,2025,"Fault localization to support debugging and testing. Identification of faulty methods from failing tests, bug reports, or both. Direct support for failure analysis activity in automated tests.",Open-source LLMs (primarily Llama 3-8B-Instruct). Also evaluated with Qwen2-7B-Instruct and Mistral-Nemo-12B-Instruct.,"FlexFL, a two-phase framework with LLM agents (Agent4SR and Agent4LR) + classic FL techniques (SBFL, IRFL, HybridFL). Use of ReAct + simulated function calls.","The system uses GenAI to reduce the search space and then refine fault localization by analyzing code, failing tests, and bug reports. Supports multiple information sources and executes almost fully automatic analysis.","High academic maturity. Extensive evaluation on Defects4J v1.0 and v2.0.0. Comparison with SOTA (AutoFL, AgentFL, SBIR, Ochiai). Top-1/3/5, MAP, MRR metrics. Public code and replication package.",Does not execute tests or fix defects. Depends on the quality of available tests/reports. Performance is still limited by the base LLM's capacity; failures in complex or ambiguous bugs.,"""FlexFL outperforms existing fault localization techniques and can localize 93 bugs that cannot be localized by non-LLM-based techniques."" First FL approach with open-source LLMs.",,,IEEE Transactions on Software Engineering,,51,5,1455 - 1471,"Xu, Chuyang and Liu, Zhongxin and Ren, Xiaoxue and Zhang, Gehao and Liang, Ming and Lo, David",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000368545&doi=10.1109%2FTSE.2025.3553363&partnerID=40&md5=fb2b1f9a800980a644f4ff5a2d40e048,,,,,Cited by: 0,10.1109/TSE.2025.3553363,Computer debugging; Computer software selection and evaluation; Open source software; Outages; Pr...,,,FlexFL Flexible and Effective Fault Localization With Open-Source Large Language Models_0Qq.pdf
rayyan-394626764,Self-Collaboration Code Generation via ChatGPT,2024,Debugging. Fault localization. Test failure analysis. Unit test generation. Code comprehension and explanation. General support for V&V (Verification and Validation) activities.,"Proprietary and open-source LLMs (e.g., GPT-3.5/4, Codex, LLaMA) evaluated in a zero-shot setting.",Does not propose a specific framework. Use of direct prompting and chain-of-thought as a cognitive mechanism.,"LLMs are used as general reasoners to solve SE tasks without specific training, including explaining failures, locating defects from code, and generating simple unit tests.",Broad experimental study. Evaluation across multiple SE benchmarks. Accuracy and success metrics per task. No integration into real testing pipelines.,No operational autonomy. Tasks are isolated. Performance sensitive to prompting. Absence of continuous integration or incremental learning.,"""LLMs demonstrate strong zero-shot reasoning capabilities across a wide range of software engineering tasks."" Evidences that LLMs can support testing even without fine-tuning.",,,ACM Transactions on Software Engineering and Methodology,,33,7,,"Dong, Yihong and Jiang, Xue and Jin, Zhi and LI, Ge",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198255497&doi=10.1145%2F3672459&partnerID=40&md5=c103ee9b9813f3e4926767fd4a5695f6,,,,,Cited by: 50,10.1145/3672459,Benchmarking; Computer software selection and evaluation; Intelligent agents; Intelligent virtual...,,,2304.07590v3_qfq.pdf
rayyan-394626766,First Experiments on Automated Execution of Gherkin Test Specifications with Collaborating LLM Agents,2024,Automatic execution of acceptance tests (BDD). Automation of Gherkin-based tests. Dynamic generation of web test code. Automatic exploration of the SUT (System Under Test). Evaluation of execution results.,"GPT-3.5-turbo-0125, GPT-4o.","AutoGen multi-agent framework with collaborative agents (Coordinator, Coder, Executor, Analyst) integrated with Playwright for web testing.","Starting from Gherkin scenarios (Given-When-Then), the agents autonomously explore the system, generate Python test scripts, execute actions in the browser, analyze the returned HTML, and decide the next steps until the scenario is completed or aborted.","Work-in-progress / initial experimental study. Empirical evaluation on 15 Gherkin scenarios (simple, complex, and negative) in the PetClinic system; detailed metrics (success rate, time, number of interactions, tokens, exceptions). Comparison between GPT-3.5 and GPT-4o.","Limited scale. Strong reliance on the LLM. Hallucination problems, especially in negative scenarios. Failure detection is still weak. High costs (GPT-4o). Lack of persistent learning between executions.","“LLM agent system is able to automatically run the given test scenarios by autonomously exploring the system under test, generating executable test code on the fly, and evaluating execution results.” GPT-4o successfully executed 100% of simple and complex scenarios.",,,,,,,12 - 15,"Bergsmann, Severin and Schmidt, Alexander and Fischer, Stefan and Ramler, Rudolf",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207104093&doi=10.1145%2F3678719.3685692&partnerID=40&md5=96e8a10edaf283adc4a4c1910d96fd0e,,,,,Cited by: 1,10.1145/3678719.3685692,Autonomous agents; Intelligent agents; Model checking; Specification languages; Domains specific ...,,,3678719.3685692.pdf
rayyan-394626767,AutoCodeRover: Autonomous Program Improvement,2024,Fault localization. Test-based validation. Debugging support. Implicit regression testing via execution of existing suites. Indirect support for program repair testing.,GPT-4 (commercial LLM). Model used as a reasoning and patch generation agent.,"AutoCodeRover – multi-agent framework with: (i) context retrieval agent (AST-based code search), (ii) patch generation agent. Optional integration with SBFL (Spectrum-Based Fault Localization).","Use of LLMs to resolve real GitHub issues, combining structured AST search, natural language issue analysis, and test execution to validate patches. Existing tests guide fault localization and automatic validation.","High experimental maturity. Implemented tool, open-source, evaluated on a large scale (SWE-bench / SWE-bench-lite). Quantitative metrics (pass@1, pass@3, cost, time). Compared with SWE-agent and Devin.","Dependence on existing tests for better performance. Possibility of plausible but incorrect patches (overfitting). Dependence on a closed model (GPT-4). Failures when the issue does not contain clear ""hints"". Limited coverage when there is no test suite.","""AutoCodeRover can leverage debugging techniques such as spectrum-based fault localization using tests."" 19% success rate on SWE-bench-lite (pass@1), average cost US$0.43; tests used as a validation oracle.",,,,,,,1592 - 1604,"Zhang, Yuntong and Ruan, Haifeng and Fan, Zhiyu and Roychoudhury, Abhik",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203182652&doi=10.1145%2F3650212.3680384&partnerID=40&md5=310c02174e2875183e70cc48042048fa,,,,,Cited by: 27; All Open Access; Gold Open Access,10.1145/3650212.3680384,Computer debugging; Computer software maintenance; Computer software selection and evaluation; Co...,,,AutoCodeRover Autonomous Program Improvement_cga.pdf
rayyan-394626771,A New Generation of Intelligent Development Environments,2024,"Development & Test Orchestration. The focus is not an isolated activity, but redefining the human's role as a ""Manager"" who supervises coding and testing AI agents.","Conceptual (GenAI Agents in general). The paper is not tied to a specific model (like GPT-4), but assumes the use of LLMs capable of symbolic reasoning and code generation.",Intelligent Development Environment (IDE 2.0). Proposes an architecture where the IDE ceases to be a text editor and becomes a command platform for agents. Integrates technologies such as the Bosque Language (a language focused on formal verification) and autonomous agents.,"Intent-Driven Programming: 1. The human defines the ""intent"" or high-level specification. 2. AI agents generate the implementation. 3. Symbolic Verification tools validate correctness (not just unit tests, but mathematical proof that the code does what the intent requested). 4. The IDE presents a structured visualization (not just text) for human approval.","Low (Visionary / Theoretical Proposal). Does not present evaluation metrics (F1-score, Coverage). It is a position paper that argues about the future of AI-based software engineering. Based on formal language principles and previous experiences with Microsoft Research tools.","Determinism: Criticizes the non-deterministic nature of current LLMs (""hallucinations""). Argues that for real autonomy, we need Neuro-Symbolic AI (Generative AI + Rigid Logical Verification), as LLMs alone will never be reliable for critical systems. Legacy: The difficulty of adapting this vision to legacy codebases (Java/C++) that were not designed to be easily machine-analyzable.","Autonomy vs. Reliability: This is the key quote for your thesis: ""We must move from probabilistic generation to provable correctness."" The author argues that ""efficient autonomous updates"" will only be possible when the IDE can prove that the AI's alteration did not break anything, without relying solely on running 1000 tests that might be flawed.",,,,,,,43 - 46,"Marron, Mark",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202433134&doi=10.1145%2F3643796.3648452&partnerID=40&md5=a3b21d5959d1802461780485e0036d84,,,,,Cited by: 0; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access,10.1145/3643796.3648452,Computer debugging; Intelligent agents; Software testing; AI assisted programming; Automated tool...,,,2406.09577v1.pdf
rayyan-394626774,Coverage-based Strategies for the Automated Synthesis of Test Scenarios for Conversational Agents,2024,Test Scenario Generation (Conversation Flow Testing) for Task-Oriented Chatbots. Definition of Coverage Criteria.,N/A (Does not use GenAI). Uses deterministic graph traversal and parameter combination algorithms.,Asymob (Model-Driven Engineering based tool). Integrates with Botium for execution. Uses the neutral language CONGA.,"The tool performs static analysis of the chatbot design (intents, flows) and synthesizes test scripts for Botium ensuring coverage criteria (Path coverage, Intent coverage). Proposes test reduction strategies (""Factoring"", ""Single-literal"") to optimize execution time without losing significant coverage.","Academic (AST 2024). Evaluated on 6 open-source agents (Dialogflow and Rasa). The exhaustive strategy guaranteed 100% coverage and correctness (all tests passed), outperforming the industrial tool Botium Crawler. Reduction strategies decreased execution time by up to 96%.","Model Dependency: Requires access to the internal specification of the bot design (White-box/Grey-box), not working in pure black-box without prior conversion. Scalability: The exhaustive strategy generates thousands of test cases, making execution slow (>6h).","Control/Baseline Article. Useful for your review as a counterpoint: shows how to generate tests autonomously without AI, focusing on rigorous coverage metrics that are often lacking in LLM approaches. ""Test suite reduction is one of the open challenges... we propose strategies... oriented to test case reduction"".",,,,,,,23 - 33,"Cañizares, Pablo C. and Ávila, Daniel and Perez-Soler, Sara and Guerra, Esther and Lara, Juan De",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196398493&doi=10.1145%2F3644032.3644456&partnerID=40&md5=1a07cb9731740db2bace5b78bda5d552,,,,,Cited by: 5; All Open Access; Gold Open Access,10.1145/3644032.3644456,Open source software; Software agents; Software testing; Automated synthesis; Chatbots; Conversat...,,,3644032.3644456.pdf
rayyan-394626779,Unit Test Generation Multi-Agent AI System for Enhancing Software Documentation and Code Coverage,2024,Unit Test Generation and Documentation Generation (User Stories). The approach connects requirements documentation (BDD) directly to test creation to ensure functional coverage.,"ChatGPT-4o-mini (OpenAI). The study explicitly chose this ""mini"" model with zero temperature to maximize cost efficiency and determinism.","AutoGen (Microsoft). ""Triple-Agent"" architecture composed of: 1. User Story Writer Agent: Creates Gherkin scenarios. 2. Unit Test Writer Agent: Writes test code (Python unittest) based on the stories. 3. Code Executor Agent: Runs the tests in a safe environment and provides error traceback as feedback.","BDD Flow with Feedback Loop: Unlike generating the test directly from the code (""Code-to-Test""), the system does: Code -> User Story (BDD) -> Unit Test. The inclusion of the intermediate User Stories step forces the model to ""explain"" the behavior before testing, helping to identify edge cases. If the test fails in execution, the Unit Test Agent receives the error and autonomously corrects the code.","Academic Maturity (Experiment on Standard Dataset). Scenario: 100 problems from the MBPP (Mostly Basic Python Problems) dataset that had low coverage. Results: Average Branch Coverage increased from 67% to 83%. The success rate (Pass Rate) of the generated tests was 85%. Efficiency: Total cost of less than $0.20 USD to generate tests for 100 programs, executing in less than 5 minutes.","Reliability (Pass Rate < 100%): 15% of tests failed or generated errors (including an infinite loop case). Dataset Complexity: MBPP contains simple/algorithmic problems. The article did not evaluate performance in complex enterprise systems with external dependencies. Absence of Human: The lack of human supervision prevented the correction of subtle errors where the model ""confused built-in functions"".","Efficiency vs. Cost: This article is the best evidence for your thesis that ""Efficiency"" does not require supercomputers. With an intelligent architecture (Agents + BDD), low-cost models outperform simple test generation. Correction Autonomy: The autonomous feedback loop corrected most syntactic errors without human intervention, demonstrating Self-Healing at development time.",,,,,,,,"Stojanovic, Dimitrije and Pavković, Bogdan and Četić, Nenad B. and Krunić, Momčilo V. and Vidakovic, Luka",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216854650&doi=10.1109%2FTELFOR63250.2024.10819096&partnerID=40&md5=590d88c939c87c1b052534a891819d4c,,,,,Cited by: 1,10.1109/TELFOR63250.2024.10819096,Distribution transformers; Electric transformer testing; Model checking; Problem oriented languag...,,,Unit_Test_Generation_Multi-Agent_AI_System_for_Enhancing_Software_Documentation_and_Code_Coverage.pdf
rayyan-394626782,Automated test generation to evaluate tool-augmented LLMs as conversational AI agents,2024,Test generation pipeline. Scenario generation using intermediate graphs. Ablation study. Functional testing using the ALMITA dataset. Benchmarking.,"GPT-4, GPT-4o, Claude 3 Sonnet, Mistral-NeMo-Instruct, Llama 3.1-8B-Instruct.","The article proposes a framework to generate evaluation datasets for tool-augmented LLMs as conversational AI agents, using intermediate graph structures to improve test quality and coverage. It does not specify a specific software framework or agent architecture like LangChain, LangGraph, or AutoGen.",Generation of tests for Customer Support scenarios using graph representations to structure conversations and test the agents' tool invocations (APIs).,"Evaluation method: Benchmarking of various LLMs on the ALMITA dataset, evaluating performance in customer support scenarios. Evaluated dimensions: Response retrieval, correct response, API retrieval, correct API, correct API parameters, test correctness, and conversation correctness. Key findings: LLMs perform well in single interactions but struggle with full conversations.",Lack of quantitative evaluation of test diversity. Limited number of human annotations. Use of a single LLM (GPT-4) for test generation. Evaluation of multiple LLMs using a single prompt. Metrics can be too rigid. Need for more advanced conversational metrics to handle response variations. Current LLMs struggle to maintain correct conversations during user interactions.,"The study presents a novel method for generating evaluation datasets for tool-augmented LLMs as conversational AI agents, highlighting that while these models perform well in single interactions, they struggle to handle complete conversations.",,,,,,,54 - 68,"Arcadinho, Samuel and Aparício, David and Almeida, Mariana S.C.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216591803&partnerID=40&md5=eeb0044155d867548dffcb3f87a276bb,,,,,Cited by: 0,,Automatic test pattern generation; Computational linguistics; Am generals; Automated test generat...,,,Automated test generation to evaluate tool-augmented LLMs as conversational AI agents_ZLU.pdf
rayyan-394626784,RGD: Multi-LLM Based Agent Debugger via Refinement and Generation Guidance,2024,Code Generation & Debugging. Iterative Code Refinement. Failure Analysis.,GPT-4o GPT-4o-mini,"RGD (Refinement and Guidance Debugging). Multi-Agent Architecture with 3 roles: Guide Agent, Debug Agent, Feedback Agent.","Uses a Guide Agent that generates a ""plan"" (guide) before coding and retrieves guides for similar tasks from a Memory Pool (RAG). The Feedback Agent analyzes not only the error but also why the tests passed, to prevent regression. The Debug Agent corrects the code based on these instructions.","High (IEEE/arXiv 2024). Evaluated on standard benchmarks: HumanEval, MBPP, and their extended versions (ET). RGD (with GPT-4o) achieved 97.6% accuracy (Pass@1) on HumanEval, outperforming the state-of-the-art (LDB) and Self-Debugging methods (+9.8% vs Baseline). Ablation showed that removing the Guide Agent reduces accuracy by 4-6%.",Computational Cost: The multi-agent architecture with RAG and feedback iterations consumes many tokens and time. Test Case Dependency: Effectiveness depends on the quality of visible tests provided in the prompt.,"""RGD decomposes the code generation task... enabling iterative refinement based on self-reflection and feedback."" Highlights the use of a Memory Pool to store past ""success guides,"" learning from experience.",,,,,,,136 - 141,"Jin, Haolin and Sun, Zechao and Chen, Huaming",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215607472&doi=10.1109%2FICA63002.2024.00037&partnerID=40&md5=bad4ee6cce20c207147b12cb02bf5210,,,,,Cited by: 0,10.1109/ICA63002.2024.00037,Automatic programming; Autonomous agents; Behavioral research; Computer debugging; Error correcti...,,,RGD_MultiLLM_Based_Agent_Debugger_via.pdf
rayyan-394626785,Test-Agent: A Multimodal App Automation Testing Framework Based on the Large Language Model,2024,"Mobile App Automation Testing (Android, iOS, HarmonyOS). GUI Testing. Generation and Execution of Test Cases from Natural Language.","Unspecified LLM (referred to generically as ""Large Language Model"" and ""ChatGPT"" in diagrams). Integrates Deep Learning (DQN) and Computer Vision models.","Test-Agent (Multimodal Framework). Modules: Visual Perception, Interaction Analysis, Test Execution. Uses ADB for execution.","The framework eliminates pre-written scripts. The user provides a natural language instruction (e.g., ""login""). The agent captures the screen (screenshot), uses Computer Vision (OCR/Edge Detection) to identify elements, and the LLM/Agent plans the action (click/input). Uses Reinforcement Learning (DQN) to optimize the action sequence.","Academic PoC (IEEE DTPI 2024). Evaluated on 7 real devices (Pixel, iPhone, Huawei) and simulators. Compared with Appium, Espresso, and XCUITest. Reduced test creation time from ~3 hours (Appium) to 0.1 hours. Achieved a 96-97% success rate in tasks like login and shopping.","Latency Dependency: Visual processing + LLM inference at each step can be slower than native scripts (although the article focuses on creation efficiency). Generalization: Evaluated on standard apps (e-commerce, social); apps with non-standard UIs (games) can be challenging.","""This innovative approach eliminates the need for pre-written test scripts... relying solely on screenshots... significantly reducing the workload of writing test cases."" Highlight for the Multimodal approach (Vision + Text).",,,,,,,609 - 614,"Li, Youwei and Li, Yangyang and Yang, Yangzhao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214923908&doi=10.1109%2FDTPI61353.2024.10778901&partnerID=40&md5=2df3aabdcab54e9e039471ef43a47e60,,,,,Cited by: 2,10.1109/DTPI61353.2024.10778901,Application programs; Computer debugging; Computer operating systems; Mobile agents; Model checki...,,,Test_Agent_A_Multimodal_App_Automation_Testing_Framework_Based_on_the_Large_Language_Model.pdf
rayyan-394626787,Fight Fire With Fire: How Much Can We Trust ChatGPT on Source Code-Related Tasks?,2024,"Code Self-Verification, Test Report Generation, and Security Validation. The study evaluates whether AI can act as ""Developer"" and ""Tester"" simultaneously to verify Code Generation, Code Completion, and Bug Repair.",GPT-3.5-turbo (Main experiments) and GPT-4 (Smaller scale validation). API access via OpenAI.,"Multi-Agent Collaboration Simulation (Conceptual). Tested three prompting strategies to simulate the ""Tester Agent"": 1. Direct Question (DQ): Direct question (""Is this code correct?""). 2. Guiding Question (GQ): Inductive question (""Do you agree there is an X error?""). 3. Test Report (TR): Requests the generation of a complete test report.","Self-Correction Loop: The model generates the code (Developer role) and is then fed with its own code to check for errors or vulnerabilities (Tester role). The study investigates whether ""fighting fire with fire"" (using AI to test AI) works in practice.","Rigorous Empirical Study (Datasets: HumanEval, MBXP, QuixBugs). - Autonomy Failure: ChatGPT failed to identify its own errors in 39% of code generation cases and 28% of repairs. - Test Reports: The use of Test Reports helped identify 77% more security vulnerabilities, but the textual explanations about why the code was wrong were inaccurate in 75% of cases.","Self-Contradictory Hallucinations: The model frequently suffers from logical inconsistency (e.g., generates code claiming it is safe, but in the verification step says it is vulnerable, or vice versa). Sycophancy (Agreement Bias): In the Guiding Question strategy, the model tends to agree with the human (or prompt) that there is an error, even if the code is correct (increasing False Positives).","Blow to Total Autonomy: The article categorically concludes that ""ChatGPT should be viewed as an assistive tool, rather than a replacement for autonomous developers and testers."" Oracle Inaccuracy: For your thesis, this proves that Pure LLM Test Agents (without real code execution/sandbox) are unreliable as oracles, as AI cannot reliably distinguish between a real bug and a hallucination.",,,IEEE Transactions on Software Engineering,,50,12,3435 - 3453,"Yu, Xiao and Liu, Lei and Hu, Xing and Keung, Jacky Wai and Liu, Jin and Xia, Xin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208721822&doi=10.1109%2FTSE.2024.3492204&partnerID=40&md5=11df2cbefd5bdd1d5eed10afaaccef29,,,,,Cited by: 2,10.1109/TSE.2024.3492204,C (programming language); Chatbots; Computer debugging; Computer software maintenance; Computer s...,,,Fight_Fire_With_Fire_How_Much_Can_We_Trust_ChatGPT_on_Source_CodeRelated_Tasks.pdf
rayyan-394626789,Extending the Frontier of ChatGPT: Code Generation and Debugging,2024,"Code Generation (Solutions) and Automated Debugging/Repair. The study evaluates AI's ability to pass ""acceptance tests"" (LeetCode test cases) and to fix the code when it fails.","ChatGPT (The article mentions ChatGPT is ""powered by GPT-4"" in the introduction, but the experiments reflect the use of the conversational interface available in May 2023).","Direct Interactive Prompting. Did not use agent frameworks (like LangChain). The method was: Prompt with the problem -> Generation -> Test on LeetCode -> If it fails, new Prompt with the error message (Simple Feedback Loop).","Human-Machine Feedback Loop: 1. Generation: The problem (description + code structure) is sent to the chat. 2. Validation: The code is submitted to LeetCode. 3. Debugging: If an error occurs (Runtime Error, Time Limit Exceeded, or logical failure), the compiler error message is pasted back into the chat to request a fix.","Empirical Academic Study. Scenario: 128 LeetCode problems (Easy, Medium, Hard) covering Trees, Graphs, DP, etc. - Initial Success Rate: 71.9% of the problems were solved correctly on the first try. - Debugging Success Rate: Only 36.7% of the initially failed problems were fixed after error feedback.","Self-Correction Failure: The model showed ""limited adaptability"" to feedback. Often, even after receiving the error, it could not fix the logic. Difficulty with Complexity: Worse performance on Dynamic Programming and Greedy Algorithms problems, where multi-step reasoning is required. Knowledge Cutoff: The model's knowledge was limited to pre-2021 data (at the time of the study).","Evolution of Autonomy: This paper is the perfect evidence that simple Prompting is not enough for autonomous maintenance. The fact that it only corrected 36% of errors shows the need for Agent architectures (seen in your other articles) that use external tools and RAG to improve this rate. Efficiency: The study also analyzed execution time and memory, noting that AI sometimes generates functionally correct but inefficient solutions (O(n²) vs O(n)).",,,,,,,,"Sakib, Fardin Ahsan and Khan, Saadat Hasan and Karim, A. H.M.Rezaul",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207460221&doi=10.1109%2FICECET61485.2024.10698405&partnerID=40&md5=9061172122ad4b9fa410d2c10d273c63,,,,,Cited by: 8,10.1109/ICECET61485.2024.10698405,Acceptance tests; Computer debugging; Program debugging; Structured programming; ChatGPT; Code de...,,,Extending the Frontier of ChatGPT_ Code Generation and Debugging.pdf
rayyan-394626790,"PENTEST-AI, an LLM-Powered Multi-Agents Framework for Penetration Testing Automation Leveraging Mitre Attack",2024,"Penetration Testing Automation (Pentesting) covering the phases of Pre-exploitation (Reconnaissance, Resource Development), Exploitation (Vulnerability Validation, Exploit Simulation), Post-exploitation, and Reporting.","GPT-4.0 (used in the Proof of Concept). The theoretical framework proposes the use of specialized/finetuned models (e.g., SecurityBERT, CyBERT, Falcon LLM) through an ""LLM Registry"".","PENTESTAI (Proposed framework) implemented using CrewAI (which is based on LangChain). Multi-Agent Architecture composed of worker agents (Scan & Search, Exploit Validation, Exploit Simulation, Post-Exploitation, Reporting, Detection) and control agents (Configuration, Saga Controller, Zookeeper).","Implementation of autonomous agents that use customized Python tools (e.g., ScanAndSearchTool, ExploitValidationTool based on Nmap) to execute actions. Orchestration is done via CrewAI, where agents receive natural language instructions to analyze JSON files and generate reports. The test environment was deployed on AWS (EC2) against public targets.","Proof of Concept (PoC). A simplified flow with 3 agents (Scan, Validation, Reporting) was implemented, which validated the core concepts and the ability of GPT-4.0 to generate correct security recommendations without customized reporting tools.","Hallucinations: GPT-4.0 generated hallucinations in some results during tests. Tool Coverage: Need to develop libraries to cover the ~405 MITRE ATT&CK techniques. Zero-day: The current framework does not discover zero-day vulnerabilities (would require a Reverse Engineering agent). Partial Implementation: The ""Control Plane"" described in the architecture was not implemented in the PoC.","The article proposes an autonomy level of ""User-Guided Adaptation"" to ensure alignment with human goals. The approach aims to mitigate the shortage of qualified cybersecurity professionals, enabling ""citizen penetration testers"".",,,,,,,763 - 770,"Bianou, Stanislas G. and Batogna, Rodrigue G.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206186144&doi=10.1109%2FCSR61664.2024.10679480&partnerID=40&md5=31791a7ca25673d064f6b1d90e42bb04,,,,,Cited by: 10,10.1109/CSR61664.2024.10679480,Model checking; Multi agent systems; AI agent; Citizen penetration tester; Cyber security; Langua...,,,PENTEST-AI_an_LLM-Powered_Multi-Agents_Framework_for_Penetration_Testing_Automation_Leveraging_Mitre_Attack.pdf
rayyan-394626795,CODEAGENT: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges,2024,"Repo-level Code Generation & Verification. The framework integrates ""Code Testing"" as a fundamental step, where the agent generates test cases and uses a Code Interpreter to execute the code and validate functional correctness (Self-debugging based on execution feedback). It also includes format verification (linting).","GPT-4, GPT-3.5-Turbo, Claude-2, Llama 2 (70B), Code Llama (34B), WizardCoder, DeepSeekCoder, Vicuna-13B. The main focus of the agent was with the GPT family models.","CODEAGENT. An LLM-based agent framework that integrates 5 external tools. The implementation uses the LangChain library. The agent employs planning and execution strategies (ReAct, Tool-Planning, OpenAIFunc, and Rule-based) to orchestrate the use of tools.",Information Retrieval: WebSearch (DuckDuckGo) and DocSearch (BM25). Implementation: SymbolSearch (Code navigation via Tree-sitter). Code Testing: FormatCheck (Black) and PythonREPL (Interpreter for execution and testing).,"Custom Experiment/Benchmark. The authors created CODEAGENTBENCH (101 tasks extracted from 5 real Python repositories: numpy-ml, tinydb, etc.). Used the Pass@1 metric. Results: CODEAGENT improved Pass@1 between 2.0% and 15.8% compared to LLMs without agents. Comparison: Outperformed GitHub Copilot in accuracy in the tests conducted.","Model Capability: Smaller or less capable models (like Vicuna-13B) could not leverage the tools, showing poor performance even with the framework. Planning Strategy: The ""Tool-Planning"" strategy (planning before execution) proved less effective than more direct approaches like Rule-based or ReAct for this type of task. Evaluations were limited by available computational resources.","""To the best of our knowledge, CODEAGENT is the first agent framework specifically for repo-level code generation."" The study highlights that over 70% of functions in open-source projects are not ""standalone"", justifying the need for agents that understand the entire repository context, something previous tools failed to do.",,,Proceedings of the Annual Meeting of the Association for Computational Linguistics,,1,,13643 - 13658,"Zhang, Kechi and Li, Jia and LI, Ge and Shi, Xianjie and Jin, Zhi",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204422336&doi=10.18653%2Fv1%2F2024.acl-long.737&partnerID=40&md5=99fd7c9dd58ad15390110ca57961ce7c,,,,,Cited by: 3,10.18653/v1/2024.acl-long.737,Autonomous agents; Benchmarking; Computational linguistics; Intelligent agents; Search engines; S...,,,CODEAGENT Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges_aeu.pdf
rayyan-394626796,Towards LLM-Assisted System Testing for Microservices,2024,"End-to-End System Testing (Black-box System Testing) for Microservices-based applications. The focus is on validating complete functionalities (e.g., ""add item to cart"") through web interface interaction, without backend access.","GPT-4 (Best performance) and GPT-3.5-turbo. Also tested CodeLlama, but it systematically failed due to ethical refusals (the model interpreted the testing commands as attacks/hacking).",Kashef (Communicative Agents-based tool). Multi-Agent Architecture with defined roles: 1. Test Engineer (TE): Generates automation code (Python/Selenium). 2. Code Executor (CE): Executes the code in a sandbox environment. 3. HTML Interpreter (HI): Analyzes the returned HTML to verify if the page state changed as expected (oracle verification).,"Collaboration and Self-Correction: 1. User provides a task prompt (e.g., ""Test checkout on site X""). 2. TE generates the script. 3. CE executes. If it fails (e.g., CSS selector error), the error returns to TE for regeneration (Feedback Loop). 4. If it runs, HI analyzes the visual/HTML result to confirm the business test success.","Academic Maturity (Work in Progress/Short Paper). Scenario: 4 web applications (including E-commerce and Pastebin). - GPT-4: 100% success rate on simple tasks, but dropped to 30% on complex e-commerce flows. - GPT-3.5: Failed almost all complex tasks (0% success in e-commerce), unable to handle long HTML contexts.","Ethical Refusals (Safety Filters): CodeLlama refused to generate test scripts, classifying them as ""malicious activities,"" which is a real barrier to using open-source models in security/penetration testing. Context Window: GPT-3.5 got lost trying to process the full page HTML for verification. Stability: Even with GPT-4, the tool required multiple code regenerations to get dynamic selectors right.","Evaluation Challenge: The article highlights the difficulty of creating a reliable ""Oracle"" in system testing. Kashef's innovation was using a dedicated agent (HTML Interpreter) just to read the screen and determine if the test passed, rather than relying solely on code assertions. Microservices Architecture: Emphasizes that in microservices, unit tests are not enough; the complexity lies in integration, and autonomous agents are promising for covering this E2E testing gap that is currently done manually.",,,,,,,29 - 34,"Almutawa, Mustafa and Ghabrah, Qusai and Canini, Marco",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204295455&doi=10.1109%2FICDCSW63686.2024.00011&partnerID=40&md5=c288614757b12066e8a8ed4ab7ec145e,,,,,Cited by: 2,10.1109/ICDCSW63686.2024.00011,Ability testing; Autonomous agents; Black-box testing; Computer debugging; Computer software sele...,,,Towards_LLMAssisted_System_Testing_for_Microservices.pdf
rayyan-394626798,Intent-Driven Mobile GUI Testing with Autonomous Large Language Model Agents,2024,"Mobile GUI Testing (Android) focusing on ""Intent-Driven Testing"". The system autonomously generates and executes high-level test scenarios (e.g., ""create a second account and add the first as a friend"") instead of just exploring screens randomly.",GPT-3.5 (used mainly by the Actor agent for action selection) and GPT-4 (used for the Self-critique mechanism and more complex planning tasks).,"DROIDAGENT. An autonomous agent architecture composed of four main modules: Planner (task planner), Actor (action executor), Observer (state observer), and Reflector (reflection and memory). Implemented using LangChain and ChromaDB (for vector database memory).","The framework operates through multi-agent collaboration: Planner: Defines natural language test goals based on history and a ""Persona"" (e.g., user ""Jade Green""). Memory: Uses three types: Short (immediate context), Long (task history and reflections), and Spatial (knowledge about specific widgets). Execution: The Actor agent uses function calling to interact with the app (via ADB) [...] Feedback: Includes a Self-critique loop where GPT-4 analyzes if the agent is ""stuck"" and suggests workarounds.","Comparative Experiment. Evaluated on 15 Android applications (from Themis and F-Droid benchmarks). Comparison: DroidBot, Humanoid, Monkey, and GPTDroid. Results: DROIDAGENT achieved 61% activity coverage (surpassing the 51% state-of-the-art). Generated 374 unique tasks, of which 85% were considered relevant and 59% were successfully completed.","Visual Representation: The agent relies on a textual representation (JSON) of the widget hierarchy, which may lose purely visual nuances of the interface. Cost and Latency: The use of multiple agents and frequent calls to models like GPT-4 implies higher operational costs and execution time. API Dependency: The exclusion of some apps from the original benchmark was due to deprecated servers, indicating the fragility of testing apps dependent on a live backend.","""To the best of our knowledge, DROIDAGENT is the first Android GUI testing technique that can automatically generate high level testing scenarios based on sequences of identified tasks."" The study is motivated by the fact that developers prefer tests that cover specific functionalities (""usage model"") rather than blind structural coverage metrics.",,,,,,,129 - 139,"Yoon, Juyeon and Feldt, Robert and Yoo, Shin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203242246&doi=10.1109%2FICST60714.2024.00020&partnerID=40&md5=da75e662900ea316debff970ce334a1b,,,,,Cited by: 14,10.1109/ICST60714.2024.00020,Autonomous agents; Benchmarking; Graphical user interfaces; High level languages; Mobile agents; ...,,,Intent-Driven Mobile GUI Testing with Autonomous Large Language Model Agents.pdf
rayyan-394626800,A Generative Adversarial Imitation Learning Method for Continuous Integration Testing,2024,Test Case Prioritization (TCP) in Continuous Integration (CI) environments. The focus is to order tests to detect failures as early as possible.,"GAN (Generative Adversarial Networks) used within a GAIL (Generative Adversarial Imitation Learning) approach. The ""Generator"" uses the PPO (Proximal Policy Optimization) Reinforcement Learning algorithm. This article uses GenAI in the sense of adversarial networks for imitation learning, differing from the text-focused LLMs present in the other articles.","GAIL-based TCP. The system acts as an agent that learns an ordering policy (Generator) by trying to fool a discriminator that distinguishes between the agent's ordering and the ""expert experience"".","Imitation Learning: Unlike traditional Reinforcement Learning, the agent does not rely on a manual reward function (difficult to design and prone to sparsity); it learns directly from ""expert experience"" derived from optimal orderings of past CI cycles. Ranking Strategy: Uses the Copeland Method for pairwise ranking to determine the final order. Features: The model receives tuples containing execution verdict, time, history, and cycle count.","Datasets: Evaluated on 6 industrial datasets (Apache Drill, IOF/ROL, Paint Control, Compress, IO, Math). Metrics: APFD (Average Percentage of Faults Detected) and a newly proposed metric APFDET (based on execution time). Results: Outperformed traditional RL-based methods in 5 out of 6 datasets in terms of fault detection capability.","Computational Cost: Training and prioritization time is higher than traditional RL methods (although the difference is only a few seconds). Data Sensitivity: Performance varies depending on the dataset (e.g., in the IOF/ROL project, the improvement was less significant). Hyperparameters: Need to tune hyperparameters of the RL/GAN algorithms.","""Designing a proper reward function is challenging... GAIL allows agents to learn directly from the expert experience rather than through potentially biased reward functions."" The article tackles the ""sparse rewards"" problem common in industrial testing where the failure rate is very low (e.g., 0.01%).",,,,,,,1084 - 1089,"Huang, Luosen and Liu, Hengyuan and Liu, Yong and Shang, Ying and Li, Zheng",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199171129&doi=10.1109%2FAINIT61980.2024.10581812&partnerID=40&md5=8c4501d6057031be3cb889fffcbf208b,,,,,Cited by: 2,10.1109/AINIT61980.2024.10581812,Efficiency; Failure analysis; Integration; Integration testing; Learning systems; Reinforcement l...,,,A_Generative_Adversarial_Imitation_Learning_Method_for_Continuous_Integration_Testing_tVU.pdf
rayyan-394626802,ChatDev: Communicative Agents for Software Development,2024,"Code review (static testing), System testing (dynamic testing), Error resolution: ModuleNotFound, NameError, ImportError. Communicative de-hallucination mechanism to resolve coding hallucinations.",ChatGPT-3.5,ChatDev,"Software development, specifically integrating multiple phases of the software development life cycle through cooperative communication between different roles.","Evaluation metrics: Completeness, Executability, Consistency, Quality. Performance comparison: ChatDev outperforms GPT-Engineer and MetaGPT. Human evaluation: ChatDev preferred over other methods. Evaluation strategy: Divide software development into smaller subtasks and evaluate quality based on metrics.","Autonomous agents' capabilities in software production may be overestimated, as they often implement simple logic and face unclear requirements. Automating the evaluation of general-purpose software is highly complex and impractical for large datasets. Multiple agents require more tokens and time, increasing computational demands and environmental impact. Future research should consider additional factors like functionalities, robustness, security, and usability. Future research should aim to enhance agent capabilities with fewer interactions.","The study presents ChatDev, a chat-powered software development framework that uses linguistic communication to integrate fragmented phases of the waterfall model, demonstrating better software quality through multi-turn communications between LLM agents.",,,Proceedings of the Annual Meeting of the Association for Computational Linguistics,,1,,15174 - 15186,"Qian, Chen and Liu, Wei and Liu, Hongzhang and Chen, Nuo and Dang, Yufan and Li, Jiahao and Yang, Cheng and Chen, Weize and Su, Yusheng and Cong, Xin and Xu, Juyuan and Li, Dahai and Liu, Zhiyuan and Sun, Maosong",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197091676&doi=10.18653%2Fv1%2F2024.acl-long.810&partnerID=40&md5=c71c0c92f0115ee34a983a62e5d9a761,,,,,Cited by: 75,10.18653/v1/2024.acl-long.810,Autonomous agents; Computational linguistics; Computer debugging; Program debugging; Software des...,,,ChatDev Communicative Agents for Software Development_Xyw.pdf
rayyan-394626805,Cloud-Based System for Source Code Analysis of Microservices with LLM Agents,2024,"Static Code Analysis focused on microservices. Includes specific activities of: Code Review: Identification of bugs and areas for improvement. Reliability Verification: Analysis of fault tolerance, resilience, and error handling. System Design Evaluation: Verification of architectural patterns, modularity, and scalability.",GPT-4o (referred to as GPT-4.0/4o in the text) used for inference. Also uses OpenAI embedding models.,Custom Cloud Architecture with 5 Specialized Agents: 1. Code Summarizer Agent 2. Code Reviewer Agent 3. Reliability Reviewer Agent 4. Code Search Agent 5. System Design Agent. Uses Neo4j (Graph Database) to store code relationships and MongoDB Atlas for vector search.,"The system operates in an event-driven architecture, integrated into the CI/CD flow (triggered via Git Push Webhooks). Uses RAG (Retrieval-Augmented Generation) combining vector base and graph base to provide context to the agents. The agents analyze individual modules (files) and their relationships, generating reports accessible via Web UI.","Proof of Concept (PoC) / Prototype Validated through tests simulated locally (Apple M1) and deployed in the cloud (Microsoft Azure). Case study conducted with a user-developed Node.js microservice (""Microservice 1""). Metrics focused on scalability, latency, and usability.","Human Validation: Results still require manual verification by a developer to validate correctness and integrate suggestions. Cost and Performance: The article notes that the choice of LLM directly impacts quality, inference speed, and operational costs. Context Dependency: Although better than traditional static analysis, it depends on the quality of indexed data in the graph/vector to avoid false positives.","""The combination of LLM agents and cloud technologies offers scalability that sets the stage for future innovations in automated code analysis."" The system proposes to solve the complexity of analyzing distributed microservices, where traditional tools fail due to a lack of full system context.",,,International Scientific and Technical Conference on Computer Sciences and Information Technologies,,,,,"Chaplia, Oleh and Klym, Halyna I.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005826698&doi=10.1109%2FCSIT65290.2024.10982613&partnerID=40&md5=aa79d5bead960eeab495f82530874986,,,,,Cited by: 0,10.1109/CSIT65290.2024.10982613,Computer operating systems; Computer software maintenance; Software design; Software prototyping;...,,,Cloud-Based_System_for_Source_Code_Analysis_of_Microservices_with_LLM_Agents.pdf
rayyan-394626808,AI-Powered Multi-Agent Framework for Automated Unit Test Case Generation: Enhancing Software Quality through LLM's,2024,"Unit Test Case Generation (Java) and Code Refinement. The system not only generates tests but also rewrites the original source code if it finds flaws (e.g., missing exception handling for division by zero).",Mistral-Large. The article explicitly cites the use of this model for evaluation and generation in the experiments.,"LangGraph (Implicitly described as a graph flow). Cyclic ""Dual-Agent"" architecture: 1. Reviewer Agent: Analyzes Java code looking for logical flaws, standard violations, and missing edge cases. 2. Coder Agent: Rewrites the code and generates tests based on the Reviewer's feedback. 3. Decision Making Agent: Validates if the final code meets quality criteria.","Simulated Peer Review Flow: The process imitates two human engineers working together. The Reviewer critiques (""You forgot the negative test for the sum"") and the Coder fixes it. Differential: The system operates in a loop until the Reviewer is satisfied, ensuring the final code is robust.","Proof of Concept (PoC). Scenario: Isolated Java classes (e.g., Sample1.java with mathematical operations). Results: Achieved 100% code coverage in the tested examples, demonstrating the ability to handle edge cases (like negative numbers and exceptions) that traditional frameworks often miss.","Limited Scope: The evaluation was done on simple example codes (""Toy examples""), not on complex legacy systems. Loop Cost: The iterative process (Reviewer <-> Coder) consumes more tokens and time than direct generation (Zero-shot).","""Self-Healing"" Autonomy: This article is crucial for your ""Autonomous Updates"" theme. It shows that efficiency comes from removing the human from the initial review loop, letting specialized agents debate among themselves to clear obvious errors before final validation.",,,,,,,,"Garlapati, Anusha and Parmesh, M. N.V.Satya Sai Muni and Savitha, null and Jaisri, S.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002210499&doi=10.1109%2FGCAT62922.2024.10923987&partnerID=40&md5=5ab5972bdb1effde4abdc467aec1d3bb,,,,,Cited by: 0,10.1109/GCAT62922.2024.10923987,Application programs; Automatic test pattern generation; Computer software selection and evaluati...,,,AI-Powered_Multi-Agent_Framework_for_Automated_Unit_Test_Case_Generation_Enhancing_Software_Quality_through_LLMs.pdf
rayyan-394626813,SWT-Bench: Testing and Validating Real-World Bug-Fixes with Code Agents,2024,"Test Generation for Issue Reproduction and Bug-Fix Validation. The main goal is to generate test cases that formalize a natural language issue description, ensuring the test fails on the original code and passes after the fix ($F \rightarrow P$).",GPT-4 (main model). Claude 3 Opus (mentioned in the SWE-Agent context).,"SWT-BENCH (Evaluation framework). Evaluates agents such as SWE-AGENT, SWE-AGENT+, AutoCodeRover, and Aider. Includes an Agent Computer Interface (ACI) for navigation and command execution.","Agents receive a GitHub Issue description and the repository. They use tools to navigate, read files, and execute commands (e.g., pytest) to create a reproduction test. SWE-AGENT+ uses specific testing tools and reproduction-focused prompts.","Dataset: 1,900 real-world issue instances from 12 Python repositories (Django, Flask, etc.). Results: SWE-AGENT+ solved 51 instances. Using generated tests to filter fixes doubled agent precision from ~20% to 47.8%.",Language: Limited to Python. Data Contamination: Risk of GPT-4 having seen solutions during training (Knowledge Cutoff). Agent Errors: Generating tests that pass without reproducing the bug or getting stuck in loops.,The study highlights that reproducing an issue via testing and fixing it are distinct tasks. Generated tests are valuable formal specifications for validating automated fixes.,,,Advances in Neural Information Processing Systems,,37,,,"Mündler, Niels and Müller, Mark Niklas and He, Jingxuan and Vechev, Martin T.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000529637&partnerID=40&md5=64830080c1fd8ab3a15e5f855dd9811b,,,,,Cited by: 2,,,,,SWT-Bench Testing and Validating Real-World Bug-Fixes with Code Agents_Yuz.pdf
rayyan-394626820,Meet C4SE: Your New Collaborator for Software Engineering Tasks,2023,"Generation of Unit and Acceptance Tests, Code Suggestion, Code Review, and GitHub Task Execution (via API).",GPT-3.5.,C4SE (Open-Source Proprietary Framework). Architecture based on LangChain (orchestration) and Pinecone (Vector Database for long-term memory).,Conversational Agent with Memory: 1. User interacts via chat. 2. BL Manager triggers a specialized agent. 3. Consults Vector DB to retrieve past conversation contexts (RAG). 4. The agent generates the test or code using the augmented context.,Proof of Concept / Preliminary Study. Study with participants performing 4 tasks (generating unit and acceptance tests for GitHub cases). Preliminary results report increased productivity without robust quantitative metrics.,Fixed Scope: Limited to pre-defined tasks. Language: Currently supports only English. Validation: Requires studies with larger samples to prove real industrial effectiveness.,"Persistent Memory: Use of Vector Databases resolves the ""Context Loss"" problem. Agents without memory cannot maintain tests consistently throughout long-term projects.",,,,,,,235 - 238,"De Vito, Gabriele and Lambiase, Stefano and Palomba, Fabio and Ferrucci, Filomena",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183322950&doi=10.1109%2FSEAA60479.2023.00044&partnerID=40&md5=ade60021c71ddbad55702599f7a6f037,,,,,Cited by: 7,10.1109/SEAA60479.2023.00044,Life cycle; Software agents; Software design; Automated tasks; Chatbots; Conversational agents; D...,,,Meet_C4SE_Your_New_Collaborator_for_Software_Engineering_Tasks.pdf
rayyan-394626822,Towards Autonomous Testing Agents via Conversational Large Language Models,2023,"Conversational Testing. Focus on Human-AI collaboration for specification clarification, test case generation (e.g., Julia), and edge case exploration.",GPT-4 (via ChatGPT interface).,SOCRATEST (Proposed Framework). Defines a 3-level taxonomy: 1. Conversational Testing (chat only); 2. With Tools (chat + compilers); 3. Agents (full autonomy via middleware).,"Socratic Dialogue: Human and AI debate specifications. The AI acts as a ""Junior Tester,"" whose questions or errors (hallucinations) force the human expert to refine and clarify software requirements.",Low (Theoretical Proposal + Illustrative Example). A foundational paper justifying the transition to autonomous agents using qualitative examples rather than quantitative metrics.,Planning: Difficulty in maintaining long-term plans. Cost: Training and inference for trivial tasks. Hallucinations: Dangerous if not verified by a human.,"Reframing Hallucinations: ""Hallucination can be beneficial for testing."" AI errors serve as mutations that validate specification robustness. The level taxonomy is ideal for organizing the review.",,,,,,,1688 - 1693,"Feldt, Robert and Kang, Sungmin and Yoon, Juyeon and Yoo, Shin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179005153&doi=10.1109%2FASE56229.2023.00148&partnerID=40&md5=a280bae3f3cc3d999608c16f706082cd,,,,,Cited by: 19,10.1109/ASE56229.2023.00148,Autonomous agents; Computational linguistics; Learning systems; Machine learning; Artificial inte...;test automation; Development cycle; Intelligence tests; Language model; Large language model; Lev...,,,2306.05152v2.pdf