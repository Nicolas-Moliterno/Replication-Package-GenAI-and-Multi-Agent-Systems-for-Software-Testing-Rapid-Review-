key,title,year,month,day,ReviewData,issn,volume,issue,pages,authors,url,language,publisher,location,abstract,notes,doi,keywords,pubmed_id,pmc_id,Coluna 1,Coluna 2,Coluna 3,Coluna 4,Coluna 5
rayyan-394626649,An Explainable Multimodal Framework with LLM Agents for Intracranial Hemorrhage Detection,2026,,,Lecture Notes in Computer Science,,16147,,3 - 12,"Punneshetty, Shashwath and Italiya, Dhyey and Agarwal, Vinti and Maurya, Chandresh Kumar and Agrawal, Amit",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018304220&doi=10.1007%2F978-3-032-06004-4_1&partnerID=40&md5=4d48ec079f845107d111d1e0cf5848df,,,,"Explainability in intracranial hemorrhage (ICH) diagnosis is essential for timely and accurate clinical decisions, especially in life–threatening situations. We propose a framework that generates explainable, clinically relevant text from 2D CT scans using two cooperative GPT-4o agents: a Multi-modal User Agent (MUA) and a Planner Agent. The MUA interprets scans with YOLOv10 (mosaic augmentation), SAM2, and clustering; the Planner selects tools and outputs key imaging parameters: bleed location, midline shift, calvarial fracture, and mass effect crucial for urgent interventions. Explainability is enforced via chain-of-thought prompting to ensure transparent decision-making. Experiments show YOLOv10 with mosaic improves mAP@0.5:0.95 by 4.1% over existing methods, and the LLM agents extract clinical parameters with 78.1% accuracy (Our code is available at https://github.com/Shashwathp/Explainable-ICH-Detection-with-LLM-Agents/tree/main). These results underscore the potential of explainable AI to enhance trust and reliability in critical healthcare applications. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Bronze Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1007/978-3-032-06004-4_1,Decision making; Diagnosis; Medical imaging; Multi agent systems; Clinical decision; Clusterings;...,,,,,,,
rayyan-394626650,"37th IFIP WG 6.1 International Conference on Testing Software and Systems, ICTSS 2025",2026,,,Lecture Notes in Computer Science,,16107,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017047520&partnerID=40&md5=9a7310659c70ac0771e3de5e5d83d0ae,,,,"The proceedings contain 23 papers. The special focus in this conference is on Testing Software and Systems. The topics include: Time for Quiescence: Modelling Quiescent Behaviour in Testing via Time-Outs in Timed Automata; On Using Homing Sequences Instead of Distinguishing in FSM-Based Testing; testability Indicators for Refactoring; enhancing Path Testing with Eye-Tracking: A Human-Centric Approach to Functional Software Testing; Introducing CreaTest: A Framework for Test Case Generation in itemis CREATE; distributed Critical Test Generation for Cyber-Physical Systems; reusable Test Suites for Reinforcement Learning; Test Generation for Deep Reinforcement Learning Using LRP-Guided Mutation of Classified Configurations; Test Amplification for REST APIs via Single and Multi-agent LLM Systems; reverse Engineering for Input Modeling: Input Parameter Model Inference from Network Traces; Automating Performance Testing in CI/CD - Tools Evaluation; automated Exploration of Conversational Agents for the Synthesis of Testing Profiles; Extracting Threats from System Descriptions with LLMs Comparing One and Two Agents Strategies; on the Evaluation of Test Suites Generated by Large Language Models; localization Testing in Video Games Using Text Recognition; assessing Test Scenarios for Autonomous Driving Using Probabilistic Model Checking; Passive Testing of Vehicular Embedded Systems: An Industrial Case Study with T-EARS and Napkin Studio; on the Use of Imbalanced Datasets for Learning-Based Vulnerability Detection; tracing Vulnerability Propagation Across Open Source Software Ecosystems; false Positive Detection in Instrumentation and Control System Testing; new Convex-Based Metamorphic Relations and Large-Scale Machine Learning Model Evaluation. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626651,Automated Exploration of Conversational Agents for the Synthesis of Testing Profiles,2026,,,Lecture Notes in Computer Science,,16107,,213 - 230,"del Horno, Iván Sotillo and del Pozzo, Alejandro and Guerra, Esther and Lara, Juan De",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016906206&doi=10.1007%2F978-3-032-05188-2_14&partnerID=40&md5=7ab6a470dadc58360f0451b30dfb7f38,,,,"Conversational agents – or chatbots – are increasingly being used to access all sorts of services, like citizen services in city halls, customer support, or shopping. Moreover, recent advances in generative artificial intelligence are prompting the integration of conversational assistants into many applications, like programming IDEs, office automation software, or operating systems. Given the prominence of these agents, their correctness is a rising concern. However, automated and robust testing techniques for conversational systems are still needed. In this paper, we present a technique for extracting a model of a deployed chatbot (i.e., treated as a black-box) through the automated exploration of its functionality via Large Language Models. This model is used for automated testing by generating testing conversation profiles, which a user simulator employs to conduct focused conversations with the chatbot-under-test. We describe our tool support, and report on an evaluation showing that our exploration technique can accurately model the chatbot-under-test, and the subsequent testing can discover existing errors in the chatbot. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.1007/978-3-032-05188-2_14,Black-box testing; Chatbots; Computer systems programming; Information systems; Intelligent agent...,,,,,,,
rayyan-394626652,Test Amplification for REST APIs via Single and Multi-agent LLM Systems,2026,,,Lecture Notes in Computer Science,,16107,,161 - 177,"Nooyens, Robbe and Bardakci, Tolgahan and Beyazit, Mutlu and Demeyer, Serge",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016905732&doi=10.1007%2F978-3-032-05188-2_11&partnerID=40&md5=99a684064135afb0a18884b210cdff0c,,,,"REST APIs (Representational State Transfer Application Programming Interfaces) play a vital role in modern cloud-native applications. As these APIs grow in complexity and scale, ensuring their correctness and robustness becomes increasingly important. Automated testing is essential for identifying hidden bugs, particularly those that appear in edge cases or under unexpected inputs. However, creating comprehensive and effective test suites for REST APIs is challenging and often demands significant effort. In this paper, we investigate the use of large language model (LLM) systems—both single-agent and multi-agent setups—for amplifying existing REST API test suites. These systems generate additional test cases that aim to push the boundaries of the API, uncovering behaviors that might otherwise go untested. We present a comparative evaluation of the two approaches across several dimensions, including test coverage, bug detection effectiveness, and practical considerations such as computational cost and energy usage. Our evaluation demonstrates increased API coverage, identification of numerous bugs in the API under test, and insights into the computational cost and energy consumption of both approaches. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1007/978-3-032-05188-2_11,Amplification; Application programming interfaces (API); Intelligent agents; Interface states; Mo...,,,,,,,
rayyan-394626653,Extracting Threats from System Descriptions with LLMs Comparing One and Two Agents Strategies,2026,,,Lecture Notes in Computer Science,,16107,,231 - 247,"Zelenskiy, Leonid and Sadovykh, Andrey",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016904785&doi=10.1007%2F978-3-032-05188-2_15&partnerID=40&md5=f99ae9370a58abd4366247580d9c8511,,,,"Effective cybersecurity testing relies on accurate threat identification to guide test design and risk mitigation. Threat modelling plays a central role in this process by helping analysts anticipate potential vulnerabilities. However, traditional threat modelling is a manual, time-consuming task that requires significant expertise, which can limit its scalability and integration into modern testing workflows. This study investigates the use of large language models (LLMs) to support and partially automate threat modelling, aiming to improve both the efficiency and coverage of cybersecurity testing. Using the STRIDE framework, we evaluate two workflows: a single-agent approach and a two-agent collaboration. We apply three LLMs—o1, o3, and Sonnet—to a curated dataset comprising 24 system descriptions and 745 known threats. The results show that LLMs can accelerate the generation of structured threat models and identify plausible threats, including some not explicitly listed in the validation data. While LLM outputs still lack the depth and reliability of expert-created models, their use can help testers identify key risks earlier and focus test efforts more effectively. These findings suggest that LLMs can augment the threat modelling process as part of cybersecurity testing, reducing analyst workload and enhancing the overall security assurance process. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""analise de segurança ?""]}",10.1007/978-3-032-05188-2_15,Cybersecurity; Industrial management; Information systems; Information use; Network security; Cyb...,,,,,,,
rayyan-394626656,Labeling-free RAG-enhanced LLM for intelligent fault diagnosis via reinforcement learning,2026,,,Advanced Engineering Informatics,,69,,,"Xu, Jiamin and Xu, Zixuan and Jiang, Zhaohui and Chen, Zhiwen and Luo, Hao and Wang, Yalin and Gui, Weihua",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016314758&doi=10.1016%2Fj.aei.2025.103864&partnerID=40&md5=bc0f8a6c2413c25b5233b2d1fc343bd8,,,,"Large language models (LLMs)-based fault diagnosis methods leverage extensive general-domain knowledge to provide valuable insights for fault analysis and maintenance. However, due to the low frequency of faults occurrences in complex systems, LLMs often exhibit insufficient coverage of fault diagnosis-related knowledge. This limitation reduces their effectiveness in such applications. In this context, retrieval-augmented generation (RAG) has emerged as a promising solution by enriching LLMs with relevant expert knowledge. Most existing RAG frameworks rely on supervised learning, training the retrieval network with fault corpora, query sets, and corresponding annotated labels. However, the inherent randomness of LLMs leads to instability in generated responses. As a result, it becomes challenging to consistently determine the relevance of different retrieved documents. To mitigate this instability, multiple LLM calls are often required, which further complicates the labeling process. To address these challenges, this paper proposes a reinforcement learning-based RAG method (TG-RL-RAG) that avoids supervised labeling. The method employs graph-structured fault corpora, optimizes the retrieval strategy via proximal policy optimization (PPO). Furthermore, considering the steadily increasing of fault-related queries over time, the method introduces a progressively diminishing teacher-guidance strategy, employing the previously trained agent as a dynamic teacher to guide a new processing agent, enabling continual learning with new queries. Finally, the paper uses fault logs from a specific set of Type-1 and Type-2 heavy-duty trains over one year, and conducts comparative experiments to validate the effectiveness and necessity of the proposed method. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1016/j.aei.2025.103864,Computer aided diagnosis; Failure analysis; Fault detection; Graphic methods; Information retriev...,,,,,,,
rayyan-394626657,"51st Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2025",2026,,,Lecture Notes in Computer Science,,16081,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016159497&partnerID=40&md5=5a1976d7b8b67a3a6ce4ee3ab840856d,,,,"The proceedings contain 82 papers. The special focus in this conference is on Software Engineering and Advanced Applications. The topics include: LLMs Based Data Augmentation Techniques for Python Code Refactoring; Empirical Analysis of OpenAI Embeddings for Semantic Code Review Comment Similarity; refactoring Detection Across Languages: Leveraging Java-Trained Models for Detecting Class-Level Refactorings in Kotlin; Towards a Service-Oriented Infrastructure for Distributed Systems with Heterogeneous AI Accelerators; Define-ML: An Approach to Ideate Machine Learning-Enabled Systems; MLTradeOps: Embedding Trade-Off Management into the MLOps Workflow; Extracting Design Patterns from Mined Component Models of ML-Enabled Systems; Quality by Prompt: LLM-Powered Transformation of Data Quality Requirements Into Great Expectations; ML Pipeline Insights Service for Rule-Based Assessment of Training Practices in Reinforcement Learning; Reconsidering Requirements Engineering: Human–AI Collaboration in AI-Native Software Development; challenges of Virtual Validation and Verification for Automotive Functions; a Systematic Approach to Fault Injection Test Case Generation in Practice; counterfactual Self-adaptation in Cyber-Physical Systems; exploring Explainability Requirements for Self-adaptive Systems; ethics-Based Requirements for Engineering Cyber-Physical Systems: A Literature Study; robot Mission Adaptation with Quantitative Guarantees; symbolic Runtime Verification and Adaptive Decision-Making for Robot-Assisted Dressing; configurable Abstraction of Signals Using Signal Temporal Logic; meta-Metamodel-Independent Model Transformations; Investigating the Role of LLMs Hyperparameter Tuning and Prompt Engineering to Support Domain Modeling; Towards Modeling Human-Agentic Collaborative Workflows: A BPMN Extension; an Automated Diagram Generator of Reference Solutions for Modeling Educators. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626658,"Co-Design of Communication, Computing and Control in Cyber-Physical Systems, CoC3CPS 2025",2026,,,Lecture Notes in Computer Science,,15955,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014740058&partnerID=40&md5=1d302787f7ab9f246d930aeef4682c2c,,,,"The proceedings contain papers. The special focus in this conference is on . The topics include: Real-Time Control Selection over the Computing Continuum; temporal Intent-Aware Multi-agent Learning for Network Optimization; Dependable AI Inference - A Work-in-Progress on CPU, Co-processor and FPGA Approaches; Methodology for Test Case Allocation Based on a Formalized ODD; Safety-Aware Strategy Synthesis for Autonomous System of Systems with UPPAAL; from Bouncing Break-ins to Frictional Firewalls: Ideas About Interacting Requirements for Vehicle Safety and Security; a ThreatGet-Based Framework for Aligning System Security with the Cyber Resilience Act; i7Fuzzer: Neural-Guided Fuzzing for Enhancing Security Testing of Stateful Protocols; HyLLM-IDS: A Conceptual Hybrid LLM-Assisted Intrusion Detection Framework for Cyber-Physical Systems; PROTECTION: Provably Robust Intrusion Detection System for IoT Through Recursive Delegation; towards Credible Simulators: A Validation Methodology for Safety-Critical Virtual Testing; cybersecurity in Partitioned Space Embedded Systems; A GSN-Based Requirement Analysis of the EU AI Regulation; a Safety Argument Fragment Towards Safe Deployment of Performant Automated Driving Systems; certus: A Domain Specific Language for Confidence Assessment in Assurance Cases; doubt in Safety Claims is Inevitable: What is its Impact, What Can be Done About It?; ensuring Information Security in Inclusive Digital Environments; Functional Safety with Model-Based Safety Analysis: A Perspective from ARP4761A; High-Performance AI Inference for Agile Deployment on Space-Qualified Processors: A Performance Benchmarking Study; SCALOFT: An Initial Approach for Situation Coverage-Based Safety Analysis of an Autonomous Aerial Drone in a Mine Environment; trick or Treat: A Study of Human Detection of Manipulative Tactics in Phishing Emails; rational Verification in Repeated Security Games; quantitative Assessment of Energy Efficiency, Comfort, and Safety in an Intelligent Heating System Under False Data Injection Attacks; cyber-Safety Assessment of Wind Turbines: A Reachability Analysis Approach Against Cyber-Attacks; Scenario Hazard Prevention for Autonomous Driving Based on Improved STPA; applying Machine Learning Towards the Recognition of Driving Behavior. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",,,,,,,,,
rayyan-394626659,COMPASS: An Agent for MLIR Compilation Pass Pipeline Generation,2026,,,Lecture Notes in Computer Science,,15841,,215 - 232,"Zhang, Hongbin and Gao, Shihao and Liu, Yang and Xing, Mingjie and Wu, Yanjun and Zhao, Chen",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011349002&doi=10.1007%2F978-3-031-98208-8_13&partnerID=40&md5=0fa82d72dc5d7465257c8b18469f7053,,,,"MLIR is the state-of-the-art multi-level compilation infrastructure. It provides a reusable and extensible compiler intermediate representation (IR) framework that supports the collaboration of IRs across different levels. MLIR has been widely adopted in various compilers, forming a domain-specific compilation ecosystem. However, the features of MLIR also bring challenges to compilation pass pipeline arrangement. Managing mixed-level abstractions and diverse IR extensions requires significant expertise, which increases the complexity of developing MLIR compilation path. COMPASS is proposed as an agent to generate MLIR pass pipelines, aiming to simplify the construction process and reduce reliance on manual expertise. Confronted with uncertain compilation passes and fragmented domain-specific knowledge, we address the problem by decomposing it into a unified compilation methodology and an extensible knowledge base. To achieve this, COMPASS combines an MLIR knowledge base with a compilation path generator to automate pass pipeline arrangement. The knowledge base is constructed using a large language model (LLM), while the generator performs backtracking over a pass-selection tree. Evaluation on a range of MLIR-based compilers shows that COMPASS achieves a success rate exceeding 90% across 1,256 test cases, successfully generating pass pipelines and compiling source files to their corresponding target abstraction levels. These results demonstrate that COMPASS enables the automatic generation of pass pipelines for MLIR-based compilers, reducing the human effort involved in the MLIR ecosystem. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1007/978-3-031-98208-8_13,Abstracting; Computer software reusability; Ecosystems; Electric generators; Knowledge based syst...,,,,,,,
rayyan-394626660,Collaborative LLM agents for flexible software development of intelligent industrial robot control systems,2025,,,Complex and Intelligent Systems,,11,12,,"Chen, Kezhou and Wang, Tao and Ni, Mingzhe and Cheng, Lianglun and Wang, Zhuowei and Chen, Chong",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019546806&doi=10.1007%2Fs40747-025-02051-z&partnerID=40&md5=69de04db2db87713c66f228b259b9ad8,,,,"Software plays a crucial role in robot control systems, and its efficient, flexible development is essential for production. Such software must be customized to specific production processes, requiring developers with specialized expertise in these areas—the high development threshold results in reduced efficiency and increased costs. Recently, significant progress has been made in automated problem-solving through societies of agents based on large language models (LLMs). To automate software development for industrial robot control systems, this paper introduces an Industrial Robot Control Software Auto-Development (IRCSAD) framework with multi-agent collaboration, and a Low-code Industrial Software Platform (LISP) for validating IRCSAD-developed software. IRCSAD automates software development and iterative optimization of prompts through the collaboration of multiple LLM-based agents. This work also proposes a software testing methodology for robot control systems based on reliability assessment. An experimental study that develops software for the robot control system for assembly, sorting, and inspection tasks is implemented. The results show that collaboration with LISP enhances IRCSAD's ability to solve complex problems in the development process, saves development costs, and improves development efficiency. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1007/s40747-025-02051-z,,,,,,,,
rayyan-394626661,StictionGPT: Detecting valve stiction in process control loops using large vision language model,2025,,,Control Engineering Practice,,165,,,"Xue, Tianci and Shang, Chao and Huang, Dexian and Huang, Biao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017549421&doi=10.1016%2Fj.conengprac.2025.106588&partnerID=40&md5=42fa61e55af761c2e89cfcc5fe47ae28,,,,"Stiction detection in control valves is a critical challenge in control loop performance assessment and fault diagnosis within the process industry. Existing stiction detection methods often require determining a threshold or rely on a large amount of image representation data to train deep neural networks. However, they face challenges such as difficulty in threshold determination, poor transferability, and lack of interpretability. Recent advancements in large language models (LLMs) and large vision-language models (LVLMs) offer new possibilities for improving the generalization of detection models by leveraging their multimodal understanding and reasoning capabilities. We propose StictionGPT, an LVLM-based agent for valve stiction detection. To overcome limitations of traditional methods, we leverage LVLMs to mimic human decision-making, combining textual semantics with visual shape features to determine the presence of stiction. First, we transform time-series data into images that contain shape features. These images are time-series plot, PV-OP plot, OP-ΔPV plot, and CRD-PV plot. Next, we construct a multimodal dataset based on the semantics of these shapes for image–text alignment, and apply low-rank adaptation (LoRA) to foundation LVLMs to enable efficient few-shot generalization to the stiction detection task. Finally, we test the model on the ISDB benchmark and another real-world plant dataset. It turns out that StictionGPT achieves the highest accuracy on the ISDB benchmark and demonstrates excellent performance on the plant dataset. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1016/j.conengprac.2025.106588,Benchmarking; Computational linguistics; Computer vision; Fault detection; Semantics; Statistical...,,,,,,,
rayyan-394626662,Query-efficient and dataset-independent red teaming for LLMs content safety evaluation,2025,,,Knowledge-Based Systems,,329,,,"Liu, Shuo and Cheng, Xiang and Su, Sen",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015138753&doi=10.1016%2Fj.knosys.2025.114404&partnerID=40&md5=71877d405c7b4e49a76a50db48ef3ed7,,,,"Large language models (LLMs) are widely used for their remarkable ability to understand and generate natural language. Nevertheless, LLMs can also produce unintended outputs that pose significant social risks. Red teaming can identify potential security vulnerabilities in LLMs and support mitigating such risks. However, existing red teaming approaches struggle to balance query efficiency and generalizability due to their complex search processes or reliance on pre-existing datasets. To address these issues, we present RAPT, a query-efficient and dataset-independent red teaming approach. RAPT employs an adaptive generate-select framework that consists of four cyclic steps: generating test cases by an LLM-based generator, selecting test cases by an reinforcement learning (RL)-based selector, testing the target model, and refining the generator and the selector. In this framework, the generator is used to generate test cases, and the selector is used to select test cases. We introduce a contrast prompt template and diversity demonstration extraction method to guide the generator, incorporating previous test feedback as demonstrations to generate more effective and diverse test cases. For the selector, we formalize the test case selection process as a Markov decision process (MDP), allowing us to design a reinforcement learning-based agent to continuously optimize the selection policy, which is able to balance the effectiveness and diversity of test cases according to a compound reward function. Experimental results show that RAPT can effectively discover more successful and diverse test cases than existing methods within a limited number of queries without relying on any pre-existing dataset. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""teste red team""]}",10.1016/j.knosys.2025.114404,Computational linguistics; Markov processes; Natural language processing systems; Query processin...,,,,,,,
rayyan-394626663,AutoControl: An end-to-end fully automated workflow for control design of building energy systems,2025,,,Energy,,336,,,"Hu, Ziqi and Li, Mingchen and Tang, Hao and Wang, Zhe",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016094583&doi=10.1016%2Fj.energy.2025.138329&partnerID=40&md5=ad2f813bd3b282e4bbca799fafa7acb3,,,,"Developing an efficient and effective control system is critical to enhance built environment quality, to reduce building energy consumption and to achieve the carbon neutrality goal. However, this process is expertise demanding, time consuming, and error-prone, particularly for large-scale buildings with complicated building energy systems. To address this challenge, this study proposes AutoControl, an end-to-end fully automated workflow based on Large Language Models (LLMs). AutoControl incorporates two LLM-based agents that utilize Brick models as inputs to automatically design and generate Proportional–Integral (PI) controller codes. The first LLM agent, a semantic interpreter, extracts and translates configuration details from the Brick model into a comprehensive description of the building energy system and related control specifications. The second LLM agent, a control expert agent, generates the PI controller code based on the interpreted configurations. Finally, Particle Swarm Optimization (PSO) is employed to fine-tune the parameters of the PI controller. Experiments were conducted on three test cases with diverse HVAC system configurations using the BOPTest virtual testbed. AutoControl achieved an average Mean Absolute Error (MAE) in temperature of 0.323 <sup>∘</sup>C and an average Root Mean Square Error (RMSE) in temperature of 0.766 <sup>∘</sup>C during a week-period, demonstrating robust temperature control performance and strong generalization capabilities. These results highlight the potential of using LLMs for automatic development of building controllers. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.1016/j.energy.2025.138329,Air conditioning; Architectural design; Automation; Brick; Controllers; Integral equations; Intel...,,,,,,,
rayyan-394626664,A Concept for Bio-Agentic Visual Communication: Bridging Swarm Intelligence with Biological Analogues,2025,,,Biomimetics,,10,9,,"Starbuck, Bryan and Li, Hanlong and Cochran, Bryan and Weissburg, Marc J. and Bras, Bert A.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017423452&doi=10.3390%2Fbiomimetics10090605&partnerID=40&md5=5f9cda4977c923b36945aa29e3e7231f,,,,"Biological swarms communicate through decentralized, adaptive behaviors shaped by local interactions, selective attention, and symbolic signaling. These principles of animal communication enable robust coordination without centralized control or persistent connectivity. This work presents a proof of concept that identifies, evaluates, and translates biological communication strategies into a generative visual language for unmanned aerial vehicle (UAV) swarm agents operating in radio-frequency (RF)-denied environments. Drawing from natural exemplars such as bee waggle dancing, white-tailed deer flagging, and peacock feather displays, we construct a configuration space that encodes visual messages through trajectories and LED patterns. A large language model (LLM), preconditioned using retrieval-augmented generation (RAG), serves as a generative translation layer that interprets perception data and produces symbolic UAV responses. Five test cases evaluate the system’s ability to preserve and adapt signal meaning through within-modality fidelity (maintaining symbolic structure in the same modality) and cross-modal translation (transferring meaning across motion and light). Covariance and eigenvalue-decomposition analysis demonstrate that this bio-agentic approach supports clear, expressive, and decentralized communication, with motion-based signaling achieving near-perfect clarity and expressiveness (0.992, 1.000), while LED-only and multi-signal cases showed partial success, maintaining high expressiveness (~1.000) but with much lower clarity (≤0.298). © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.3390/biomimetics10090605,Antennas; Behavioral research; Biocommunications; Biomimetics; Intelligent agents; Multi agent sy...,,,,,,,
rayyan-394626665,Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework,2025,,,Applied Sciences (Switzerland),,15,17,,"Marandi, Saman and Hu, Yushu and Modarres, Mo H.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015434450&doi=10.3390%2Fapp15179428&partnerID=40&md5=4670b6e6774702267a8df733eb8b50d5,,,,"Featured Application: This framework demonstrates how Large Language Models (LLMs) can be used to automate functional model construction and enable natural language-driven fault diagnostics in complex engineered systems. By integrating LLMs with a knowledge graph of an Auxiliary Feedwater system, the approach supports predictive maintenance and intelligent fault analysis. It applies to safety-critical domains such as nuclear power plants and other high-reliability industries. This paper presents a hybrid diagnostic framework that integrates Knowledge Graphs (KGs) with Large Language Models (LLMs) to support fault diagnosis in complex, high-reliability systems such as nuclear power plants. The framework is based on the Dynamic Master Logic (DML) model, which organizes system functions, components, and dependencies into a hierarchical KG for logic-based reasoning. LLMs act as high-level facilitators by automating the extraction of DML logic from unstructured technical documentation, linking functional models with language-based reasoning, and interpreting user queries in natural language. For diagnostic queries, the LLM agent selects and invokes predefined tools that perform upward or downward propagation in the KG using DML logic, while explanatory queries retrieve and contextualize relevant KG segments to generate user-friendly interpretations. This ensures that reasoning remains transparent and grounded in the system structure. This approach reduces the manual effort needed to construct functional models and enables natural language queries to deliver diagnostic insights. In a case study on an auxiliary feedwater system used in the nuclear pressurized water reactors, the framework achieved over 90 percent accuracy in model element extraction and consistently interpreted both diagnostic and explanatory queries. The results validate the effectiveness of LLMs in automating model construction and delivering explainable AI-assisted health monitoring. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.3390/app15179428,Failure analysis; Fault detection; Graph theory; Knowledge graph; Large scale systems; Nuclear fu...,,,,,,,
rayyan-394626666,Ontology-enabled AI agent-driven intelligent digital twins for building operations and maintenance,2025,,,Journal of Building Engineering,,108,,,"Yoon, Sungmin and Song, Jihwan and Li, Jiteng",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004815812&doi=10.1016%2Fj.jobe.2025.112802&partnerID=40&md5=fd420f45fa49eb960af27b15db48f480,,,,"Building digital twins (DTs) are essential for enhancing operational efficiency, optimizing energy consumption, and reducing costs in buildings. However, the inherent complexity of buildings, their long operational lifespans, and the specific nature of the construction industry pose significant challenges in creating digital twins for buildings. Intelligent digital twins (IDTs) address these challenges by integrating existing digital twin models with AI, enabling a comprehensive representation of the building lifecycle while incorporating expert input. This study proposes an AI agent-based IDT framework using an ontological approach, where AI agents are engineered by DT administrators with building operations and maintenance (O&M) data, information, and applications within an ontological DT environment. Data and information generated within this environment are expressed in the DT ontology, enabling AI agents to gain a holistic understanding of the target system. Applications are integrated as a tool, thereby enabling AI agents to expand their actions and gain additional information from results. To validate this framework, virtual in-situ modeling (VIM) and fault detection and diagnosis (FDD) algorithms were implemented as DT applications to demonstrate the operation of the IDT system. Four case studies were conducted to demonstrate IDT-enabled O&M services, and LangSmith was used to visualize the AI agents' reasoning process as part of the result validation. It shows that AI agents have capabilities of performing building O&M tasks with high-level reasoning. The significance of this study lies in demonstrating the feasibility of implementing IDT models in building O&M by enabling AI agents to provide comprehensive, domain-specific knowledge and perform operational tasks, thereby serving as an assistant for both users and operators. Finally, this study underscores the critical role of engineers in managing and maintaining ontology and applications within the DT environment. © 2025 Elsevier B.V., All rights reserved.","Cited by: 8 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1016/j.jobe.2025.112802,Architectural design; AI agent; Building informatics; Built environment; Digital twin; Intelligen...,,,,,,,
rayyan-394626667,DCA-Bench: A Benchmark for Dataset Curation Agents,2025,,,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,2,,5482 - 5492,"Huang, Benhao and Yu, Yingzhuo and Huang, Jin and Zhang, Xingjian and Ma, Jiaqi W.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014362039&doi=10.1145%2F3711896.3737422&partnerID=40&md5=fe0bf44c620b538b3308c99a81c94e05,,,,"The quality of datasets plays an increasingly crucial role in the research and development of modern artificial intelligence (AI). Despite the proliferation of open dataset platforms nowadays, data quality issues, such as incomplete documentation, inaccurate labels, ethical concerns, and outdated information, remain common in widely used datasets. Furthermore, these issues are often subtle and difficult to be detected by rule-based scripts, therefore requiring identification and verification by dataset users or maintainers-a process that is both time-consuming and prone to human mistakes. With the surging ability of large language models (LLM), it's promising to streamline the discovery of hidden dataset issues with LLM agents. To achieve this, one significant challenge is enabling LLM agents to detect issues in the wild rather than simply fixing known ones. In this work, we establish a benchmark to measure LLM agent's ability to tackle this challenge. We carefully curate 221 real-world test cases from eight popular dataset platforms and propose an automatic evaluation framework using GPT-4o. Our proposed framework shows strong empirical alignment with expert evaluations, validated through extensive comparisons with human annotations. Without any hints, most competitive Curator agent can only reveal ∼30% of the data quality issues in the proposed dataset, highlighting the complexity of this task and indicating that applying LLM agents to real-world dataset curation still requires further in-depth exploration and innovation. The data and code is available at https://github.com/TRAIS-Lab/dca-bench. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1145/3711896.3737422,Artificial intelligence; Data curation; Human computer interaction; Intelligent agents; Large dat...,,,,,,,
rayyan-394626668,Artificial Intelligence Agent-Enabled Predictive Maintenance: Conceptual Proposal and Basic Framework,2025,,,Computers,,14,8,,"Jiang, Wenyu and Hu, Fuwen",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014416900&doi=10.3390%2Fcomputers14080329&partnerID=40&md5=f12ea2c9ab0843d74f2ba535231d0bee,,,,"Predictive maintenance (PdM) represents a significant evolution in maintenance strategies. However, challenges such as system integration complexity, data quality, and data availability are intricately intertwined, collectively impacting the successful deployment of PdM systems. Recently, large model-based agents, or agentic artificial intelligence (AI), have evolved from simple task automation to active problem-solving and strategic decision-making. As such, we propose an AI agent-enabled PdM method that leverages an agentic AI development platform to streamline the development of a multimodal data-based fault detection agent, a RAG (retrieval-augmented generation)-based fault classification agent, a large model-based fault diagnosis agent, and a digital twin-based fault handling simulation agent. This approach breaks through the limitations of traditional PdM, which relies heavily on single models. This combination of “AI workflow + large reasoning models + operational knowledge base + digital twin” integrates the concepts of BaaS (backend as a service) and LLMOps (large language model operations), constructing an end-to-end intelligent closed loop from data perception to decision execution. Furthermore, a tentative prototype is demonstrated to show the technology stack and the system integration methods of the agentic AI-based PdM. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.3390/computers14080329,Decision making; Digital twin; Intelligent agents; Knowledge based systems; Knowledge management;...,,,,,,,
rayyan-394626669,Evaluation of error detection and treatment recommendations in nucleic acid test reports using ChatGPT models,2025,,,Clinical Chemistry and Laboratory Medicine,,63,9,1698 - 1708,"Han, Wenzheng and Wan, Chao and Shan, Rui and Xu, Xudong and Chen, Guang and Zhou, Wenjie and Yang, Yuxuan and Feng, Gang and Li, Xiaoning and Yang, Jianghua and Jin, Kai and Chen, Qing",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003572208&doi=10.1515%2Fcclm-2025-0089&partnerID=40&md5=d6984d430a59ca185e111fa3f721c488,,,,"Objectives: Accurate medical laboratory reports are essential for delivering high-quality healthcare. Recently, advanced artificial intelligence models, such as those in the ChatGPT series, have shown considerable promise in this domain. This study assessed the performance of specificGPT models-namely, 4o, o1, and o1 mini-in identifying errors within medical laboratory reports and in providing treatment recommendations. Methods: In this retrospective study, 86 medical laboratory reports of Nucleic acid test report for the seven upper respiratory tract pathogens were compiled. There were 285 errors from four common error categories intentionally and randomly introduced into reports and generated 86 incorrected reports. GPT models were tasked with detecting these errors, using three senior medical laboratory scientists (SMLS) and three medical laboratory interns (MLI) as control groups. Additionally, GPT models were tasked with generating accurate and reliable treatment recommendations following positive test outcomes based on 86 corrected reports. χ2 tests, Kruskal-Wallis tests, and Wilcoxon tests were used for statistical analysis where appropriate. Results: In comparison with SMLS or MLI, GPT models accurately detected three error types, and the average detection rates of the three GPT models were 88.9 - %(omission), 91.6 % (time sequence), and 91.7 % (the same individual acted both as the inspector and the reviewer). However, the average detection rate for errors in the result input format by the three GPT models was only 51.9 %, indicating a relatively poor performance in this aspect. GPT models exhibited substantial to almost perfect agreement with SMLS in detecting total errors (kappa [min, max]: 0.778, 0.837). However, the agreement between GPT models and MLI was moderately lower (kappa [min, max]: 0.632, 0.696). When it comes to reading all 86 reports, GPT models showed obviously reduced reading time compared with SMLS or MLI (all p<0.001). Notably, our study also found the GPT-o1 mini model had better consistency of error identification than the GPT-o1 model, which was better than that of the GPT-4o model. The pairwise comparisons of the same GPT model's outputs across three repeated runs showed almost perfect agreement (kappa [min, max]: 0.912, 0.996). GPT-o1 mini showed obviously reduced reading time compared with GPT-4o or GPT-o1(all p<0.001). Additionally, GPT-o1 significantly outperformed GPT-4o or o1 mini in providing accurate and reliable treatment recommendations (all p<0.0001). Conclusions: The detection capability of some of medical laboratory report errors and the accuracy and reliability of treatment recommendations of GPT models was competent, especially, potentially reducing work hours and enhancing clinical decision-making. © 2025 Elsevier B.V., All rights reserved.","Cited by: 2 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1515/cclm-2025-0089,nucleic acid; adult; Article; California; ChatGPT; clinical laboratory personnel; controlled stud...;Clinical; Nucleic Acids; Retrospective Studies,,,,,,,
rayyan-394626670,Mutation-Guided LLM-based Test Generation at Meta,2025,,,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,,,180 - 191,"Foster, Christopher and Gulati, Abhishek and Harman, Mark and Harper, Inna and Mao, Ke and Ritchey, Jillian and Robert, Hervé and Sengupta, Shubho",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013964900&doi=10.1145%2F3696630.3728544&partnerID=40&md5=72e4cc0d7327e32e3ebb61d1e2662a5f,,,,"This paper<sup>1</sup> describes Meta’s Automated Compliance Hardening (ACH) system for mutation-guided LLM-based test generation. ACH generates relatively few mutants (aka simulated faults), compared to traditional mutation testing. Instead, it focuses on generating currently undetected faults that are specific to an issue of concern. From these currently uncaught faults, ACH generates tests that can catch them, thereby ‘killing’ the mutants and consequently hardening the platform against regressions. We use privacy concerns to illustrate our approach, but ACH can harden code against any type of regression. In total, ACH was applied to 10,795 Android Kotlin classes in 7 software platforms deployed by Meta, from which it generated 9,095 mutants and 571 privacy-hardening test cases. ACH also deploys an LLM-based equivalent mutant detection agent that achieves a precision of 0.79 and a recall of 0.47 (rising to 0.95 and 0.96 with simple pre-processing). ACH was used in Messenger and WhatsApp test-a-thons where engineers accepted 73% of its tests, judging 36% to privacy relevant. We conclude that ACH hardens code against specific concerns and that, even when its tests do not directly tackle the specific concern, engineers find them useful for their other benefits. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1145/3696630.3728544,Automatic test pattern generation; Engineers; Software testing; Automated test generations; Equiv...,,,,,,,
rayyan-394626671,MultiMind: A Plug-in for the Implementation of Development Tasks Aided by AI Assistants,2025,,,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,,,1310 - 1317,"Donato, Benedetta and Mariani, Leonardo and Micucci, Daniela and Riganelli, Oliviero and Somaschini, Marco",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013962583&doi=10.1145%2F3696630.3730564&partnerID=40&md5=7dae58673446f3788edff1ace21661e8,,,,"The integration of AI assistants into software development workflows is rapidly evolving, shifting from automation-assisted tasks to collaborative interactions between developers and AI. Large Language Models (LLMs) have demonstrated their effectiveness in several development activities, including code completion, test case generation, and documentation production. However, embedding AI-assisted tasks within Integrated Development Environments (IDEs) presents significant challenges. It requires designing mechanisms to invoke AI assistants at the appropriate time, coordinate interactions with multiple assistants, process the generated outputs, and present feedback in a way that seamlessly integrates with the development workflow. To address these issues, we introduce MultiMind, a Visual Studio Code plug-in that streamlines the creation of AI-assisted development tasks. MultiMind provides a modular and extensible framework, enabling developers to cost-effectively implement and experiment with new AI-powered interactions without the need for complex IDE customizations. MultiMind has been tested in two use cases: one for the automatic generation of code comments and the other about the definition of AI-powered chat. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1145/3696630.3730564,Automatic programming; Human engineering; Integrodifferential equations; Multi agent systems; Sof...,,,,,,,
rayyan-394626672,ProphetAgent: Automatically Synthesizing GUI Tests from Test Cases in Natural Language for Mobile Apps,2025,,,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,,,174 - 179,"Kong, Qichao and Lv, Zhengwei and Xiong, Yiheng and Sun, Jingling and Su, Ting and Wang, Dingchun and Li, Letao and Yang, Xu and Huo, Gang",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013961463&doi=10.1145%2F3696630.3728543&partnerID=40&md5=b5c6eee38a63a745a4434ad68f42cac5,,,,"GUI tests is crucial for ensuring software quality and user satisfaction of mobile apps. In practice, companies often maintain extensive test cases written in natural language. Testers need to convert these test cases into executable scripts for regression and compatibility testing. Requirement changes or version updates often necessitate the addition and modification to these test cases. Thus, when faced with large volumes of test cases and regular updates, this process becomes costly, which is a common challenge across the industry. To address this issue, this paper proposes ProphetAgent that can automatically synthesize executable GUI tests from the test cases written in natural language. ProphetAgent first constructs a Clustered UI Transition Graph (CUTG) enriched with semantic information, then leverages large language models to generate the executable test case based on CUTG and test cases written in natural language. Experiment results show that ProphetAgent achieved a 78.1% success rate across 120 test cases in Douyin, Doubao, and six open-source apps, surpassing existing automated approaches (21.4% for AppAgent and 32.5% for AutoDroid). Additionally, statistical data from ByteDance’s testing platform show that ProphetAgent increased testers’ efficiency in synthesizing UI tests by 260%. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1145/3696630.3728543,Application programs; Computer software selection and evaluation; Graphic methods; Graphical user...,,,,,,,
rayyan-394626673,From Overload to Insight: Bridging Code Search and Code Review with LLMs,2025,,,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,,,656 - 660,"Rao, Nikitha and Vasilescu, Bogdan and Holmes, Reid",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013959386&doi=10.1145%2F3696630.3728518&partnerID=40&md5=44b507a779648293d9b152108a61218b,,,,"The software engineering (SE) research community has developed numerous tools to search and extract actionable insights from software artifacts, ranging from static analysis tools to testing frameworks and continuous integration pipelines (hereafter just “search tools”). Despite their potential, many of these search tools remain underutilized during code review, a critical process for ensuring software quality. Key challenges include the overwhelming volume of information generated by automated tools, high false-positive rates, and the need for manual configuration or interpretation, which disrupts the flow of review. In this paper, we propose a vision for an LLM-powered conversational agent designed to assist code reviewers by bridging the gap between human reviewers and search tools. This agent would summarize relevant insights, tailor them to the specific code change under review, and facilitate context-aware interactions. By enhancing the human-in-the-loop nature of code review, such a tool has the potential to amplify reviewer effectiveness, streamline the review process, and ultimately improve software quality. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1145/3696630.3728518,Automation; Computer software selection and evaluation; Software quality; Software testing; Stati...,,,,,,,
rayyan-394626674,Can Virtual AI Agents Improve Cognitive Assessment? A Virtual Reality Perspective,2025,,,,,,,424 - 428,"Hebri, Aref and Pavel, Hamza Reza and Nikanfar, Sama and Farahanipad, Farnaz and Makedon, Fillia S.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013074132&doi=10.1145%2F3733155.3734917&partnerID=40&md5=5e202f11c61d7571bce7f5df2557b5af,,,,"We introduce SmartSage, an intelligent virtual AI agent powered by Large Language Models (LLMs) and Vision Language Models (VLMs) that enhances cognitive assessment through adaptive, embodied interactions in virtual environments. As an integral component of our Virtual Reaility-based ADHD Assessment System, SmartSage serves as an interactive guide that demonstrates tasks, delivers real-time feedback, and dynamically adjusts task difficulty based on user performance. Based on the clinically validated Automated Test of Embodied Cognition (ATEC) framework, our system leverages motion tracking and haptic feedback of the Meta Quest platform to facilitate bidirectional sensorimotor interactions that boost engagement while maintaining clinical validity. By combining embodied cognition principles with virtual reality technology and AI-driven interaction, SmartSage makes cognitive assessment more accessible, engaging, and ecologically valid. In this paper, we provide an overview of the system design, present initial pilot results, and outline a roadmap for future validation studies. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1145/3733155.3734917,Artificial intelligence; Cognitive systems; Feedback; Haptic interfaces; Human computer interacti...,,,,,,,
rayyan-394626675,Is Having Rationales Enough? Rethinking Knowledge Enhancement for Multimodal Hateful Meme Detection,2025,,,,,,,559 - 569,"Lu, Junyu and Xu, Bo and Zhang, Xiaokun and Zhu, Haohao and Wang, Kaichun and Yang, Liang and Lin, Hongfei",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011821122&doi=10.1145%2F3726302.3730014&partnerID=40&md5=2915867895510b120f7ca2e90e75426e,,,,"Hateful memes are prevalent on the Internet, raising the urgent need for effective detection. Given their implicit nature, incorporating rationales with background knowledge is crucial for enhancing model understanding. However, existing methods often suffer from limited quality of external rationales and misalignment with original meme information. These challenges hinder model comprehension, leading to reduced accuracy and explainability. To address these challenges, we propose a Multimodal Multi-agent Knowledge Enhanced (M2KE) framework for hateful meme detection. M2KE introduces a multi-agent rationale discovery mechanism to extract high-quality rationales relevant to meme content and an adaptive knowledge interaction mechanism to ensure alignment between original meme information and external rationales. Specifically, multi-agent rationale discovery mechanism improves the reliability of rationales by collaboratively verifying and refining them with multiple agents, supported by large language models (LLMs) due to their extensive knowledge. And adaptive knowledge interaction mechanism uses information entropy to dynamically balance the model’s attention between original meme information and external rationales, preventing over-reliance on rationales and enabling a more comprehensive understanding. Experimental results on three datasets demonstrate that M2KE significantly outperforms existing models. Further analysis underscores the importance of effectively integrating accurate rationales to enhance model performance. Disclaimer: Samples in this paper may be considered offensive. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1145/3726302.3730014,Alignment; Error detection; Intelligent agents; Background knowledge; Hateful meme detection; Int...,,,,,,,
rayyan-394626676,Leveraging LLM-Based AI Agents for Boosting Vehicle Testing Process,2025,,,SAE Technical Papers,,,,,"Unterschütz, Stefan and Hansen, Björn",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011094345&doi=10.4271%2F2025-01-0300&partnerID=40&md5=e1a4fd3a378c0af05b1cfd178f6cc37e,,,,"The validation process in research and development involves several complex stages, including test requests, planning, execution, and the analysis and evaluation of results. In the automotive domain, compliance with regulatory standards, such as those required for Euro 7 homologation, adds an additional layer of complexity. Implementing these regulations into operational validation workflows and ensuring their seamless integration with supporting tools remains a significant challenge. Recent advancements in Large Language Models (LLMs) have introduced innovative use cases across various domains. In particular, AI agents powered by LLMs demonstrate immense potential by autonomously performing complex tasks while utilizing user-defined tools. This capability extends far beyond traditional applications like knowledge management or text generation typically associated with LLMs. In this paper, we explore how a modern AI agent can be developed and integrated into existing IT tools for test management to optimize the validation process. We present a feasibility study focused on the implementation of Euro 7 homologation requirements for braking systems. This includes functionalities such as generating test plans based on the Euro 7 regulation, performing software-based verification of constraints, and analyzing measurement data. The proposed concepts are not limited to validation processes. The proposed AI agent concept can be seamlessly applied to other domains and integrated into additional products, leading to cost reductions and enhanced efficiency. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.4271/2025-01-0300,Agents; Cost reduction; Knowledge management; Software testing; Verification; Analysis and evalua...,,,,,,,
rayyan-394626677,Enhancing search strategies for systematic reviews on drug Harms: An evaluation of the utility of ChatGPT in error detection and keyword generation,2025,,,Computers in Biology and Medicine,,193,,,"Gitman, Victor and Maxwell, Colleen J. and Gamble, J. M.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006706624&doi=10.1016%2Fj.compbiomed.2025.110464&partnerID=40&md5=ce7574374739e4410214d1fd2522e17e,,,,"Objective: Developing search strategies for synthesizing evidence on drug harms requires specialized expertise and knowledge. The aim of this study was to evaluate ChatGPT's ability to enhance search strategies for systematic reviews of drug harms by identifying missing and generating omitted keywords. Materials and methods: A literature search in PubMed identified systematic reviews of drug harms from 10 high-impact journals between 1-Nov-2013 to 27-Nov-2023. Sixteen search strategies used in these reviews were selected each with a single error of omission introduced. ChatGPT's (GPT-4) performance was evaluated based on error detection, similarity between the extracted and generated search strategies via strict and semantic keyword matching, and proportion of omitted keywords generated. Results: ChatGPT identified the introduced errors in all search strategies. Under strict matching, the mean Jaccard's similarity measure was 0.17 (range: 0.00–0.52) and with semantic matching this increased to 0.23 (range: 0.00–0.53). Similarly, the mean proportion of keywords recreated by ChatGPT was 49 % using strict matching increasing to 71 % with semantic matching. Discussion and conclusion: ChatGPT effectively detected errors and generated relevant keywords, showing potential as a tool for evidence retrieval on drug harms. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Hybrid Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1016/j.compbiomed.2025.110464,Drug-related side effect and adverse reaction; Evidence-based medicine; Literature search; Matchi...,,,,,,,
rayyan-394626678,Probing a novel machine tool fault reasoning and maintenance service recommendation approach through data-knowledge empowered LLMs integrated with AR-assisted maintenance guidance,2025,,,Advanced Engineering Informatics,,66,,,"Liu, Changchun and Song, Jiaye and Tang, Dunbing and Wang, Liping and Zhu, Haihua and Cai, Qixiang",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005204916&doi=10.1016%2Fj.aei.2025.103460&partnerID=40&md5=42203515c9f34918c75d3d5520a5cc31,,,,"With the growing complexity and quantity of machine tools, the emergence of various faults threatens manufacturing process stability. Existing methods often fail to effectively utilize knowledge for fault causality reasoning and maintenance service provision, while the absence of intuitive visual guidance results in low maintenance efficiency and potential misoperations. To address this issue, a novel machine tool fault reasoning and maintenance service recommendation approach through data-knowledge empowered LLMs (Large Language Models) integrated with AR (Augmented Reality)-assisted visible guidance. Firstly, a scene graph is established to analyze fault correlations through semantic associations, enabling comprehensive fault-root cause analysis. Based on this, an industrial LLM is constructed by integrating fault-maintenance scene graphs with foundational Llama 3, employing prompt-based fine-tuning and multi-agent collaborative fault detection. On the one hand, multi-agent collaborative fault detection leverages a network of agents working in tandem to enhance fault identification efficiency. On the other hand, the integration of AR-assisted visual guidance facilitates accurate fault localization and provides maintenance personnel with enhanced operational support, significantly improving maintenance efficiency and accuracy. The comparative experimental results indicate that the proposed industrial LLM demonstrates superior capability in modeling complex node relationships and identifying intricate patterns within large-scale graph datasets, enabling precise maintenance service recommendations. Based on this, a significant advancement in predictive maintenance can be offered for complex machine tools by the proposed comprehensive approach. © 2025 Elsevier B.V., All rights reserved.","Cited by: 3 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1016/j.aei.2025.103460,Contour followers; Dies; Fault tree analysis; Metal working tools; Data-knowledge empowered large...,,,,,,,
rayyan-394626679,"AI-DRIVEN TOOLS IN MODERN SOFTWARE QUALITY ASSURANCE: AN ASSESSMENT OF BENEFITS, CHALLENGES, AND FUTURE DIRECTIONS",2025,,,Technology Audit and Production Reserves,,3,2,44 - 54,"Pysmennyi, Ihor and Kyslyi, Roman and Kleshch, Kyrylo",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011843831&doi=10.15587%2F2706-5448.2025.330595&partnerID=40&md5=25baf85fa1312707ac7952b86bd77ad4,,,,"Traditional quality assurance (QA) methods face significant challenges in addressing the complexity, scale, and rapid iteration cycles of modern software systems and are strained by limited resources available, leading to substantial costs associated with poor quality. The object of this research is the quality assurance processes for modern distributed software applications. The subject of the research is the assessment of the benefits, challenges, and prospects of integrating modern AI-oriented tools into quality assurance processes. Comprehensive analysis of implications was performed on both verification and validation processes covering exploratory test analyses, equivalence partitioning and boundary analyses, metamorphic testing, finding inconsistencies in acceptance criteria (AC), static analyses, test case generation, unit test generation, test suit optimization and assessment, end to end scenario execution. End to end regression of sample enterprise application utilizing AI-agents over generated test scenarios was implemented as a proof of concept highlighting practical use of the study. The results, with only 8.3% flaky executions of generated test cases, indicate significant potential for the proposed approaches. However, the study also identified substantial challenges for practical adoption concerning generation of semantically identical coverage, ""black box"" nature and lack of explainability from state-of-the-art Large Language Models (LLMs), the tendency to correct mutated test cases to match expected results, underscoring the necessity for thorough verification of both generated artifacts and test execution results. The research demonstrates AI’s transformative potential for QA but highlights the importance of a strategic approach to implementing these technologies, considering the identified limitations and the need for developing appropriate verification methodologies. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.15587/2706-5448.2025.330595,,,,,,,,
rayyan-394626680,Iterative Proof-Driven Development LLM Prompt,2025,,,,,,,1596 - 1597,"Bakharia, Aneesha",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009219296&doi=10.1145%2F3701716.3717811&partnerID=40&md5=f88586011827a87e92e9a261a36f3b1d,,,,"This paper introduces Iterative Proof-Driven Development, a novel prompt engineering method designed to take advantage of GPT-4 level models that are able to follow detailed instructions. Iterative Proof-Driven Development is a structured prompt that outlines a test-driven process for solving complex mathematics and programming tasks. The prompt provides an LLM with instructions to decompose a problem into sub-problems, generate test cases, verify results, and integrate sub-solutions. While Chain of Thought (CoT) reasoning remains central to individual steps, the structured process ensures consistency and reliability. This method takes advantage of embedded code interpreters within chatbot user interfaces, enabling immediate execution, debugging, and iterative refinement without external tools. We demonstrate this prompting technique by guiding an LLM through the development of a small CSV processing library, illustrating each step and highlighting how the method ensures well-tested, logically consistent, and reliable outputs. Finally, we explore potential use cases, future directions for automation with agent-based systems (e.g., Langgraph), and the broader implications of prompt engineering for larger software development projects. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1145/3701716.3717811,Autonomous agents; Human engineering; Software design; User interfaces; 4-level; Complex mathemat...,,,,,,,
rayyan-394626681,Evaluating Large Language Models through Communication Games: An Agent-Based Framework Using Werewolf in Unity,2025,,,,,,,,"Poglitsch, Christian and Szakács, Fabian and Pirker, Johanna",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007413232&doi=10.1145%2F3723498.3723702&partnerID=40&md5=43d5ff8816c7262d11411eb7b278a8c8,,,,"In this study, we explore the reasoning capabilities of Large Language Models (LLMs) within the context of the social communication game Werewolf, aiming to evaluate their performance in managing complex system states commonly found in computer games. Our agent architecture gathers data, refines them into detailed information, and plans actions based on this knowledge. To demonstrate the feasibility of using LLM based agents in computer games, we developed a simulation and evaluation tool using the Unity game engine. This software enables users to experiment with various LLMs and agent architectures and to measure model performance within the application. For evaluation, we tested three models: GPT-3.5 Turbo, Mistral-7B-OpenOrca, and Nous-Hermes-Llama2-13B. The results show that even smaller models can perform reasonably well in Werewolf. However, their error rate is significantly higher, highlighting the need for additional software modules or fine-tuning to improve their accuracy. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1145/3723498.3723702,Computer software selection and evaluation; Enterprise software; Intelligent agents; Mobile appli...,,,,,,,
rayyan-394626682,A community-centric intelligent cyberinfrastructure for addressing nitrogen pollution using web systems and conversational AI,2025,,,Environmental Science and Policy,,167,,,"Shrestha, Samrat and Mount, Jerry and Vald, Gabriel and Sermet, Yusuf and Samuel, Dinesh Jackson and Bryant, Chelsea and Peralta Brichtova, Ana C. and Beck, Marcus W. and Meyers, Steven D. and Müller-Karger, Frank Edgar and Cwiertny, David M. and Demir, I.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001556730&doi=10.1016%2Fj.envsci.2025.104055&partnerID=40&md5=387129f018fc3beefc25dc058dd16a74,,,,"The Blue-Green Action Platform (BlueGAP) information system (IS) is an intelligent cyberinfrastructure framework designed to support large-scale water quality assessments in the context of demographic statistics and community stories about water issues. The system prioritizes collaboration with interested parties in three pilot watersheds with test cases implemented in US locations including Iowa, Tampa, and the U.S. Virgin Islands. The BlueGAP IS leverages Artificial Intelligence (AI) technologies with large language models based on regional nutrient management issues and community knowledge to provide access to water quality information. The current focus of the system is on nitrate in drinking water, rivers, and waterways, and can be expanded to incorporate other water quality information. BlueGAP identifies possible partnerships and promotes collaborations among diverse stakeholders to facilitate effective evaluation of nitrogen-related analytes, guide action to address possible pollution, and outline sustainable water management practices. The BlueGAP IS also emphasizes its educational mission by connecting water quality data with inclusive and accessible educational content through AI technology. By integrating nitrogen data and water quality issues into educational resources, BlueGAP fosters a deeper understanding of water quality issues across diverse communities, empowering users to make informed decisions and contribute to sustainable water management practices. © 2025 Elsevier B.V., All rights reserved.","Cited by: 2 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1016/j.envsci.2025.104055,drinking water; nitrate; nitrogen; artificial intelligence; information system; water management;...,,,,,,,
rayyan-394626683,Methodology for Quality Assurance Testing of LLM-based Multi-Agent Systems,2025,,,,,,,,"Shamim, Isha and Singhal, Rekha",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001155897&doi=10.1145%2F3703412.3703439&partnerID=40&md5=0e7c01d6b77cd45d0f1491241a69340e,,,,"Large Language Models (LLMs) based Multi-Agent Systems (MAS) are a rapidly emerging field with great potential to optimize work-flows across various industries. However, the unpredictable and hallucinating nature of LLMs prevents the industries from deploying MAS to production. Currently, no software exists to evaluate and test the overall performance of MAS. To address this problem, we created a quality assurance methodology that integrates system performance monitoring (cost, LLM calls, duration) with LLM evaluation software that assesses the quality of the output using various parameters such as relevance, groundedness, correctness, etc, both at the individual agent level and complete MAS. We illustrate our methodology’s efficacy in testing application and system performance for quality assurance by applying it to an LLM-based MAS under various scenarios. We believe this approach can create a framework to help industries optimize MAS for production deployment ensuring effectiveness, resource efficiency, and scalability, thereby facilitating wider adoption of LLM-based MAS technology. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | RAYYAN-EXCLUSION-REASONS: EC6",10.1145/3703412.3703439,Application programs; Autonomous agents; Computer software selection and evaluation; Input output...,,,,,,,
rayyan-394626684,LLMs: A game-changer for software engineers?,2025,,,"BenchCouncil Transactions on Benchmarks, Standards and Evaluations",,5,1,,"Haque, Md Asraful",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006809602&doi=10.1016%2Fj.tbench.2025.100204&partnerID=40&md5=a0f0660deab18ec9f0e970c193521112,,,,"Large Language Models (LLMs) like GPT-3 and GPT-4 have emerged as groundbreaking innovations with capabilities that extend far beyond traditional AI applications. These sophisticated models, trained on massive datasets, can generate human-like text, respond to complex queries, and even write and interpret code. Their potential to revolutionize software development has captivated the software engineering (SE) community, sparking debates about their transformative impact. Through a critical analysis of technical strengths, limitations, real-world case studies, and future research directions, this paper argues that LLMs are not just reshaping how software is developed but are redefining the role of developers. While challenges persist, LLMs offer unprecedented opportunities for innovation and collaboration. Early adoption of LLMs in software engineering is crucial to stay competitive in this rapidly evolving landscape. This paper serves as a guide, helping developers, organizations, and researchers understand how to harness the power of LLMs to streamline workflows and acquire the necessary skills. © 2025 Elsevier B.V., All rights reserved.","Cited by: 4; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1016/j.tbench.2025.100204,Application programs; Computer aided software engineering; Computer operating systems; Computer p...,,,,,,,
rayyan-394626685,LLM-Vectorizer: LLM-Based Verified Loop Vectorizer,2025,,,,,,,137 - 149,"Taneja, Jubi and Laird, Avery and Yan, Cong and Musuvathi, Madanlal and Lahiri, Shuvendu K.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001176388&doi=10.1145%2F3696443.3708929&partnerID=40&md5=4301bf6db4e85ef4f474ec5cbac4cca8,,,,"Vectorization is a powerful optimization technique that significantly boosts the performance of high performance computing applications operating on large data arrays. Despite decades of research on auto-vectorization, compilers frequently miss opportunities to vectorize code. On the other hand, writing vectorized code manually using compiler intrinsics is still a complex, error-prone task that demands deep knowledge of specific architecture and compilers. In this paper, we evaluate the potential of large-language models (LLMs) to generate vectorized (Single Instruction Multiple Data) code from scalar programs that process individual array elements. We propose a novel finite-state-machine multi-agents based approach that harnesses LLMs and test-based feedback to generate vectorized code. Our findings indicate that LLMs are capable of producing high-performance vectorized code with run-time speedup ranging from 1.1x to 9.4x as compared to the state-of-the-art compilers such as Intel Compiler, GCC, and Clang. To verify the correctness of vectorized code, we use Alive2, a leading bounded translation validation tool for LLVM IR. We describe a few domain-specific techniques to improve the scalability of Alive2 on our benchmark dataset. Overall, our approach is able to verify 38.2% of vectorizations as correct on the TSVC benchmark dataset. © 2025 Elsevier B.V., All rights reserved.","Cited by: 2; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1145/3696443.3708929,Benchmarking; Computer software selection and evaluation; Deep learning; Finite automata; Program...,,,,,,,
rayyan-394626686,Large language models for building energy applications: Opportunities and challenges,2025,,,Building Simulation,,18,2,225 - 234,"Liu, Mingzhe and Zhang, Liang and Chen, Jianli and Chen, Wei An and Yang, Zhiyao and Lo, L. James and Wen, Jin and O’Neill, Zheng",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217221286&doi=10.1007%2Fs12273-025-1235-9&partnerID=40&md5=bf5965865499c33ffef3cec5eb99b9b8,,,,"Large language models (LLMs) are gaining attention due to their potential to enhance efficiency and sustainability in the building domain, a critical area for reducing global carbon emissions. Built on transformer architectures, LLMs excel at text generation and data analysis, enabling applications such as automated energy model generation, energy management optimization, and fault detection and diagnosis. These models can potentially streamline complex workflows, enhance decision-making, and improve energy efficiency. However, integrating LLMs into building energy systems poses challenges, including high computational demands, data preparation costs, and the need for domain-specific customization. This perspective paper explores the role of LLMs in the building energy system sector, highlighting their potential applications and limitations. We propose a development roadmap built on in-context learning, domain-specific fine-tuning, retrieval augmented generation, and multimodal integration to enhance LLMs’ customization and practical use in this field. This paper aims to spark ideas for bridging the gap between LLMs capabilities and practical building applications, offering insights into the future of LLM-driven methods in building energy applications. © 2025 Elsevier B.V., All rights reserved.","Cited by: 25 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1007/s12273-025-1235-9,Building energy; Building energy application; Energy; Energy applications; Energy management opti...,,,,,,,
rayyan-394626687,Toward Automated Simulation Research Workflow through LLM Prompt Engineering Design,2025,,,Journal of Chemical Information and Modeling,,65,1,114 - 124,"Liu, Zhihan and Chai, Yubo and Li, Jianfeng",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214789637&doi=10.1021%2Facs.jcim.4c01653&partnerID=40&md5=5e463256a99054ecebebcdef6126457a,,,,"The advent of Large Language Models (LLMs) has created new opportunities for the automation of scientific research spanning both experimental processes and computational simulations. This study explores the feasibility of constructing an autonomous simulation agent (ASA) powered by LLMs through prompt engineering and automated program design to automate the entire simulation research process according to a human-provided research plan. This process includes experimental design, remote upload and simulation execution, data analysis, and report compilation. Using a well-studied simulation problem of polymer chain conformations as a test case, we assessed the long-task completion and reliability of ASAs powered by different LLMs, including GPT-4o, Claude-3.5, etc. Our findings revealed that ASA-GPT-4o achieved near-flawless execution on designated research missions, underscoring the potential of methods like ASA to achieve automation in simulation research processes to enhance research efficiency. The outlined automation can be iteratively performed for up to 20 cycles without human intervention, illustrating the potential of ASA for long-task workflow automation. Additionally, we discussed the intrinsic traits of ASA in managing extensive tasks, focusing on self-validation mechanisms, and the balance between local attention and global oversight. © 2025 Elsevier B.V., All rights reserved.","Cited by: 5 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1021/acs.jcim.4c01653,Design of experiments; Digital elevation model; Engineering research; Computational simulation; E...,,,,,,,
rayyan-394626688,"GreenAI@AIxIA 2024 - Proceedings of the 1st AIxIA Workshop on Green-Aware Artificial Intelligence, co-located with the 23rd International Conference of the Italian Association for Artificial Intelligence, AIxIA 2024",2025,,,CEUR Workshop Proceedings,,3934,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000729871&partnerID=40&md5=eeaec515a859a5a55d8bca4f0766a654,,,,"The proceedings contain 7 papers. The topics discussed include: exploiting outlier explanation to unveil key-aspects of high green comparative advantage nations; on the environmental impact of the algorithm LatentOut for unsupervised anomaly detection; a lightweight meta-feature extraction strategy for deep reinforcement anomaly detection; enhancing the evaluation of fault detection models in smart agriculture using LLM agents for rule-based anomaly generation; a declarative framework for temporal reasoning in green-aware applications; and optimizing photosensor placement for energy-efficient lighting in sustainable building design based on multivariate long short-term memory models. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626689,Enhancing the Evaluation of Fault Detection Models in Smart Agriculture Using LLM Agents for Rule-Based Anomaly Generation,2025,,,CEUR Workshop Proceedings,,3934,,29 - 39,"Lindia, Paolo and Cantini, Riccardo and Bettucci, Francesco and Sartori, Luigi and Trunfio, Paolo",https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000713671&partnerID=40&md5=69b6824aea49063787b90e9d59bcf947,,,,"In the context of Agriculture 4.0, advanced technologies such as the Internet of Things (IoT), artificial intelligence (AI), and big data analytics play a critical role in enhancing the efficiency and sustainability of farming operations. These innovations enable real-time monitoring and decision-making, improving the efficiency, sustainability, and productivity of agricultural systems. Central to Agriculture 4.0 is the deployment of sensors embedded in agricultural machinery, such as tractors, which continuously collect data on key operational metrics, including engine performance, fuel consumption, soil conditions, and equipment health. The effective analysis of such data is essential for predictive maintenance, as early detection of potential anomalies can prevent costly breakdowns and reduce downtime. However, finding real-world datasets containing examples of anomalies in agricultural machinery is highly challenging, making it difficult to develop and assess the effectiveness of anomaly detection models. Additionally, classical methods for anomaly generation, such as stochastic and adversarial approaches, may be difficult to apply given the intricate patterns and time dependency of these data. To address this gap, our work leverages Large Language Models (LLMs) and agentic workflows to generate realistic anomaly scenarios from agricultural data. Using a rule-based approach that combines prompt engineering techniques with a multiagent system, we create synthetic anomalies that can later be used to evaluate anomaly detection models. These models would then enable the timely identification of potential machinery failures, reducing maintenance costs, minimizing downtime, and significantly lowering the environmental impact by preventing inefficiencies such as increased fuel consumption from faulty equipment, reducing the need for replacement parts, and conserving energy and resources used in repairs. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",,Agricultural robots; Fertilizers; Tractors (agricultural); Agentic workflow; Anomaly detection; A...,,,,,,,
rayyan-394626690,"Proceedings of the 6th Northern Lights Deep Learning Conference, NLDL 2025",2025,,,Proceedings of Machine Learning Research,,265,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219153965&partnerID=40&md5=904661ee7560cb40123aaa611b569b83,,,,"The proceedings contain 27 papers. The topics discussed include: hallucination detection in LLMs: fast and memory-efficient finetuned models; towards concurrent real-time audio-aware agents with deep reinforcement learning; connecting concept convexity and human-machine alignment in deep neural networks; BoRA: Bayesian hierarchical low-rank adaption for multi-task large language models; familiarity-based open-set recognition under adversarial attacks; world model agents with change-based intrinsic motivation; graph counterfactual explainable AI via latent space traversal; enhancing fault detection in optical networks with conditional denoising diffusion probabilistic models; one-class SVM-guided negative sampling for enhanced contrastive learning; and interpretable function approximation with gaussian processes in value-based model-free reinforcement learning. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626691,GoNoGo: An Efficient LLM-Based Multi-agent System for Streamlining Automotive Software Release Decision-Making,2025,,,Lecture Notes in Computer Science,,15383,,30 - 45,"Khoee, Arsham Gholamzadeh and Yu, Yinan and Feldt, Robert and Freimanis, Andris and Rhodin, Patrick Andersson and Parthasarathy, Dhasarathy",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218471609&doi=10.1007%2F978-3-031-80889-0_3&partnerID=40&md5=3325c301104063a92e08d80fbd7754fa,,,,"Traditional methods for making software deployment decisions in the automotive industry typically rely on manual analysis of tabular software test data. These methods often lead to higher costs and delays in the software release cycle due to their labor-intensive nature. Large Language Models (LLMs) present a promising solution to these challenges. However, their application generally demands multiple rounds of human-driven prompt engineering, which limits their practical deployment, particularly for industrial end-users who need reliable and efficient results. In this paper, we propose GoNoGo, an LLM agent system designed to streamline automotive software deployment while meeting both functional requirements and practical industrial constraints. Unlike previous systems, GoNoGo is specifically tailored to address domain-specific and risk-sensitive systems. We evaluate GoNoGo’s performance across different task difficulties using zero-shot and few-shot examples taken from industrial practice. Our results show that GoNoGo achieves a 100% success rate for tasks up to Level 2 difficulty with 3-shot examples, and maintains high performance even for more complex tasks. We find that GoNoGo effectively automates decision-making for simpler tasks, significantly reducing the need for manual intervention. In summary, GoNoGo represents an efficient and user-friendly LLM-based solution currently employed in our industrial partner’s company to assist with software release decision-making, supporting more informed and timely decisions in the release process for risk-sensitive vehicle systems. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1007/978-3-031-80889-0_3,Application programs; Chemical plants; Competition; Computer program listings; Computer software ...,,,,,,,
rayyan-394626692,Generation of Rational Drug-like Molecular Structures Through a Multiple-Objective Reinforcement Learning Framework,2025,,,Molecules,,30,1,,"Zhang, Xiangying and Gao, Haotian and Qi, Yifei and Li, Yan and Wang, Renxiao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214453638&doi=10.3390%2Fmolecules30010018&partnerID=40&md5=607c2e4d9b3ae71532881db36e2c5538,,,,"As an appealing approach for discovering novel leads, the key advantage of de novo drug design lies in its ability to explore a much broader dimension of chemical space, without being confined to the knowledge of existing compounds. So far, many generative models have been described in the literature, which have completely redefined the concept of de novo drug design. However, many of them lack practical value for real-world drug discovery. In this work, we have developed a graph-based generative model within a reinforcement learning framework, namely, METEOR (Molecular Exploration Through multiplE-Objective Reinforcement). The backend agent of METEOR is based on the well-established GCPN model. To ensure the overall quality of the generated molecular graphs, we implemented a set of rules to identify and exclude undesired substructures. Importantly, METEOR is designed to conduct multi-objective optimization, i.e., simultaneously optimizing binding affinity, drug-likeness, and synthetic accessibility of the generated molecules under the guidance of a special reward function. We demonstrate in a specific test case that without prior knowledge of true binders to the chosen target protein, METEOR generated molecules with superior properties compared to those in the ZINC 250k data set. In conclusion, we have demonstrated the potential of METEOR as a practical tool for generating rational drug-like molecules in the early phase of drug discovery. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.3390/molecules30010018,algorithm; chemical structure; drug design; drug development; machine learning; procedures; Algor...,,,,,,,
rayyan-394626693,Using Large Language Models for Efficient Cancer Registry Coding in the Real Hospital Setting: A Feasibility Study,2025,,,Pacific Symposium on Biocomputing,,30,,121 - 137,"Wang, Chenkai and Ke, Chengrong and Huang, Ming Siang and Chong, Inn Wen and Yang, Yihsin and Tseng, S. Vincent Shin Mu and Dai, Hong Jie",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212611510&partnerID=40&md5=59439a85628c0fdd94322a4ad548c719,,,,"The primary challenge in reporting cancer cases lies in the labor-intensive and time-consuming process of manually reviewing numerous reports. Current methods predominantly rely on rule-based approaches or custom-supervised learning models, which predict diagnostic codes based on a single pathology report per patient. Although these methods show promising evaluation results, their biased outcomes in controlled settings may hinder adaption to real-world reporting workflows. In this feasibility study, we focused on lung cancer as a test case and developed an agentic retrieval-augmented generation (RAG) system to evaluate the potential of publicly available large language models (LLMs) for cancer registry coding. Our findings demonstrate that: (1) directly applying publicly available LLMs without fine-tuning is feasible for cancer registry coding; and (2) prompt engineering can significantly enhance the capability of pre-trained LLMs in cancer registry coding. The off-the-shelf LLM, combined with our proposed system architecture and basic prompts, achieved a macro-averaged F-score of 0.637 when evaluated on testing data consisting of patients' medical reports spanning 1.5 years since their first visit. By employing chain of thought (CoT) reasoning and our proposed coding item grouping, the system outperformed the baseline by 0.187 in terms of the macro-averaged F-score. These findings demonstrate the great potential of leveraging LLMs with prompt engineering for cancer registry coding. Our system could offer cancer registrars a promising reference tool to enhance their daily workflow, improving efficiency and accuracy in cancer case reporting. This record is sourced from MEDLINE/PubMed, a database of the U.S. National Library of Medicine","Cited by: 3 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",,bioinformatics; coding; electronic health record; feasibility study; genetics; human; lung tumor;...,,,,,,,
rayyan-394626694,Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems,2025,,,IEEE Transactions on Smart Grid,,,,,"Yang, Xu and Lin, Chenhui and Yang, Yue and Wang, Qi and Liu, Haotian and Hua, Haizhou and Wu, Wenchuan",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019566609&doi=10.1109%2FTSG.2025.3621438&partnerID=40&md5=68dfb9b5c2d3ab4a551251e9df834cbd,,,,"The increasing penetration of distributed energy resources into active distribution networks (ADNs) has made effective ADN dispatch imperative. However, the numerous newly-integrated ADN operators, such as distribution system aggregators, virtual power plant managers, and end prosumers, often lack specialized expertise in power system operation, modeling, optimization, and programming. This knowledge gap renders reliance on human experts both costly and time-intensive. To address this challenge and enable intelligent, flexible ADN dispatch, this paper proposes a large language model (LLM) powered automated modeling and optimization approach. First, the ADN dispatch problems are decomposed into sequential stages, and a multi-LLM coordination architecture is designed. This framework comprises an Information Extractor, a Problem Formulator, and a Code Programmer, tasked with information retrieval, optimization problem formulation, and code implementation, respectively. Afterwards, tailored refinement techniques are developed for each LLM agent, greatly improving the accuracy and reliability of generated content. The proposed approach features a user-centric interface that enables ADN operators to derive dispatch strategies via simple natural language queries, eliminating technical barriers and increasing efficiency. Comprehensive comparisons and end-to-end demonstrations on various test cases validate the effectiveness of the proposed architecture and methods. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.1109/TSG.2025.3621438,Codes (symbols); Computer systems programming; Distributed energy; Electric load dispatching; Ele...,,,,,,,
rayyan-394626695,Construction and Application of Multi-Agent Large Language Model for Power Transformer Fault Diagnosis,2025,,,Hsi-An Chiao Tung Ta Hsueh/Journal of Xi'an Jiaotong University,,59,10,22 - 31,"Lin, Jinshan and Li, Yuan and Fang, Qixuan and Liu, Zhihao and Li, Chunpeng and Zhang, Guanjun",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019306654&doi=10.7652%2Fxjtuxb202510002&partnerID=40&md5=3e6e289ad9bf59cea6a49c54fd4af95a,,,,"To address the limited applicability of traditional small language models and the unsatisfactory diagnostic effects caused by the multi-dimensional heterogeneity of state parameters and data loss in power transformers,a multi-agent large language model framework for transformer fault diagnosis is proposed.The framework establishes a collaborative reasoning system with fault cases knowledge graph and three agents.The fault cases knowledge graph constraint mechanism significantly enhances the large language model's understanding of power engineering expertise while effectively mitigating machine hallucination.Three agents simulate expert diagnostic processes by decomposing complex transformer fault diagnosis tasks.Primary diagnostic agents perform preliminary fault identification through feature threshold analysis, expert diagnostic agents conduct uncertainty reasoning on typical fault patterns using probabilistic graphical models,and case analysis agents access a historical fault case database to enable knowledge retrieval and diagnostic result validation.Validation results show that the proposed model achieves excellent performance in diagnosing 100 fault cases,with an accuracy rate of 86%,representing a 33% improvement over the BERT model.The integration of the fault cases knowledge graph enhances the large language model's output in terms of completeness,semantic consistency,and professional depth,with an expert rating average performance increase of 50%. This multi-agent large language model demonstrates superior performance in reducing misjudgment rates compared to monolithic large language models,and can provide technical support for intelligent fault diagnosis and operation and maintenance of power transformers. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.7652/xjtuxb202510002,Graphic methods; Information retrieval; Intelligent agents; Knowledge graph; Multi agent systems;...,,,,,,,
rayyan-394626696,Are numerical or verbal explanations of AI the key to appropriate user reliance and error detection?,2025,,,Behaviour and Information Technology,,,,,"Papenkordt, Jorg and Ngonga-Ngomo, Axel Cyrille and Thommes, Kirsten",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018808566&doi=10.1080%2F0144929X.2025.2568928&partnerID=40&md5=d5359ee5c3db500514d61fa5011c91cc,,,,"Advances in AI and our limited human capabilities have made AI decision-making opaque to humans. One prerequisite for enhancing the transparency of AI recommendations is improving AI explainability as humans need to be enabled to take responsibility for their actions even with AI support. Our study aims to tackle this issue by investigating two basic approaches to explainability: We evaluate numerical explanations, such as certainty measures, against verbal explanations, such as those provided by LLM as explanatory agents. Specifically, we examine whether verbal or numerical (or both) explanations in tasks of high uncertainty lure users into false beliefs or, on the contrary, promote appropriate reliance. Drawing on an experiment with 441 participants, we explore the dynamics of non-expert users' interactions with AI under varying explanatory conditions. Results show that explanations significantly improve reliance and decision accuracy. Numerical explanations aid in identifying uncertainties and errors, but the users' reliance on the advice falls far behind the given numerical certainty. Verbal explanations foster higher reliance while increasing the risk of over-reliance. Combining both explanation types enhances reliance but further amplifies blind trust in AI. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Hybrid Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1080/0144929X.2025.2568928,Artificial intelligence; Decision making; Error detection; Computer interaction; Decisions making...,,,,,,,
rayyan-394626697,Beyond Test Cases: Multi-Agent Collaboration for Detecting Defects in Full-Score Code Implementations,2025,,,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",,,,124 - 129,"Li, Yiwei and Liu, Jiaxin and Hu, Yanfeng and Liu, Chen and Zhang, Yating and Yin, Liangze and Dong, Wei",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018743838&doi=10.18293%2FSEKE2025-053&partnerID=40&md5=6b4813dad78e2b4f3340c1ac6b4a3fe8,,,,"Automated evaluation of programming code on online platforms often relies on predefined test cases. However, due to limited test coverage, many programs receive full marks despite violating intended specifications. We present Maveric, a framework that combines large language models (LLMs) with formal verification to more rigorously assess code correctness. Maveric consists of four agents: a template generator that derives formal specifications from problem descriptions, a consistency checker that validates semantic alignment, a code analyzer that detects potential defects and synthesizes counterexamples, and a counterexample validator that formally verifies their validity. We evaluated Maveric on 100 full-score code submissions from 10 real-world programming tasks sourced from a widely used online education platform. Manual review identified 32 with functional defects. Maveric accurately detected 31 of these with no false positives, completing the evaluation of each program in under one minute. In contrast, LLM-only methods detected 25 defects but yielded 6 false positives, while formal verification alone found 23 and suffered frequent timeouts. Importantly, all defects reported by Maveric were supported by verifiable counterexamples, confirming their semantic violations. These results demonstrate Maveric’s effectiveness and practicality for automated program evaluation in educational settings. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.18293/SEKE2025-053,Codes (symbols); Computer programming languages; Computer systems programming; Defects; E-learnin...,,,,,,,
rayyan-394626698,Comparative Study on Test Case generation using Generative AI,2025,,,,,,,366 - 369,"Azzam, Adham and Hany, Omar and Mansour, Hesham",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018464135&doi=10.1109%2FIMSA65733.2025.11166964&partnerID=40&md5=b86914aaa102a4a2761613b1734aa6aa,,,,"Testing is an important part of Development life cycle, resource intensive and prone to human error. Over the years, various tools have been developed, with a recent surge in those based on Large Language Models (LLMs). Examples include prompting LLMs in chat applications to generate test cases or using AI agents with project context to generate tests. This paper comparatively studies the most prominent open and closed-source models available at the time of writing. This paper covers the most famous open and closed source models as of the date of writing this paper in a comparative study. This study analyzes each model's characteristics and performance against well known metrics like average code coverage and mutation score. While closed source models Like GPT-4o are demonstrating better performance than all other models at 35.2% coverage, some open source models such as Llama 3.1 70B is demonstrating significantly p romising p erformance with 30.6% coverage, or models like DeepSeekCoderV2 16B that have a better chance of running locally in a normal home setting with 28.2% coverage. This study highlights LLM capabilities in automated test generation. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""secundario ?""]}",10.1109/IMSA65733.2025.11166964,Artificial intelligence; Open source software; Open systems; Closed source; Comparatives studies;...,,,,,,,
rayyan-394626699,An LLM-based software developer agent demonstrated through a port-logistic optimization case study,2025,,,,,,,,"Dulai, Tibor and Kiss, Gábor",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018454710&doi=10.1109%2FACDSA65407.2025.11166656&partnerID=40&md5=07beea4a4eddd6e7f441df7515005770,,,,"Advancements in artificial intelligence (AI) are having a significant impact across various domains. Among these, generative AI models - particularly large language models (LLMs) - have brought substantial changes to a wide range of activities and professions. As these models are capable of handling complex business workflows and interacting with external tools (e.g., via APIs), their agentic behaviour becomes especially valuable for supporting diverse workflows. Software development is one of the domains that can greatly benefit from the use of LLM-based agents. We have developed a software developer agent using the LangGraph platform, capable of generating and validating the software requirements specification (SRS), design document specification (DDS), project structure, function implementations, and corresponding unit tests - all based on a well-formulated input prompt. After successfully testing the agent on the relatively simple task of generating a Snake game, we applied it to a more complex problem: an optimization scenario. A simulation framework was developed to optimize port logistics processes, such as routing and scheduling trucks and vessels. This framework allows for port structure customization and, thanks to its modular design, supports the evaluation of various optimization algorithms. Using this framework, we investigated how our software developer agent performs on a significantly more complex coding task compared to the Snake game. We also compared the results with those generated by two widely used LLM-based systems: ChatGPT and Gemini Code Assist. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/ACDSA65407.2025.11166656,Computer programming; Intelligent agents; Logistics; Ports and harbors; Software testing; Specifi...,,,,,,,
rayyan-394626700,"Multi-Agent LLM Collaboration for Adaptive Code Review, Debugging, and Security Analysis",2025,,,,,,,541 - 546,"Sharanarthi, Tanush and Polineni, Sreenidhi",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017962329&doi=10.1109%2FMRAI65197.2025.11135756&partnerID=40&md5=c1c8dcd7efc5a31fdf3f2f8723e6caf1,,,,"Automated code review systems have improved software development, yet many lack contextual awareness, leading to redundant feedback and limited adaptability to user-specific coding styles. This paper presents a multi-agent AI-driven framework that leverages FAISS-based memory to improve review efficiency, personalization, and collaboration. The system integrates code review, bug detection, and security analysis agents, operating independently and interactively to analyze and refine code submissions. A feedback mechanism enables users to influence future AI suggestions, ensuring that recommendations evolve based on individual preferences and past interactions. Through structured experiments, we evaluated the impact of FAISS memory on the reduction of redundant feedback, evaluated the effectiveness of collaborative agent execution, and measured the system's ability to adapt to coding patterns over time. The results indicate that the incorporation of FAISS significantly improves AI-assisted development by minimizing unnecessary repetitions while maintaining essential corrective feedback. This research demonstrates the potential of adaptive AI systems in software engineering, contributing to more intelligent, context-aware, and efficient code review methodologies. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/MRAI65197.2025.11135756,Codes (symbols); Computer programming languages; Computer software selection and evaluation; Dist...,,,,,,,
rayyan-394626701,Seeing is Believing: Vision-driven Non-crash Functional Bug Detection for Mobile Apps,2025,,,IEEE Transactions on Software Engineering,,,,,"Liu, Zhe and Li, Cheng and Chen, Chunyang and Wang, Junjie and Chen, Mengzhuo and Wu, Boyu and Wang, Yawen and Hu, Jun and Wang, Qing",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017652583&doi=10.1109%2FTSE.2025.3614469&partnerID=40&md5=4e5a57b6552e186ec4d8233dee3c822c,,,,"Mobile app GUI (Graphical User Interface) pages now contain rich visual information, with the visual semantics of each page helping users understand the application logic. However, these complex visual and functional logics present new challenges to software testing. Existing automated GUI testing methods, constrained by the lack of reliable testing oracles, are limited to detecting crash bugs with obvious abnormal signals. Consequently, many non-crash functional bugs, ranging from unexpected behaviors to logical errors, often evade detection by current techniques. While these non-crash functional bugs can exhibit visual cues that serve as potential testing oracles, they often entail a sequence of screenshots, and detecting them necessitates an understanding of the operational logic among GUI page transitions, which is challenging traditional techniques. Considering the remarkable performance of Multimodal Large Language Models (MLLM) in visual and language understanding, this paper proposes VisionDroid, a novel vision-driven, multi-agent collaborative automated GUI testing approach for detecting non-crash functional bugs. It comprises three agents: Explorer, Monitor, and Detector, to guide the exploration, oversee the testing progress, and spot issues.We also address several challenges,i.e., aligning visual and textual information for MLLM input, achieving functionality-oriented exploration, and inferring test oracles for non-crash bugs, to enhance the performance of functionality bug detection. We evaluate VisionDroid on 590 non-crash bugs and compare it with 12 baselines, it can achieve more than 14%-112% and 108%-147% boost in average recall and precision compared with the best baseline. The ablation study further proves the contribution of each module. Moreover, VisionDroid identifies 43 unknown bugs on Google Play, of which 31 have been fixed. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/TSE.2025.3614469,Android (operating system); Automation; Computer vision; Graphical user interfaces; Mobile applic...,,,,,,,
rayyan-394626702,Enhancing LLM-based Quantum Code Generation with Multi-Agent Optimization and Quantum Error Correction,2025,,,,,,,,"Campbell, Charlie and Chen, Mark and Luk, Wayne W.C. and Fan, Hongxiang",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017605997&doi=10.1109%2FDAC63849.2025.11133316&partnerID=40&md5=27976ae3a148261af6d3b69c8ea47b27,,,,"Multi-agent frameworks with Large Language Models (LLMs) have become promising tools for generating generalpurpose programming languages using test-driven development, allowing developers to create more accurate and robust code. However, their potential has not been fully unleashed for domainspecific programming languages, where specific domain exhibits unique optimization opportunities for customized improvement. In this paper, we take the first step in exploring multi-agent code generation for quantum programs. By identifying the unique optimizations in quantum designs such as quantum error correction, we introduce a novel multi-agent framework tailored to generating accurate, fault-tolerant quantum code. Each agent in the framework focuses on distinct optimizations, iteratively refining the code using a semantic analyzer with multi-pass inference, alongside an error correction code decoder. We also examine the effectiveness of traditional techniques, like Chain-ofThought (CoT) and Retrieval-Augmented Generation (RAG) in the context of quantum programming, uncovering observations that are different from general-purpose code generation. To evaluate our approach, we develop a test suite to measure the impact each optimization has on the accuracy of the generated code. Our findings indicate that techniques such as structured CoT significantly improve the generation of quantum algorithms by up to 50%. In contrast, we have also found that certain techniques such as RAG show limited improvement, yielding an accuracy increase of only 4%. Moreover, we showcase examples of AIassisted quantum error prediction and correction, demonstrating the effectiveness of our multi-agent framework in reducing the errors of generated quantum programs. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/DAC63849.2025.11133316,Automatic programming; Computer programming languages; Error correction; Intelligent agents; Iter...,,,,,,,
rayyan-394626703,"2025 IEEE/ACM 33rd International Symposium on Quality of Service, IWQoS 2025",2025,,,"IEEE International Workshop on Quality of Service, IWQoS",,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017058102&partnerID=40&md5=bc8f32c18ed9b5f0c5c2909ff4056ca2,,,,"The proceedings contain 144 papers. The topics discussed include: handling data plane program deployment dynamics with high-quality generative diffusion models; divide and conquer: the first step towards adaptable internet of models; multi-range query in commodity RFID systems; NetMAS: efficient network configuration translation with multi-agent system; deploy efficient large language model distributed inference pipeline for heterogeneous GPUs; embedding more knowledge: strategic graph masking based advanced persistent threats detection; HFHEMS: energy-efficient hierarchical federated learning via model distillation; Monica: towards scalable distributed system verification by programmable switch-based testing; and diffusion-type AIGC request scheduling with inference sharing. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626704,LLM4VC: Harnessing Large Language Models for Virtual Commissioning of IEC 61499 Automation Systems,2025,,,IEEE International Symposium on Industrial Electronics,,,,,"Lyu, Tuojian and Atmojo, Udayanto Dwi and Vyatkin, Valeriy V.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016246391&doi=10.1109%2FISIE62713.2025.11124673&partnerID=40&md5=c23162cb2d364391660580df62dfc540,,,,"This paper addresses a critical deficiency of virtual commissioning systems developed for industrial automation: they lack the ability to analyze the avalanche of generated events and recognize faulty situations in them efficiently. The solution, called LLM4VC, is a cloud-based pipeline that turns a large language model into an LLM-based Validation Agent (LVA). It is an autonomous program that ingests human-centred specifications and produces pass/fail verdicts for distributed IEC 61499 systems automatically during testing. The agent's knowledge is derived from user-approved artifacts: the Sequence of Operations (SOO) and the Cause-&-Effect matrix (C&E), and users' prompts. A lightweight parser plus GPT models prompts converts these materials into a Machine-Readable Expected Behavior (MREB), which is a JSON document enriched with timing requirements and interlock rules. A Python script streams normalized runtime logs from mul-tiple SoftPLC containers. At run time the LVA uses MREB and SoftPLC logs to generate a structured verdict together with a human-readable description. We demonstrate LLM4VC on a four-controller conveyor and jack system containing manually injected fault scenarios. The agent analyses about 12 000 log lines in around 38 s per test, identifies most of the injected faults and produces traceable explanations suitable for factory acceptance reports without manual intervention or hard-coded rules. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/ISIE62713.2025.11124673,Automatic test pattern generation; Automation; Distributed computer systems; Software testing; Ve...,,,,,,,
rayyan-394626705,Automated Code Review In Practice,2025,,,IEEE/ACM International Conference on Software Engineering - Software Engineering in Practice,,,2025,425 - 436,"Cihan, Umut and Haratian, Vahid and İçöz, Arda and Gül, Mert Kaan and Devran, Ömercan and Bayendur, Emircan Furkan and Uçar, Baykal Mehmet and Tüzün, Eray",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016229873&doi=10.1109%2FICSE-SEIP66354.2025.00043&partnerID=40&md5=3cfa33e95f22293c166be73421a758c3,,,,"Context: Code review is a widespread practice among practitioners to improve software quality and transfer knowledge. It is often perceived as time-consuming due to the need for manual effort and potential delays in the development process. Several AI-assisted code review tools (Qodo, GitHub Copilot, Coderabbit, etc.) provide automated code reviews using large language models (LLMs). The overall effects of such tools in the industry setting are yet to be examined. Objective: This study examines the impact of LLM-based automated code review tools in an industry setting. Method: The study was conducted within an industrial software development environment that adopted an AI-assisted code review tool (based on open-source Qodo PR Agent). 238 practitioners across ten projects had access to the tool. We focused our analysis on three projects, which included 4,335 pull requests, 1,568 of which underwent automated reviews. Our data collection comprised three sources: (1) a quantitative analysis of pull request data, including comment labels indicating whether developers acted on the automated comments, (2) surveys sent to developers regarding their experience with the reviews on individual pull requests, and (3) a broader survey of 22 practitioners capturing their general opinions on automated code reviews. Results: 73.8% of automated code review comments were labeled as resolved. However, the overall average pull request closure duration increased from five hours 52 minutes to eight hours 20 minutes, with varying trends observed across different projects. According to survey responses, most practitioners observed a minor improvement in code quality as a result of automated code reviews. Conclusion: The LLM-based automated code review tool proved useful in software development, enhancing bug detection, increasing awareness of code quality, and promoting best practices. However, it also led to longer pull request closure times and introduced drawbacks such as faulty reviews, unnecessary corrections, and irrelevant comments. Based on these findings, we discussed how practitioners can more effectively utilize automated code review technologies. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""secundario  ?""]}",10.1109/ICSE-SEIP66354.2025.00043,Codes (symbols); Computer programming languages; Computer software selection and evaluation; Know...,,,,,,,
rayyan-394626706,Enhancing Adaptive Test Healing with Graph Neural Networks for Dependency-Aware Decision Making,2025,,,,,,,126 - 133,"Mani, Nariman and Attaranasl, Salma",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016218817&doi=10.1109%2FAITest66680.2025.00023&partnerID=40&md5=7fc73908915069f8672327d6b6f14248,,,,"Flaky tests are a major obstacle in modern CI/CD pipelines, leading to unreliable feedback, increased reruns, and developer frustration. Our previously published adaptive healing framework combined Large Language Models (LLMs) and Reinforcement Learning (RL) to automate flaky test recovery, but it assumed test independence and failed to account for structural dependencies between tests. In this paper, we introduce a significant extension to that baseline: a Graph Neural Network (GNN)-based Test Dependency Mapping layer that models inter-test relationships. By integrating GNN embeddings with LLM-classified failures, the RL agent becomes dependency-aware, enabling more precise and efficient healing decisions. We evaluate the enhanced framework on a real-world industrial platform, a social lifestyle application actively used by thousands of users for health, nutrition, and coaching. Results show a 90% reduction in flaky test-related costs and faster, autonomous resolution of dependency-induced failures. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/AITest66680.2025.00023,Computer system recovery; Distributed computer systems; Human computer interaction; Machine learn...,,,,,,,
rayyan-394626707,OpenROAD Agent: An Intelligent Self-Correcting Script Generator for OpenROAD,2025,,,,,,,16 - 22,"Wu, Bingyue and Sharma, Utsav and Rovinski, Austin and Chhabria, Vidya A.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015871212&doi=10.1109%2FICLAD65226.2025.00039&partnerID=40&md5=163d4d6230f67a28f31669c32c0f1cfa,,,,"Large language models (LLMs) are increasingly being used in various domains, including chip design. Recent works have demonstrated the effectiveness of LLMs in EDA tool script generation. However, these LLMs can often hallucinate API calls even when directly provided API documentation and context. As a result, this leads to significant errors and inefficiencies in chip design workflows. To address this, we introduce OpenROAD Agent, an LLM that integrates directly with OpenROAD, an open-source tool for physical design. OpenROAD Agent enables real-time script generation with error detection and correction. OpenROAD Agent autonomously generates and executes Python code within OpenROAD while dynamically refining outputs based on tool feedback. OpenROAD Agent leverages Qwen2.5-Coder and employs a hybrid supervised and reinforcement learning training to improve code correction capabilities, usability, and hallucination frequency. OpenROAD Agent achieves an accuracy of 94% on script generation tasks and outperforms both prior work and existing foundation models. The model, data, and scripts are open-sourced and publicly available. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/ICLAD65226.2025.00039,Computational linguistics; Integrated circuit design; Open source software; Open systems; Personn...,,,,,,,
rayyan-394626708,A New Paradigm for Scientific Computing: Accelerated Algorithm Development With Large Reasoning Models,2025,,,IEEE Access,,13,,159749 - 159773,"Kokkinakis, Ioannis W. and Drikakis, Dimitris",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015762032&doi=10.1109%2FACCESS.2025.3607265&partnerID=40&md5=c2bbeb2cbdb3514df978d9d0e84740bc,,,,"This study examines the application of Large Reasoning Model (LRM)-based artificial intelligence (AI) agents to accelerate scientific discovery, with a specific focus on the rapid prototyping of numerical algorithms. The research demonstrates that current-generation LRM-based AI agents, when collaborating with human experts, can significantly expedite the development of complex algorithms by formalizing a Human-in-the-Loop (HIL) plus Chain-of-Thought (CoT) workflow and introducing, to our knowledge, the first quantitative benchmark of LRMs on a CFD algorithm derivation task. We test the hypothesis that CoT prompting plus domain-expert oversight reduces the derivation error rate and development time of high-order numerical schemes relative to typical prompting, and we instantiate this hypothesis in a cross-model evaluation suite with end-to-end feasibility, from symbolic derivation (polynomials and smoothness indicators) to automated code generation and solver-level validation. The novelty lies in the use of advanced reasoning artificial intelligence (AI) models to assist in the algorithm development process. To this end, the derivation of key formulae within the widely utilized Weighted Essentially Non-Oscillatory (WENO) algorithm –a high-order algorithm applicable to various fields such as fluid dynamics, astrophysics, and medical imaging– serves as a case study. We employ the WENO algorithm as a test case to help evaluate and demonstrate the capabilities of several AI models in this context, thereby laying the foundation for future research and development in this field. The interaction between a human expert and an LRM was examined in the context of designing and deploying a WENO scheme for simulating vortical flows. Initial AI-generated responses, while generally accurate, required iterative refinement guided by expert knowledge and a CoT approach to correct minor errors and optimize performance. This iterative process demonstrated the importance of user involvement, fostering both deeper engagement and a clearer understanding of the algorithm’s intricacies. Optimal performance was achieved through a collaborative partnership that leverages the AI’s computational speed and the human’s ability to perform logical decomposition and error detection. This collaborative approach facilitates the rapid development of tailored solutions. This study highlights the transformative potential of AI copilots in scientific research, showing that their effectiveness is maximized through synergy with domain experts. The findings suggest that artificial intelligence is poised to significantly accelerate research and development, driving scientific innovation. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1109/ACCESS.2025.3607265,Astrophysics; Deep learning; Error detection; Intelligent agents; Iterative methods; Medical imag...,,,,,,,
rayyan-394626709,Toward Generative 6G Simulation: An Experimental Multi-Agent LLM and ns-3 Integration,2025,,,,,,,,"Rezazadeh, Farhad and Gargari, Amir Ashtari and Lagen, Sandra and Song, Houbing and Niyato, Dusit (Tao) and Liu, Lingjia",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015738145&doi=10.1109%2FMeditCom64437.2025.11104374&partnerID=40&md5=d97a85dffc69ab925ee5e4de28c33ce6,,,,"The move toward open Sixth-Generation (6G) networks necessitates a novel approach to full-stack simulation environments for evaluating complex technology developments before prototyping and real-world implementation. This paper introduces an innovative approach<sup>1</sup>1 A lightweight, mock version of the code is available on GitHub at https://github.com/frezazadeh/LangChain-RAG-Technology that combines a multi-agent framework with the Network Simulator 3 (ns-3) to automate and optimize the generation, debugging, execution, and analysis of complex Fifth-Generation (5G) network scenarios. Our framework orchestrates a suite of specialized agents - namely, the Simulation Generation Agent, Test Designer Agent, Test Executor Agent, and Result Interpretation Agent - using advanced LangChain coordination. The Simulation Generation Agent employs a structured chain-of-thought (CoT) reasoning process, leveraging large language models (LLMs) and retrieval-augmented generation (RAG) to translate natural language simulation specifications into precise ns-3 scripts. Concurrently, the Test Designer Agent generates comprehensive automated test suites by integrating knowledge retrieval techniques with dynamic test case synthesis. The Test Executor Agent dynamically deploys and runs simulations, managing dependencies and parsing detailed performance metrics. At the same time, the Result Interpretation Agent utilizes LLM-driven analysis to extract actionable insights from the simulation outputs. By integrating external resources such as library documentation and ns-3 testing frameworks, our experimental approach can enhance simulation accuracy and adaptability, reducing reliance on extensive programming expertise. A detailed case study using the ns-3 5G-LENA module validates the effectiveness of the proposed approach. The code generation process converges in an average of 1.8 iterations, has a syntax error rate of 17.0%, a mean response time of 7.3 seconds, and receives a human evaluation score of 7.5. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/MeditCom64437.2025.11104374,Chains; Codes (symbols); Computational linguistics; Computer simulation languages; Computer syste...,,,,,,,
rayyan-394626710,ScriptDoctor: Automatic Generation of PuzzleScript Games via Large Language Models and Tree Search,2025,,,"IEEE Conference on Computatonal Intelligence and Games, CIG",,,,,"Earle, Sam and Khalifa, Ahmed and Nasir, Muhammad Umair and Jiang, Zehua and Todd, Graham and Banburski-Fahey, Andrzej and Togelius, Julian",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015532974&doi=10.1109%2FCoG64752.2025.11114269&partnerID=40&md5=dc7577af507fa177d736fc589fd984e4,,,,"There is much interest in using large pre-trained models in Automatic Game Design (AGD), whether via the generation of code, assets, or more abstract conceptualization of design ideas. But so far, this interest largely stems from the ad hoc use of such generative models under persistent human supervision. Much work remains to show how these tools can be integrated into longer-time-horizon AGD pipelines, in which systems interface with game engines to test generated content autonomously. To this end, we introduce ScriptDoctor, a Large Language Model (LLM)-driven system for automatically generating and testing games in PuzzleScript, an expressive but highly constrained description language for turn-based puzzle games over 2D gridworlds. ScriptDoctor generates and tests game design ideas in an iterative loop, where human-authored examples are used to ground the system's output, compilation errors from the PuzzleScript engine are used to elicit functional code, and search-based agents play-test generated games. ScriptDoctor serves as a concrete example of the potential of automated, openended LLM-based workflows in generating novel game content. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1109/CoG64752.2025.11114269,Artificial intelligence; Automatic programming; Automatic test pattern generation; Computer games...,,,,,,,
rayyan-394626711,AnalogTester: A Large Language Model-Based Framework for Automatic Testbench Generation in Analog Circuit Design,2025,,,,,,,201 - 207,"Chen, Weiyu and Liu, Chengjie and Huang, Wenhao and Lyu, Jinyang and Yang, Mingqian and Du, Yuan and Du, Li and Yang, Jun",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014240815&doi=10.1109%2FISEDA65950.2025.11100397&partnerID=40&md5=2b78a080f7650e49638baaf46a09097e,,,,"Recent advancements have demonstrated the significant potential of large language models (LLMs) in analog circuit design. Nevertheless, testbench construction for analog circuits remains manual, creating a critical bottleneck in achieving fully automated design processes. Particularly when replicating circuit designs from academic papers, manual Testbench construction demands time-intensive implementation and frequent adjustments, which fails to address the dynamic diversity and flexibility requirements for automation. AnalogTester tackles automated analog design challenges through an LLM-powered pipeline: a) domain-knowledge integration, b) paper information extraction, c) simulation scheme synthesis, and d) testbench code generation with Tsinghua Electronic Design (TED). AnalogTester has demonstrated automated Testbench generation capabilities for three fundamental analog circuit types: operational amplifiers (op-amps), bandgap references (BGRs), and low-dropout regulators (LDOs), while maintaining a scalable framework for adaptation to broader circuit topologies. Furthermore, AnalogTester can generate circuit knowledge data and TED code corpus, establishing fundamental training datasets for LLM specialization in analog circuit design automation. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/ISEDA65950.2025.11100397,Automatic programming; Automatic test pattern generation; Automation; Codes (symbols); Computer a...,,,,,,,
rayyan-394626712,"Smart Fault Detection, Classification, and Localization in Distribution Networks: AI-Driven Approaches and Emerging Technologies",2025,,,IEEE Access,,13,,141664 - 141693,"Wang, Jianxian and MOKHLIS, Hazlie Bin and Mansor, Nurulafiqah Nadzirah Binti and Illias, H. A. and Ramasamy, A. K. and Wu, Xingyu and Wang, Siqi",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013213396&doi=10.1109%2FACCESS.2025.3596791&partnerID=40&md5=6620f41706c9dfad001668e107acecaf,,,,"Distribution networks play a vital role in bridging transmission systems and end users, offering enhanced flexibility, decentralization, and the capacity to integrate distributed generation. However, with nations worldwide actively pursuing carbon neutrality and emission peak goals, sustainable energy sources such as solar and wind are increasingly penetrating distribution networks, posing significant challenges to conventional fault detection, classification, and localization techniques due to bidirectional power flows, dynamic fault currents, and rising network complexity. These challenges manifest as reduced sensitivity of protection systems in distribution networks, increased difficulty in identifying high impedance faults, and frequent misclassification or mislocation of faults under dynamic network conditions. To address these limitations, this paper presents a comprehensive review of artificial intelligence-driven approaches and emerging technologies that are specifically tailored for fault analysis in distribution networks, to enhance diagnostic accuracy, adaptability, and real-time decision-making efficiency. Following the chronological development of artificial intelligence, the review systematically investigates smart fault detection methods applied to fault scenarios in distribution networks, with a particular emphasis on presenting fault type classification and fault localization separately to facilitate a logically structured understanding. In addition, common types of distribution network faults are examined, and the impact of distributed generation on fault behavior, electrical characteristics, and protection coordination is critically assessed. The review further distinguishes between artificial intelligence-based smart approaches that directly process raw distribution networks signal data and those that rely on advanced feature extraction techniques to enhance functional performance. This review also explores the emerging potential of large language models to enhance the explainability of diagnostics, support multi-agent coordination, and enable natural language-based fault reasoning. The insights offered herein are expected to provide practical guidance for engineers and researchers for selecting and deploying intelligent fault diagnosis strategies in future distribution networks with high distributed generation penetration. © 2025 Elsevier B.V., All rights reserved.","Cited by: 2; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/ACCESS.2025.3596791,Behavioral research; Decision making; Electric fault location; Electric power system protection; ...,,,,,,,
rayyan-394626713,Automating Pedagogical Evaluation of LLM-based Conversational Agents,2025,,,CEUR Workshop Proceedings,,4006,,,"Pauzi, Zaki and Dodman, Michael and Mavrikis, Manolis",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013073650&partnerID=40&md5=20aa0d93db152a7b02de7aeedb0524fd,,,,"With the growing adoption of large language models (LLMs) in educational settings, there is an urgent need for systematic and scalable evaluation methods. Traditional natural language generation metrics such as BLEU, ROUGE and METEOR excel at measuring surface‐level linguistic quality but fall short in evaluating the interactive, adaptive nature of dialogue alignment of conversational agents, particularly in relation to their intended design. To address these gaps, we propose an evaluation strategy that extends beyond technical evaluation (linguistic coherence and semantic relevance). In this pilot study we compare human and LLM-based evaluation of a conversational agent, with a focus on Socratic dialogue as a specific instantiation. Early results indicate that our LLM-as-a-Judge aligns closely to human evaluators for clear, surface‐level qualities like encouragement and actionable guidance, but less on subtle pedagogical behaviours such as recognising errors and maintaining natural dialogue flow. These early results underscore the promise of LLM-based evaluators for scalable assessment of tutoring behaviours while highlighting the need for targeted fine-tuning and hybrid approaches to improve nuanced error detection and dialogue coherence. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",,Behavioral research; Computer aided instruction; Error detection; Information systems; Natural la...,,,,,,,
rayyan-394626714,AgentTester: An LLM-Based Tool for Unit Test Generation with Automatically Generated Prompts,2025,,,Communications in Computer and Information Science,,2574,,114 - 126,"Chen, Honghui and Chen, Kaiqing and Zhang, Fanlong and Wang, Tao and Cheng, Lianglun",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013062510&doi=10.1007%2F978-981-95-0011-6_10&partnerID=40&md5=b7408785d11617d826eacb243fc81dd8,,,,"Unit tests are critical for software reliability, yet manually writing them is laborious and time-consuming. While traditional tools like EvoSuite achieve high coverage, their low readability limits adoption. Recent LLM-based methods (e.g., AthenaTest, ChatTester) improve test readability but suffer from suboptimal prompt design and rigid template-based instructions that lack adaptability to different focal methods. To address these limitations, we propose AgentTester—an LLM-based method with three core components: 1) AutoPrompting that extracts the essential information of focal method and infers method intent, 2) Prompt Distillation to refine tailored test instructions via multi-temperature sampling before generating the unit tests, and 3) Validation-Repair for iterative error correction of buggy test cases. Experimental evaluations show AgentTester surpasses EvoSuite in line coverage and outperforms both AthenaTest and ChatTester in compilation rate, test correctness, and overall coverage. These results demonstrate AgentTester’s effectiveness in generating reliable, adaptable and universality unit tests. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1007/978-981-95-0011-6_10,Automatic test pattern generation; Error correction; Software reliability; Software testing; Auto...,,,,,,,
rayyan-394626715,Automatically Generated Multi-Agent Framework for Jailbreaking Large Language Models,2025,,,,,,,1500 - 1503,"Yang, Ao and Wang, Bin and Liu, Aofan and Li, Hui",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012115204&doi=10.1109%2FAIITA65135.2025.11047880&partnerID=40&md5=237cd5bd9ea7345c27fe9d37fecac33d,,,,"LLMs have developed rapidly at an unprecedented speed and are being widely used, including question answering, code generation and reasoning. LLMs are not completely safe and reliable, and may output harmful or illegal content under attack. Jailbreak attacks can bypass the security measures of LLMs and use LLMs to generate harmful content. However, jailbreak attack methods often rely on manually crafted prompt templates or not having sufficient diversity or jailbreak effect. In this paper, we introduce a new automatically generated multi-agent framework for automatic jailbreak testing of black-box large language models. We use the collaborative capabilities of multiple agents to automatically generate diverse jailbreak attack prompts to cover a wide range of vulnerability scenarios. We carefully implement three key modules: an automatically generated multi-agent framework, jailbreaking strategies for black-box large language models, and an iterative reflection mechanism. We evaluate on many different attack scenarios and multiple different black-box LLMs. Our results show that our work can achieve jailbreak with a high success rate. The attack success rate for GPT-4 exceeds 95%, which shows that our method can help current LLMs improve security and reliability. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1109/AIITA65135.2025.11047880,Automatic test pattern generation; Distributed computer systems; Intelligent agents; Iterative me...,,,,,,,
rayyan-394626716,Comprehensive Study on Integrating AI-Powered Threat Intelligence Using Large Language Models,2025,,,,,,,2141 - 2146,"Nishith, P. and Ratnam, S. Ajay and Bhaskaran, Sreebha",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012111569&doi=10.1109%2FICCSAI64074.2025.11063731&partnerID=40&md5=0ec7b8043470ba4929b72c5dbf36ce97,,,,"This paper presents a comprehensive analysis of algorithmic efficiency within automated testing tools, with a particular emphasis on integrating AI-powered threat intelligence through Large Language Models (LLMs) for enhanced penetration testing. The investigation focuses on measuring the time complexity, resource utilization, and various performance metrics of these tools. We extend our analysis to explore how LLMs and multi-agent systems can augment dynamic and static analysis during Automated Penetration Testing (APT). We rigorously quantify the performance of both in-house developed tools and existing automation frameworks, especially those that leverage LLMs. The primary goal is to evaluate the strengths and weaknesses of the algorithm by comparing the performance of the tool, analyzing the underlying algorithms, and evaluating critical aspects such as scalability, resource management, and optimization strategies to improve real-world applications, particularly in cybersecurity. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/ICCSAI64074.2025.11063731,Automation; Cybersecurity; Integration testing; Intelligent agents; Network security; Algorithmic...,,,,,,,
rayyan-394626718,Autonomous Cyber Incident Response Using Reasoning and Action,2025,,,,,,,1392 - 1397,"Baral, Sudipto and Saha, Sajal and Haque, Anwar",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011349572&doi=10.1109%2FIWCMC65282.2025.11059476&partnerID=40&md5=aa520127cde6b16a1cdead356f5cd146,,,,"The increasing complexity and frequency of cyber threats necessitate autonomous security solutions capable of real-time detection, reasoning, and response. This paper introduces an autonomous cyber incident response framework that integrates Reasoning and Acting (ReAct) agents with Large Language Models (LLMs) to enhance cybersecurity decision-making. The proposed system features a cloud-based testbed, real-time monitoring tools (Wazuh, Suricata), and a NATS messaging system for seamless threat detection and mitigation. The ReAct agent, powered by a fine-tuned LLM, iteratively analyzes security alerts, generates context-aware mitigation strategies, and autonomously executes response actions via integrated cybersecurity tools such as firewalls. The framework demonstrates its effectiveness in real-time cyberattack mitigation, including port scanning, botnet intrusions, and SSH brute-force attacks. By leveraging LangGraph-guided decision loops and Chain-of-Thought (CoT) reasoning, the system dynamically adapts to evolving threats while reducing reliance on human intervention. Evaluations in a simulated environment highlight the scalability of the architecture and its ability to achieve low-latency, autonomous threat mitigation. The findings highlight the potential of LLM-driven security automation in modern cyber defense strategies, paving the way for future advancements in mitigating phishing, malware, and insider threats. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1109/IWCMC65282.2025.11059476,Autonomous agents; Cybersecurity; Malware; Network security; Automated incident response; Autonom...,,,,,,,
rayyan-394626719,Transformer-Enhanced Intelligent Microgrid Self-Healing: Integrating Large Language Models and Adaptive Optimization for Real-Time Fault Detection and Recovery,2025,,,Energy Engineering: Journal of the Association of Energy Engineering,,122,7,2767 - 2800,"Gao, Qiang and Shen, Lei and Shi, Jiaming and Gu, Xinfa and Gu, Shanyun and Ge, Yuwei and Xie, Yang and Zhu, Xiaoqiong and Zang, Baoguo and Zhang, Ming and Nazir, Muhammad Shahzad and Ji, Jie",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011166206&doi=10.32604%2Fee.2025.065600&partnerID=40&md5=03a9cbbdd1316fa9cdc0b75cfe684a65,,,,"The rapid proliferation of renewable energy integration and escalating grid operational complexity have intensified demands for resilient self-healing mechanisms in modern power systems. Conventional approaches relying on static models and heuristic rules exhibit limitations in addressing dynamic fault propagation and multi-modal data fusion. This study proposes a Transformer-enhanced intelligent microgrid self-healing framework that synergizes large language models (LLMs) with adaptive optimization, achieving three key innovations: (1) A hierarchical attention mechanism incorporating grid impedance characteristics for spatiotemporal feature extraction, (2) Dynamic covariance estimation Kalman filtering with wavelet packet energy entropy thresholds (Daubechies-4 basis, 6-level decomposition), and (3) A grouping-stratified ant colony optimization algorithm featuring penalty-based pheromone updating. Validated on IEEE 33/100-node systems, our framework demonstrates 96.7% fault localization accuracy (23% improvement over STGCN) and 0.82-s protection delay, outperforming MILP-based methods by 37% in reconfiguration speed. The system maintains 98.4% self-healing success rate under cascading faults, resolving 89.3% of phase-to-ground faults within 500 ms through adaptive impedance matching. Field tests on 220 kV substations with 45% renewable penetration show 99.1% voltage stability (±5% deviation threshold) and 40% communication efficiency gains via compressed GOOSE message parsing. Comparative analysis reveals 12.6× faster convergence than conventional ACO in 1000-node networks, with 95.2% robustness against ±25% load fluctuations. These advancements provide a scalable solution for real-time fault recovery in renewable-dense grids, reducing outage duration by 63% in multi-agent simulations compared to centralized architectures. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.32604/ee.2025.065600,Computer system recovery; Distributed computer systems; Electric power transmission networks; Int...,,,,,,,
rayyan-394626720,An Efficient Federated Learning Framework for Enhancing Data Diversity and Communication in Industrial IoT Fault Diagnosis,2025,,,IEEE Internet of Things Journal,,12,17,36562 - 36576,"Sun, Xuehua and Yuan, Zengsen and Kong, Xianguang and Xue, Liang and Cheng, Han and Chen, Zhong",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010606708&doi=10.1109%2FJIOT.2025.3583081&partnerID=40&md5=b6407e852021500236d549577957199c,,,,"In the field of smart manufacturing, the widespread application of Industrial Internet of Things (IIoT) has prompted various data silos to generate and accumulate huge amounts of industrial data. To ensure the security of multiparty data, the industry has introduced federated learning (FL) technology to realize the circulation of data value by training machine learning models across silos. However, the nonindependent and identically distributed (Non-IID) nature of data distribution among different silos in real industrial environments, which results in degradation of model performance and increase in communication overheads, has become a key challenge that needs to be addressed. In this article, we propose a sparse quantization compression solution based on FL multiagent generative adversarial network (MAD-GAN) named SQC-FLMGAN, aiming to alleviate the problem of Non-IID data across silos in industrial environments and to improve communication efficiency. The scheme generates data samples with diversity and high quality for each client by training MAD-GAN models in an FL environment. This process effectively mitigates the modal collapse problem and improves the generalization ability and diagnostic accuracy of the model. In order to further reduce communication overhead, we have introduced an advanced model compression technique that combines Top-k sparsification and quantization methods. The Top-k algorithm selects crucial model parameters for transmission, while quantization further reduces their precision, eliminating redundancy in communication reducing the amount of data transmitted. Through experiments on the bearing dataset in industrial scenarios, we have demonstrated that the SQC-FLMGAN scheme significantly reduces communication overhead while maintaining model performance. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/JIOT.2025.3583081,Cost reduction; Data communication systems; Efficiency; Generative adversarial networks; Industri...,,,,,,,
rayyan-394626721,A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs,2025,,,Proceedings - International Conference on Software Engineering,,,,1409 - 1421,"Kim, Myeongsoo and Stennett, Tyler and Sinha, Saurabh and Orso, Alessandro",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010327327&doi=10.1109%2FICSE55347.2025.00179&partnerID=40&md5=4727c4956022848d4318383703af88cb,,,,"As modern web services increasingly rely on REST APIs, their thorough testing has become crucial. Furthermore, the advent of REST API documentation languages, such as the OpenAPI Specification, has led to the emergence of many black-box REST API testing tools. However, these tools often focus on individual test elements in isolation (e.g., APIs, parameters, values), resulting in lower coverage and less effectiveness in fault detection. To address these limitations, we present AutoRestTest, the first black-box tool to adopt a dependency-embedded multi-agent approach for REST API testing that integrates multi-agent reinforcement learning (MARL) with a semantic property dependency graph (SPDG) and Large Language Models (LLMs). Our approach treats REST API testing as a separable problem, where four agents-API, dependency, parameter, and value agents-collaborate to optimize API exploration. LLMs handle domain-specific value generation, the SPDG model simplifies the search space for dependencies using a similarity score between API operations, and MARL dynamically optimizes the agents' behavior. Our evaluation of AutoRestTest on 12 real-world REST services shows that it outperforms the four leading black-box REST API testing tools, including those assisted by RESTGPT (which generates realistic test inputs using LLMs), in terms of code coverage, operation coverage, and fault detection. Notably, AutoRestTest is the only tool able to trigger an internal server error in the Spotify service. Our ablation study illustrates that each component of AutoRestTest-the SPDG, the LLM, and the agent-learning mechanism-contributes to its overall effectiveness. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/ICSE55347.2025.00179,Application programming interfaces (API); Intelligent agents; Machine learning; Multi agent syste...,,,,,,,
rayyan-394626722,NIODebugger: A Novel Approach to Repair Non-Idempotent-Outcome Tests with LLM-Based Agent,2025,,,Proceedings - International Conference on Software Engineering,,,,1014 - 1025,"Ke, Kaiyao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010297534&doi=10.1109%2FICSE55347.2025.00226&partnerID=40&md5=9fae623678ae69408c15f101a9b493d6,,,,"Flaky tests, characterized by inconsistent results across repeated executions, present significant challenges in software testing, especially during regression testing. Recently, there has been emerging research interest in non-idempotentoutcome (NIO) flaky tests-tests that pass on the initial run but fail on subsequent executions within the same environment. Despite progress in utilizing Large Language Models (LLMs) to address flaky tests, existing methods have not tackled NIO flaky tests. The limited context window of LLMs restricts their ability to incorporate relevant source code beyond the test method itself, often overlooking crucial information needed to address state pollution, which is the root cause of NIO flakiness. This paper introduces NIODebugger, the first framework to utilize an LLM-based agent to repair flaky tests. NIODebugger features a three-phase design: detection, exploration, and fixing. In the detection phase, dynamic analysis collects stack traces and custom test execution logs from multiple test runs, which helps in understanding accumulative state pollution. During the exploration phase, the LLM-based agent provides instructions for extracting relevant source code associated with test flakiness. In the fixing phase, NIODebugger repairs the tests using the information gathered from the previous phases. NIODebugger can be integrated with multiple LLMs, achieving patching success rates ranging from 11.63% to 58.72%. Its best-performing variant, NIODebugger-GPT-4, successfully generated correct patches for 101 out of 172 previously unknown NIO tests across 20 largescale open-source projects. We submitted pull requests for all generated patches; 58 have been merged, only 1 was rejected, and the remaining 42 are pending. The Java implementation of NIODebugger is provided as a Maven plugin accessible at https://github.com/kaiyaok2/NIOInspector. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/ICSE55347.2025.00226,Codes (symbols); Nickel oxide; Open source software; Open systems; Repair; Software agents; Conte...,,,,,,,
rayyan-394626723,SPOC: A Scale for Potential Operation Consequences of UI Interactions,2025,,,,,,,28 - 34,"Eggenkemper, Florian and Rehers, Teresa and Swerew, Jana and Mertens, Robert",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010129351&doi=10.1109%2FAIxMM62960.2025.00011&partnerID=40&md5=1629992d5bd427e63d4e4b1a5a11f199,,,,"Many approaches rely on a semantic understanding of screen contents to perform further actions on this information. This is relevant for test automation, robotic process automation, or context based assistive tasks (digital agents). Most of these approaches just analyze basic information about user interface elements but fall short in predicting the consequences of single user interface actions. Possible consequences of UI actions include (permanent) data loss, effects on the reputation of people (e.g. posting on social media), or other irreversible consequences. This makes it necessary to identify and analyze the potential consequences of operation on user interfaces to prevent automatic systems from making possibly fatal mistakes with a high impact on the human user. This paper presents a Scale for Potential Operation Consequences (SPOC) and demonstrates an automatic rating system based on Large Language Models (LLMs), that can be performed locally or in cloud implementations. The LLM-based ratings were tested against a human control group based on a questionnaire (n=35), and proved to perform as well as their human counterparts, making SPOC a robust and automation-friendly rating system for user interface element actions. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1109/AIxMM62960.2025.00011,Automation; Man machine systems; Rating; Semantics; Automation/robotics; Context-based; Hci; Inte...,,,,,,,
rayyan-394626726,Automated Bug Discovery in Cloud Infrastructure-as-Code Updates with LLM Agents,2025,,,,,,,20 - 25,"Xiang, Yiming and Yang, Zhenning and Peng, Jingjia and Bauer, Hermann and Kon, Patrick Tser Jern and Qiu, Yiming and Chen, Ang",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009458915&doi=10.1109%2FAIOps66738.2025.00011&partnerID=40&md5=22fec64a714f3a2c99b17a030e2ddc74,,,,"Cloud environments are increasingly managed by Infrastructure-as-Code (IaC) platforms (e.g., Terraform), which allow developers to define their desired infrastructure as a configuration program that describes cloud resources and their dependencies. This shields developers from low-level operations for creating and maintaining resources, since they are automatically performed by IaC platforms when compiling and deploying the configuration. However, while IaC platforms are rigorously tested for initial deployments, they exhibit myriad errors for runtime updates, e.g., adding/removing resources and dependencies. IaC updates are common because cloud infrastructures are long-lived but user requirements fluctuate over time. Unfortunately, our experience shows that updates often introduce subtle yet impactful bugs. The update logic in IaC frameworks is hard to test due to the vast and evolving search space, which includes diverse infrastructure setups and a wide range of provided resources with new ones frequently added. We introduce TerraFault, an automated, efficient, LLM-guided system for discovering update bugs, and report our findings with an initial prototype. TerraFault incorporates various optimizations to navigate the large search space efficiently and employs techniques to accelerate the testing process. Our prototype has successfully identified bugs even in simple IaC updates, showing early promise in systematically identifying update bugs in today's IaC frameworks to increase their reliability. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/AIOps66738.2025.00011,Cloud computing; Cloud platforms; Codes (symbols); Program debugging; Software reliability; Cloud...,,,,,,,
rayyan-394626727,Evaluating Large Language Models in Exercises of UML Use Case Diagrams Modeling,2025,,,,,,,41 - 44,"Garaccione, Giacomo and Vega Carrazan, Pablo Federico and Coppola, Riccardo and Ardito, Luca",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009455501&doi=10.1109%2FNLBSE66842.2025.00015&partnerID=40&md5=d12f20478491ad5511e9f1f6a136af9a,,,,"In recent years, Large Language Models (LLMs) have been extensively used in several Software Engineering tasks, from requirements analysis to coding and software testing. Research has proved that LLMs can effectively generate software models to assist in software documentation. The goal of this study is to assess the capability of LLM agents to generate UML Use Case Diagrams (UCD), starting from software requirements in natural language. We perform the assessment in an educational setting, i.e., we evaluate the capability to solve software modeling exercises tailored for master's students in SE curricula. Our results, based on the comparison of the results obtained by a human and an LLM solver on 17 UCD modeling exercises, show that LLMs have comparable results in terms of completeness and redundancy of the generated diagrams, with no significant difference if compared to human-proposed solutions. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""apenas UML ?""]}",10.1109/NLBSE66842.2025.00015,Software agents; Unified Modeling Language; Engineering tasks; Language model; Large language mod...,,,,,,,
rayyan-394626728,Human-In-The-Loop Software Development Agents: Challenges and Future Directions,2025,,,,,,,756 - 757,"Pasuksmit, Jirat and Takerngsaksiri, Wannita and Thongtanunam, Patanamon Pick and Tantithamthavorn, Kla (kla) and Zhang, Ruixiong and Wang, Shiyan and Jiang, Fan and Li, Jing and Cook, Evan and Chen, Kun and Wu, Ming",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009162123&doi=10.1109%2FMSR66628.2025.00112&partnerID=40&md5=698142c669aae605243d9a432638bec7,,,,"Multi-agent LLM-driven systems for software development are rapidly gaining traction, offering new opportunities to enhance productivity. At Atlassian, we deployed Human-in-the-Loop Software Development Agents to resolve Jira work items and evaluated the generated code quality using functional correctness testing and GPT-based similarity scoring. This paper highlights two major challenges: the high computational costs of unit testing and the variability in LLM-based evaluations. We also propose future research directions to improve evaluation frameworks for Human-In-The-Loop software development tools. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/MSR66628.2025.00112,Information systems; Intelligent agents; Multi agent systems; Software quality; Software testing;...,,,,,,,
rayyan-394626731,Special Session: ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification,2025,,,Proceedings of the IEEE VLSI Test Symposium,,,,,"Saha, Dipayan and Al-Shaikh, Hasan and Tarek, Shams and Farahmandi, Farimah",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008498031&doi=10.1109%2FVTS65138.2025.11022932&partnerID=40&md5=7aa515b66bd36cec92dc68c0e6f83d34,,,,"Current hardware security verification processes predominantly rely on manual threat modeling and test plan generation, which are labor-intensive, error-prone, and struggle to scale with increasing design complexity and evolving attack methodologies. To address these challenges, we propose ThreatLens, an LLM-driven multi-agent framework that automates security threat modeling and test plan generation for hardware security verification. ThreatLens integrates retrieval-augmented generation (RAG) to extract relevant security knowledge, LLM-powered reasoning for threat assessment, and interactive user feedback to ensure the generation of practical test plans. By automating these processes, the framework reduces the manual verification effort, enhances coverage, and ensures a structured, adaptable approach to security verification. We evaluated our framework on the NEORV32 SoC, demonstrating its capability to automate security verification through structured test plans and validating its effectiveness in real-world scenarios. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""testes em hardware""]}",10.1109/VTS65138.2025.11022932,Computer hardware; Human computer interaction; Verification; Hardware security and trust; LLM; Pl...,,,,,,,
rayyan-394626732,CKGFuzzer: LLM-Based Fuzz Driver Generation Enhanced By Code Knowledge Graph,2025,,,Proceedings - International Conference on Software Engineering,,,,243 - 254,"Xu, Hanxiang and Ma, Wei and Zhou, Ting and Zhao, Yanjie and Chen, Kai and Hu, Qiang and Liu, Yang and Wang, Haoyu",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008497196&doi=10.1109%2FICSE-Companion66252.2025.00079&partnerID=40&md5=3f96e9b2e02faa23fe1edaa25aa1a65b,,,,"In recent years, the programming capabilities of large language models (LLMs) have garnered significant attention. Fuzz testing, a highly effective technique, plays a key role in enhancing software reliability and detecting vulnerabilities. However, traditional fuzz testing tools rely on manually crafted fuzz drivers, which can limit both testing efficiency and effectiveness. To address this challenge, we propose an automated fuzz testing method driven by a code knowledge graph and powered by an LLM-based intelligent agent system, referred to as CKGFuzzer. We approach fuzz driver creation as a code generation task, leveraging the knowledge graph of the code repository to automate the generation process within the fuzzing loop, while continuously refining both the fuzz driver and input seeds. The code knowledge graph is constructed through interprocedural program analysis, where each node in the graph represents a code entity, such as a function or a file. The knowledge graph-enhanced CKGFuzzer not only effectively resolves compilation errors in fuzz drivers and generates input seeds tailored to specific API usage scenarios, but also analyzes fuzz driver crash reports, assisting developers in improving code quality. By querying the knowledge graph of the code repository and learning from API usage scenarios, we can better identify testing targets and understand the specific purpose of each fuzz driver. We evaluated our approach using eight open-source software projects. The experimental results indicate that CKGFuzzer achieved an average improvement of 8.73% in code coverage compared to state-of-the-art techniques. Additionally, CKGFuzzer reduced the manual review workload in crash case analysis by 84.4% and successfully detected 11 real bugs (including nine previously unreported bugs) across the tested libraries. Our research enhances the overall performance of fuzz testing by refining fuzz driver generation strategies and input seed analysis, offering a more effective solution for vulnerability remediation and software quality improvement. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/ICSE-Companion66252.2025.00079,Accidents; Application programming interfaces (API); Codes (symbols); Computer software selection...,,,,,,,
rayyan-394626733,Revisiting SWE-Bench: On the Importance of Data Quality for LLM-Based Code Models,2025,,,Proceedings - International Conference on Software Engineering,,,,235 - 236,"Aleithan, Reem",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008495454&doi=10.1109%2FICSE-Companion66252.2025.00075&partnerID=40&md5=522ae8ff6aac3f4a7bdcaaa12739f76a,,,,"The use of Large Language Models (LLMs) for code generation has emerged as a rapidly growing field, gaining substantial traction within software engineering. However, ensuring the reliability and accuracy of generated code requires robust evaluation frameworks. To address this gap, Carlos et al. introduced the SWE-bench dataset, which consists of 2,294 GitHub issues paired with their corresponding pull requests, collected from 12 prominent Python repositories. This dataset has become a key benchmark for evaluating code generation models, with resolution rates prominently featured on the SWE-bench leaderboard. Despite its widespread adoption, the dataset has yet to undergo a systematic reliability assessment. Motivated by this gap, we conducted the first empirical study aimed at evaluating the reliability of the SWE-Bench dataset to ensure it provides meaningful and realistic model evaluations. We centered our analysis on the highest-performing model reported on the leaderboard at the time of the study: SWE-Agent + GPT-4. A thorough investigation was conducted by comparing the model-generated patches with the corresponding pull requests from the dataset. Our findings revealed two key issues: (1) 32.67% of successful cases were influenced by solution leakage, and (2) 31.08% succeeded due to weak test cases. When these problematic instances were excluded, the resolution rate of SWE-Agent + GPT-4 dropped from 12.47% to 3.97%. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/ICSE-Companion66252.2025.00075,Benchmarking; Computer software; Data accuracy; Data integrity; Data quality; Data reliability; P...,,,,,,,
rayyan-394626734,AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL,2025,,,Proceedings - International Conference on Software Engineering,,,,21 - 24,"Stennett, Tyler and Kim, Myeongsoo and Sinha, Saurabh and Orso, Alessandro",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008493507&doi=10.1109%2FICSE-Companion66252.2025.00015&partnerID=40&md5=6b424c86446186db5a71163dacbdd1aa,,,,"As REST APIs have become widespread in modern web services, comprehensive testing of these APIs is increasingly crucial. Because of the vast search space of operations, parameters, and parameter values, along with their dependencies and constraints, current testing tools often achieve low code coverage, resulting in suboptimal fault detection. To address this limitation, we present AutoRestTest, a novel tool that integrates the Semantic Property Dependency Graph (SPDG) with Multi-Agent Reinforcement Learning (MARL) and large language models (LLMs) for effective REST API testing. AutoRestTest determines operation-dependent parameters using the SPDG and employs five specialized agents (operation, parameter, value, dependency, and header) to identify dependencies of operations and generate operation sequences, parameter combinations, and values. Through an intuitive command-line interface, users can easily configure and monitor tests with successful operation count, unique server errors detected, and time elapsed. Upon completion, AutoRestTest generates a detailed report highlighting errors detected and operations exercised. In this paper, we introduce our tool and present preliminary findings, with a demonstration video available at https://www.youtube.com/watch?v=VVus2W8rap8. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/ICSE-Companion66252.2025.00015,Application programming interfaces (API); Error detection; Fault detection; Intelligent agents; M...,,,,,,,
rayyan-394626735,Debate-Driven Multi-Agent LLMs for Phishing Email Detection,2025,,,,,,,,"Vy Nguyen, Ngoc Tuong and Childress, Felix D. and Yin, Yunting",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008489080&doi=10.1109%2FISDFS65363.2025.11012014&partnerID=40&md5=5e66a71bcd56068603980650b1053ca5,,,,"Phishing attacks remain a critical cybersecurity threat. Attackers constantly refine their methods, making phishing emails harder to detect. Traditional detection methods, including rule-based systems and supervised machine learning models, either rely on predefined patterns like blacklists, which can be bypassed with slight modifications, or require large datasets for training and still can generate false positives and false negatives. In this work, we propose a multi-agent large language model (LLM) prompting technique that simulates debates among agents to detect whether the content presented on an email is phishing. Our approach uses two LLM agents to present arguments for or against the classification task, with a judge agent adjudicating the final verdict based on the quality of reasoning provided. This debate mechanism enables the models to critically analyze contextual cue and deceptive patterns in text, which leads to improved classification accuracy. The proposed framework is evaluated on multiple phishing email datasets and demonstrate that mixed -agent configurations consistently outperform homogeneous configurations. Results also show that the debate structure itself is sufficient to yield accurate decisions without extra prompting strategies. © 2025 Elsevier B.V., All rights reserved.","Cited by: 2; All Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1109/ISDFS65363.2025.11012014,Classification (of information); Computational linguistics; Computer crime; Cybersecurity; Electr...,,,,,,,
rayyan-394626736,Towards Architectural Pen Test Case Generation and Attack Surface Analysis to Support Secure Design,2025,,,,,,,143 - 148,"Sarvejahani, Mahdi Jafari",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007880639&doi=10.1109%2FICSA-C65153.2025.00027&partnerID=40&md5=c705d9b1be50927d023e0e9155558783,,,,"In today's interconnected world, software systems have become indispensable components of complex frameworks, such as cyber-physical systems, e-commerce platforms, and healthcare information systems. This widespread integration highlights the importance of security more than ever, as these systems often function in critical environments where vulnerabilities can lead to significant destructive consequences. Pen-etration testing is a key method for identifying vulnerabilities but is often conducted after deployment, making remediation costly and time-consuming. On the other hand, back to the early phases of the Software Development Life Cycle (SDLC), software architects often lack the security expertise and feedback mechanisms needed to make informed design decisions, leading to vulnerabilities that remain undetected until later stages. In this paper, to address these challenges, we propose a research plan to integrate security considerations into the design phase. Our approach involves generating architecture-based penetration test cases, evaluating the attack surface of alternative architectures by using the generated test cases, and supporting software architects in making secure design decisions afterward. We plan to leverage threat modeling and Large Language Models (LLMs) to fulfill our target ambitions. To validate the applicability and effectiveness of our approach, we aim to conduct case studies in areas such as autonomous vehicles (AVs), which present significant security challenges. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Pen test ??""]}",10.1109/ICSA-C65153.2025.00027,Computer operating systems; Computer software selection and evaluation; Embedded software; Intell...,,,,,,,
rayyan-394626737,Evaluation of the Choice of LLM in a Multi-Agent Solution for GUI-Test Generation,2025,,,,,,,487 - 497,"Tomic, Stevan and Alégroth, Emil and Isaac, Maycel",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007519090&doi=10.1109%2FICST62969.2025.10989038&partnerID=40&md5=a9c1278607d06e5157ef49503bf355f4,,,,"Automated testing, particularly for GUI-based systems, remains a costly and labor-intensive process and prone to errors. Despite advancements in automation, manual testing still dominates in industrial practice, resulting in delays, higher costs, and increased error rates. Large Language Models (LLMs) have shown great potential to automate tasks traditionally requiring human intervention, leveraging their cognitive-like abilities for test generation and evaluation. In this study, we present PathFinder, a Multi-Agent LLM (MALLM) framework that incorporates four agents responsible for (a) perception and summarization, (b) decision-making, (c) input handling and extraction, and (d) validation, which work collaboratively to automate exploratory web-based GUI testing. The goal of this study is to assess how different LLMs, applied to different agents, affect the efficacy of automated exploratory GUI testing. We evaluate PathFinder with three models, Mistral-Nemo, Gemma2, and Llama3.1, on four e-commerce websites. Thus, 27 permutations of the LLMs, across three agents (excluding the validation agent), to test the hypothesis that a solution with multiple agents, each using different LLMs, is more efficacious (efficient and effective) than a multi-agent solution where all agents use the same LLM. The results indicate that the choice of LLM constellation (combination of LLMs) significantly impacts efficacy, suggesting that a single LLM across agents may yield the best balance of efficacy (measured by F1-score). Hypothesis to explain this result include, but are not limited to: improved decision-making consistency and reduced task coordination discrepancies. The contributions of this study are an architecture for MALLM-based GUI testing, empirical results on its performance, and novel insights into how LLM selection impacts the efficacy of automated testing. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""secundario ? supervisao para industrias ?""]}",10.1109/ICST62969.2025.10989038,Ability testing; Autonomous agents; C (programming language); Intelligent agents; Model checking;...,,,,,,,
rayyan-394626738,"Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios",2025,,,,,,,657 - 668,"Chen, Zhi and Jiang, Lingxiao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007302779&doi=10.1109%2FSANER64311.2025.00068&partnerID=40&md5=1e5568549f4eba6213f35f8ccaa4be56,,,,"In recent years, AI-based software engineering has progressed from pre-trained models to advanced agentic workflows, with Software Development Agents representing the next major leap. These agents, capable of reasoning, planning, and interacting with external environments, offer promising solutions to complex software engineering tasks. However, while much research has evaluated code generated by large language models (LLMs), comprehensive studies on agent-generated patches, particularly in real-world settings, are lacking. This study addresses that gap by evaluating 4,892 patches from 10 top-ranked agents on 500 real-world GitHub issues from SWE-Bench Verified, focusing on their impact on code quality. Our analysis shows no single agent dominated, with 170 issues unresolved, indicating room for improvement. Even for patches that passed unit tests and resolved issues, agents made different file and function modifications compared to the gold patches from repository developers, revealing limitations in the benchmark's test case coverage. Most agents maintained code reliability and security, avoiding new bugs or vulnerabilities; while some agents increased code complexity, many reduced code duplication and minimized code smells. Finally, agents performed better on simpler codebases, suggesting that breaking complex tasks into smaller sub-tasks could improve effectiveness. This study provides the first comprehensive evaluation of agent-generated patches on real-world GitHub issues, offering insights to advance AI-driven software development. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/SANER64311.2025.00068,Application programs; Computer operating systems; Computer software maintenance; Computer softwar...,,,,,,,
rayyan-394626739,Approach to Forming Vulnerability Datasets for Fine-Tuning AI Agents,2025,,,,,,,771 - 776,"Gladkikh, Kirill and Zakharov, Alexander A.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007163730&doi=10.1109%2FSmartIndustryCon65166.2025.10986048&partnerID=40&md5=c17a17e425a33f43983fe72168611c09,,,,"This study addresses the problem of identifying vulnerabilities in open-source code by exploring existing methods of code analysis and evaluating the feasibility of automating security assessments using large language models (LLMs). We propose an approach for constructing high-quality datasets to fine-tune LLMs for software security analysis. Our methodology involves collecting and processing vulnerability data, filtering and curating security-related code changes, and structuring datasets to optimize model fine-tuning. We present an algorithm for aggregating vulnerability data sources and constructing a dataset specifically for training security-focused LLMs. To validate our approach, we fine-tune models from the Qwen family for software vulnerability detection in Python codebases during development and testing. Our findings demonstrate that the proposed method enables the development of intelligent, continuously adaptable AI agents capable of identifying and analyzing emerging zero-day vulnerabilities, not only in Python but also in other structurally similar programming languages. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""vulnerabilidades CVEs?""]}",10.1109/SmartIndustryCon65166.2025.10986048,Computer software selection and evaluation; Data curation; Data flow analysis; Model checking; Op...,,,,,,,
rayyan-394626740,One Prompt to Rule Them All: Automated Curve and Image Retrieval from PDFs and Websites with Agentic Multimodal RAG,2025,,,,,,,158 - 170,"Elahi, Siavash Hakim and Zyngier, Danielle",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006912778&doi=10.1061%2F9780784486184.016&partnerID=40&md5=c7bc84e68f56c630134e7efbf27b0d9e,,,,"In the water industry, subject matter experts (SMEs) often manually review numerous documents and websites to find image-based information, such as chemical reaction curves and software manual screenshots for model setups. This process is time-consuming, inconsistent, and inefficient. This paper introduces a multimodal agentic Retrieval-Augmented Generation (RAG) tool to automate this task. RAG combines information retrieval systems with generative models to process and integrate multiple data types, including text, images, and tables. To achieve our goal, we designed a unique nested agentic multimodal RAG with three main large language model (LLM) agents. The first agent, although optional, conducts research in the absence of a library of PDFs and websites. For instance, it can locate top articles for a specific topic in the water industry such as water treatment removal curve. The second agent, a multimodal RAG specialist, extracts images, curves, tables, and text. Finally, the third agent digitizes the extracted curves into CSV format. This framework has successfully produced accurate and reliable results for multiple test cases. In one example, the framework automatically analyzed PDFs and websites and provided turbidity removal curves for alum from various resources. Another experiment focused on extracting both images and text from a software manual to answer questions about cost factors. This advanced automation framework leads to better decision-making, optimized performance, and increased efficiency in managing water infrastructure. Moreover, it significantly reduces the manual effort required by subject matter experts (SMEs), enabling them to focus on higher-level analytical tasks. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1061/9780784486184.016,Autonomous agents; Intelligent agents; Online searching; Recommender systems; Search engines; Gen...,,,,,,,
rayyan-394626741,"5th International Conference on Data Science and Applications, ICDSA 2024",2025,,,Lecture Notes in Networks and Systems,,1237,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006747399&partnerID=40&md5=c6a5c740e17dd083d43565d8d0bc1c89,,,,"The proceedings contain 40 papers. The special focus in this conference is on Data Science and Applications. The topics include: Persistence and Fixed Autoregression Models for Time-Series Prediction of Net Asset Value (NAV) of Savings Fund; Emoji-RoBERTa: A Contextual Emoji Representation for Hate Speech Detection; Software Bugs Classification Using SVM, RF, DT Algorithms; Ascend.AI Building Confidence Through Technology: A Technical Exploration of Facial Expression, Tone, and Pitch Analysis with Chatbot Guidance; Transformer Generative AI Model for Enhanced Molecular Property Prediction; compaction and Restoration of the S-Transform Based on N-Fold Redundancy; deep Learning-Based Electric Vehicle Charging Load Prediction: A Comparative Study; a Comparative Analysis of Quantum Programming Bug Detection Tools; DWMS-HGR: 1D CNN for Hand Gesture Recognition on Normalized sEMG Signals with Sliding Window; secured File-Sharing: Hybrid Encryption and Network Theory for Enhanced Privacy; kernel Density Estimation Based Clustering for Visual Walking Stick Detection in Human-Robot Coexisting Environments; optimizing Battery Efficiency: Design and Implementation of a Fuzzy Logic Based Controller for Hybrid Energy Storage System in Electric Vehicles; guardians of Truth: Advancing Deepfake Detection with Transparency and Insight; enhancing Agricultural Price Forecasting with Time Series Models: A Case Study on Tomato Markets; hybrid Approach Using Deep Learning Techniques to Enhance Forecasting Accuracy in Garch Model; mitigating Model Poisoning Attacks in Federated Learning: A Comprehensive Approach; a Volterra Equalizer for Compensation of Nonlinear Phase Noise and Frequency Offset in 100 Giga-Baud Fiber System; Protein Secondary Structure Prediction Using Hybrid CNN with Attention Mechanism; non-invasive Measurement of HbA1C Using Spectroscopic Method; NLP Inspired Bayesian-Optimized Random Forest Classifier for Adverse Drug Events Prediction; DAPC: Decomposed Action Prediction for Cooperative Exploration in Multi-agent System. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626742,"Future of Information and Communication Conference, FICC 2025",2025,,,Lecture Notes in Networks and Systems,,1285,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006408966&partnerID=40&md5=35cf2258f93e2fc95a548566acc97dad,,,,"The proceedings contain 138 papers. The special focus in this conference is on Future of Information and Communication. The topics include: Robots in Healthcare: Measuring Acceptance of Professional Caregivers Towards Finding Key Requirements for System Design; a Human-Centric Architecture for Natural Interaction with Organizational Systems; industrial Metaverse for Smart Manufacturing: Ecosystem Architecture and Applications; centralised Graph-Based Collision-Free Air Traffic Management Approach for Autonomous Aerial Vehicle Navigation; phytoNode Upgraded: Energy-Efficient Long-Term Environmental Monitoring Using Phytosensing; evaluating the Socio-Economic Impacts of Hyperloop Technology Through the Lens of Labour Market: A Focus on Intelligent Transportation, Case of Latvia; Human-In-The-Loop Reasoning for Traffic Sign Detection: Collaborative Approach YOLO with Video-LLaVA; Reasoning with Generative AI; “Model Cards for Model Reporting” in 2024: Reclassifying Category of Ethical Considerations in Terms of Trustworthiness and Risk Management; robotic Process Automation in Software Testing: Challenges and Open Research Directions; chatbot Personas as a Gateway to Enhanced Learning Experiences; is It Time to Start Taking the Concept of a Holodeck Seriously?; agent for Machine Learning: A Text-to-Model (T2M) Approach; The Theory of Cybernetics for Managing Human-AI Interactions: A Framework for AI Management; steering Toward Trustworthiness: A Speech-Act Theory Perspective on Building Trust in Language Models for Autonomous Vehicle Applications; fingerprint Synthesis from Diffusion Models and Generative Adversarial Networks; Easy Problems that LLMs Get Wrong; socratic Dialogue with Generative Artificial Intelligence: Where is the Future?; Vectoring Languages: A High-Dimensional Perspective of Language to Bridge the Gap Between Philosophy and AI Science; The Elephant in the Room: Why AI Safety Demands Diverse Teams; exploring Foundation Model Fusion Effectiveness and Explainability for Stylistic Analysis of Emotional Podcast Data; machine Learning Enabled Earthquake Classification with Real Time Monitoring and Alert System. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626743,Customer - Software Agent Negotiations Using Large Language Model: An Experimental Study,2025,,,Proceedings of the Annual Hawaii International Conference on System Sciences,,,,4357 - 4362,"Vahidov, Rustam M. and Carbonneau, Réal André",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005146819&doi=10.24251%2Fhicss.2025.522&partnerID=40&md5=7b0e405626c80fd394e703b310dea79d,,,,"Large Language Models (LLMs) present remarkable opportunities for researchers and professionals to improve the effectiveness of software agents acting on companies' behalf. A particularly promising application is using LLMs to negotiate deals with potential customers. This paper proposes integrating negotiation models with LLM capabilities to generate textual offers in machine-human negotiations. It builds on an assumption that LLMs demonstrate emotional intelligence in their interactions with humans, positively influencing negotiation outcomes and human perceptions. The work introduces a prototype agent application based on a phone plan sales scenario. An experiment with human participants tested the performance of the LLM-powered negotiation agent against a version without LLM. The results indicate that the LLM-enhanced software agent reached agreements with better prices. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.24251/hicss.2025.522,Application programs; Emotional intelligence; Intelligent agents; Mobile agents; Software prototy...,,,,,,,
rayyan-394626744,A Review of Reasoning in Artificial Agents using Large Language Models,2025,,,Proceedings of the Annual Hawaii International Conference on System Sciences,,,,1390 - 1399,"Naidu, Nagraj and El-Gayar, Omar F.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005144638&doi=10.24251%2Fhicss.2025.168&partnerID=40&md5=f47513ca1c1ddc80ffc230543914290a,,,,"The increasing sophistication and the use of large language models (LLMs) in artificial agents highlights the need to investigate their reasoning capabilities and limitations. Understanding these aspects is crucial, given the integral role of reasoning in decision-making processes, which are central to a software or embodied agent. This research paper presents a systematic review of the topic. We review the literature by selecting and analyzing highly cited papers using both PRISMA and snowballing. The gathered literature is categorized using a detailed framework of facets and categories. In the results section, we elaborate on our findings and illustrate the mapping through bubble chart visualizations. The paper concludes by highlighting research gaps and suggesting directions for future studies. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""secundario""]}",10.24251/hicss.2025.168,Decision making; Modeling languages; Software testing; Artificial agents; Decision-making process...,,,,,,,
rayyan-394626745,Unified Search for Multi-requirement Falsification for Cyber-Physical Systems,2025,,,,,,,235 - 243,"Winsten, Jesper and Porres, Ivan",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004735517&doi=10.1109%2FICSTW64639.2025.10962525&partnerID=40&md5=3cdc9a0aa443ec48e7f8595247719be0,,,,"This paper addresses the challenge of efficiently falsifying multiple requirements in cyber-physical systems (CPSs). Traditional falsification approaches typically evaluate requirements sequentially, leading to redundant computations and decreased efficiency. We present Multi-Requirement Unified Search (MRUS), an algorithm that evaluates all requirements simultaneously using conjunctive Signal Temporal Logic (STL) formulas. MRUS combines an Online Generative Adversarial Network (OGAN) for test case generation with a unified search algorithm to evaluate multiple requirements conjunctively. The performance of the algorithm was evaluated using the ARCH-COMP 2024 falsification competition as a benchmark suite. The results demonstrate that MRUS achieves a high Falsification Rate (FR) across all benchmarks while requiring a small number of total execution counts to find falsifying inputs. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1109/ICSTW64639.2025.10962525,Embedded systems; Intelligent systems; Multi agent systems; Temporal logic; Adversarial networks;...,,,,,,,
rayyan-394626746,Adaptive Test Healing using LLM/GPT and Reinforcement Learning,2025,,,,,,,9 - 16,"Mani, Nariman and Attaranasl, Salma",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004735212&doi=10.1109%2FICSTW64639.2025.10962516&partnerID=40&md5=b70259ee11a7c7ada5d2d2cab21e9645,,,,"Flaky tests disrupt software development pipelines by producing inconsistent results, undermining reliability and efficiency. This paper introduces a hybrid framework for adaptive test healing, combining Large Language Models (LLMs) like GPT with Reinforcement Learning (RL) to address test flakiness dynamically. LLMs analyze test logs to classify failures and extract contextual insights, while the RL agent learns optimal strategies for test retries, parameter tuning, and environment resets. Experimental results demonstrate the framework's effectiveness in reducing flakiness and improving CI/CD pipeline stability, outperforming traditional approaches. This work paves the way for scalable, intelligent test automation in dynamic development environments. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""testes deterministicos""]}",10.1109/ICSTW64639.2025.10962516,C (programming language); Computer operating systems; Computer software selection and evaluation;...,,,,,,,
rayyan-394626747,Fault Detection in Transmission Lines via Transfer Functions Based on Multi-Agent Reinforcement Learning,2025,,,,,,,,"Bittla, Srinivasa Rao and Riadhusin, Raami and Malathi, M. and Nethravathi, T. L. and Aravindh, S.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004731816&doi=10.1109%2FICICACS65178.2025.10968991&partnerID=40&md5=c613f8b07d07dd45aa108906bbddd4f5,,,,"In recent years, fault detection addresses high-impedance faults in transmission lines which is crucial for creating reliability and safety in distributed system. The improvements in power system fault detection have employed intelligent techniques like Deep Learning (DL) and Reinforcement Learning (RL) models to improve accuracy and reliability. The existing methods struggled with exact fault detection under varying fault conditions such as changing network topologies, high impedance, and power swings. This research proposed a Multi-Agent Reinforcement Learning (MARL) framework integrated with Transfer Function (TF) analysis to convert the voltage and current signals into the frequency domain, capturing changes caused by faults. The features are extracted through Convolution Neural Network (CNN) to learn automatically and extract complex patterns from TF, and effective detection of faults. MARL employs multiple agents distributed across the power network for detecting and localizing faults through independent learning and decision-making, improving accuracy, adaptability in fault detection tasks. Finally, results of proposed MARL frame work shows that fault detection achieved high performance better outcomes compared to existing Conditional Tabular Generative Adversarial Network (CTGAN) in terms of precision, recall and F1 score by achieving 0.95%, 0.85% and 0.88% respectively. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/ICICACS65178.2025.10968991,Convolutional neural networks; Deep learning; Frequency domain analysis; Generative adversarial n...,,,,,,,
rayyan-394626748,Electronic cleansing in CT colonography using denoising diffusion probabilistic models,2025,,,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,,13411,,,"Tachibana, Rie and Näppi, Janne Johannes and Hironaka, Toru and Okamoto, Masaki and Yoshida, Hiroyuki",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004731731&doi=10.1117%2F12.3046498&partnerID=40&md5=76fed659e7fffb811a10326e4ff8dc99,,,,"Colon cancer is one of the most common cancers. CT colonography (CTC) has been shown to provide a safe and accurate colon examination for cancers. A CTC examination uses orally administered contrast agents to enhance retained fluid and feces for their virtual subtraction from the CTC images of the colon. In this study, we developed a new electronic cleansing (EC) scheme for CTC using a denoising diffusion probabilistic model (DDPM). The model was trained by using CT image volumes of an anthropomorphic colon phantom that was filled partially with contrast-enhanced foodstuff to simulate a CTC examination. After training, the denoising module of the DDPM model makes use of pure noise to convert an uncleansed fecal-tagging input CTC image volume into the corresponding EC image volume. The quality of the EC images was tested visually with three clinical CTC test cases and quantitatively using a phantom test set of 100 unseen samples, with comparison to our previous EC scheme based on a 3D generative adversarial network (GAN). Our preliminary results show that the DDPM-based EC scheme outperforms the 3D GAN-based EC scheme in terms of the image quality of EC. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1117/12.3046498,Photointerpretation; CT colonography; De-noising; Deep learning; Electronic cleansing; Generative...,,,,,,,
rayyan-394626749,Coding Agents: A Comprehensive Survey of Automated Bug Fixing Systems and Benchmarks,2025,,,,,,,680 - 686,"Puvvadi, Meghana and Kumar, Arava Sai and Santoria, Adarsh and Chennupati, Sesha Sai Prasanna and Puvvadi, Harsha Vardhan",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004557703&doi=10.1109%2FCSNT64827.2025.10968728&partnerID=40&md5=27ca8232ba7f865a558fab9d05da910c,,,,"One of the trickiest problems in software engineering is automating software issue fixes, which calls for a thorough comprehension of contextual relationships, code semantics, and dynamic debugging techniques. The development of automatic program repair (APR) is examined in this survey, which traces a path from early template and constraint-based approaches to more recent developments powered by large language models (LLMs). Three main paradigms are compared here: retrieval-augmented approaches that integrate external knowledge sources, agent-based systems that use multi-agent frameworks, and agentless systems that use simplified repair pipelines. Real-world benchmarks that mimic actual engineering workflows and repository-level difficulties, such as SWE-bench, CODEAGENT-BENCH, and CodeRAG-Bench, are used to assess these cutting-edge technologies. This study demonstrates how agentic, agentless, and retrieval- augmented systems use LLMs to achieve previously unheard- of precision and scalability by following the shift from localized, single-file solutions to solving complicated, multi-file, and repository-wide difficulties. According to our findings, while complex agent architectures have potential, straightforward test- time scaling frequently produces better outcomes, especially when paired with containerized environments that allow for parallel exploration. Additionally, the survey looks at industrial applications, emphasizing effective connections with quality assurance and DevOps procedures. In order to further the development of more resilient and flexible APR frameworks that blend in perfectly with contemporary software engineering practices, we conclude by highlighting important issues in context handling and validation and suggesting future research directions in improved contextual models, human-AI collaboration, and multi-modal debugging systems. © 2025 Elsevier B.V., All rights reserved.","Cited by: 2 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""survey, secundario ?""]}",10.1109/CSNT64827.2025.10968728,Application programs; Autonomous agents; Computer aided software engineering; Computer operating ...,,,,,,,
rayyan-394626750,"27th RoboCup International Symposium, 2024",2025,,,Lecture Notes in Computer Science,,15570,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003879183&partnerID=40&md5=0bd24fa6643321568a8992228a861ab9,,,,"The proceedings contain 46 papers. The special focus in this conference is on RoboCup. The topics include: Using Off-the-Shelf Deep Neural Networks for Position-Based Visual Servoing; deep Learning Based Measurement Model for Monte Carlo Localization in the RoboCup Humanoid League; semantic Path Planning for Heterogeneous Robots from Building Digital Twin Data; planning the Path with Reinforcement Learning: Optimal Robot Motion Planning in RoboCup Small Size League Environments; holes and Clashes in Simulated Soccer: When a Real-Time Simulation System Meets Compute-Hungry Agents; lightweight Real-Time Gesture Recognition for Dynamic Soccer Referee Signals; Quantized Neural Networks for Ball Detection on the NAO Robot: An Optimized Implementation; Decision Tree-Like Dynamic Conditional Stand-Up Routines for NAO Robots; a Mental Simulation Based Decision-Making Algorithm for the RoboCupSoccer Goalkeeper; analysis of the Introduction Trajectory Planning in Control Applied in Small Size League Robots; cross Language Soccer Framework: An Open Source Framework for the RoboCup 2D Soccer Simulation; position and Altitude of the Nao Camera Head from Two Points on the Soccer Field Plus the Gravitational Direction; LLCoach: Generating Robot Soccer Plans Using Multi-role Large Language Models; Introduction of Automated Testing and Continuous Metrics & KPI Monitoring in Student-Driven Projects: a Use Case; proposal of a Method for Acquiring Characteristics of Large-Diameter Solenoids; on Graph Reduction in Consensus Control of Multi-agent Systems: A Preliminary Study; Enhancing Autonomous Vehicle Control Through Sensor Fusion, NARX-Based Reinforcement Learning with Soft Actor-Critic (SAC) in CARLA Simulator; digital Environment Description and Reconstruction Using Panoptic Segmentation; efficient Sequence Model for Early Fall Detection of Humanoid Robots; Steam Deck: A Handheld ROS 2 Based Rescue Robot Controller; planning Robot Placement for Object Grasping; automated Game Statistics for the RoboCup Standard Platform League; a Light-Weighted Event-Based Simulation for the RoboCup Logistics League; event-Based Vision for Robot Soccer; soS: A Semi-Synthetic RoboCup Soccer Dataset for Visual Segmentation; Hibikino-Musashi@Home RoboCup@Home DSPL Champion 2024. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626751,Experimental demonstration of local AI-Agents for lifecycle management and control automation of optical networks,2025,,,Journal of Optical Communications and Networking,,17,8,C82 - C92,"Sun, Chenyu and Yang, Xin and Di Cicco, Nicola and Ayassi, Reda and Virajit Garbhapu, Venkata and Stavrou, Photios A. and Tornatore, Massimo and Charlet, Gabriel and Pointurier, Yvan",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003809756&doi=10.1364%2FJOCN.550286&partnerID=40&md5=fb321af47614f17a450053bf3cd60264,,,,"This paper presents an innovative approach to automating the full lifecycle management of optical networks using locally fine-tuned large language models (LLMs) and digital twin technologies. We experimentally demonstrate the integration of generative AI and digital twins to create powerful AI-Agents capable of handling the design, deployment, maintenance, and upgrade phases in the lifecycle of optical networks. By deploying and fine-tuning LLMs locally, our framework eliminates the need for public cloud services, thereby ensuring data privacy and security. The experimental setup includes a commercial-product-based testbed with eight optical multiplex sections in the C-band, showcasing the effectiveness of the AI-Agents in various automation tasks, such as API-calling for service establishment and periodic power equalization, as well as log analysis for troubleshooting. The results highlight significant improvements in operational accuracy and efficiency, underscoring the feasibility of this approach in real-world scenarios. This work represents a significant advancement toward intent-based networking, showcasing the transformative potential of AI in automating and optimizing optical network operations. © 2025 Elsevier B.V., All rights reserved.","Cited by: 3 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1364/JOCN.550286,Control automation; Experimental demonstrations; Fine tuning; Innovative approaches; Language mod...,,,,,,,
rayyan-394626752,Multi-Agent hierarchical workflow for autonomous code generation with Large Language Models,2025,,,,,,,,"Akilesh, S. and Sekar, Rajeev and Om Kumar, C. U. and Prakalya, D. and Suguna, M.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002712410&doi=10.1109%2FSCEECS64059.2025.10940635&partnerID=40&md5=82551e1af9a6048e627580f4f80faab8,,,,"This paper presents a multi-agent hierarchical workflow tailored for automating data analysis, code generation, and visualization, focusing specifically on user-provided CSV datasets. The workflow integrates AlphaCodium with LangChain, LangGraph, and GPT, enabling autonomous code generation, unit test development, and debugging. The system operates by analyzing the uploaded dataset, assigning agents that work sequentially: a programmer agent generates code using the Skeleton-Of-Code approach, a unit test agent verifies the code, and an executor agent runs the code. A debugging agent is also included to identify and resolve any issues. The AI agents involved are capable of dynamically accessing online resources, including documentation and references to enhance their decision-making processes. This work attempts to exemplify the application of AI in automating not only code execution but also the planning and validation stages by writing unit tests in the software development process to reflect the increasing role of AI in advancing automation for rapid code generation within the software industry. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/SCEECS64059.2025.10940635,Ada (programming language); Application programs; Autonomous agents; C (programming language); Co...,,,,,,,
rayyan-394626753,GRLfuzz: Gan-Powered Fuzzing Based on Deep Reinforcement Learning,2025,,,Lecture Notes on Data Engineering and Communications Technologies,,243,,88 - 97,"Zhang, Yuan and Cui, Baojiang and Chen, Chen",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002469417&doi=10.1007%2F978-3-031-86149-9_9&partnerID=40&md5=e555d4bdfbe365a75f2c256e1083a54a,,,,"Nowadays, more and more fuzzing techniques are being combined with deep learning, especially reinforcement learning. While reinforcement learning makes the mutation algorithm in fuzzing smarter, it still remain blind because of the lack of input format information. Meanwhile, traditional fuzzing often selects the mutation seed randomly or sequentially, which makes it hard to concentrate on more valuable seeds. As a result, it is challenging to achieve higher code coverage. To mitigate these problems, this paper proposes a new fuzzer named GRLfuzz, a gan-powered fuzzing based on deep reinforcement learning. We use generative adversarial networks to learn the format structures in seeds and then provide high-quality seeds. We add seed selection to the action space of reinforcement learning so that the agent can learn from the execution of historical seeds and prioritize the use of seed with higher coverage. The seeds selected from the agent with higher rewards are re-fed into the generative adversarial networks to further generate seeds that are more capable of triggering higher reward. Experimental results show that GRLfuzz outperforms AFL on format-specific programs with 81% to 145% better coverage and better Test Case Recept Rate. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1007/978-3-031-86149-9_9,Adversarial machine learning; Contrastive Learning; Federated learning; Generative adversarial ne...,,,,,,,
rayyan-394626754,Using LLM-Based Deep Reinforcement Learning Agents to Detect Bugs in Web Applications,2025,,,International Conference on Agents and Artificial Intelligence,,3,,1001 - 1008,"Sakai, Yuki and Tahara, Yasuyuki and Ohsuga, Akihiko and Sei, Yuichi",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001979448&doi=10.5220%2F0013248800003890&partnerID=40&md5=e11343925c0bfbc45c2e1839fd45504a,,,,"This paper presents an approach to automate black-box GUI testing for web applications by integrating deep reinforcement learning (DRL) with large language models (LLMs). Traditional GUI testing is often inefficient and costly due to the difficulty in generating comprehensive test scenarios. While DRL has shown potential in automating exploratory testing by leveraging GUI interaction data, such data is browser-dependent and not always accessible in web applications. To address this challenge, we propose using LLMs to infer interaction information directly from HTML code, incorporating these inferences into the DRL’s state representation. We hypothesize that combining the inferential capabilities of LLMs with the robustness of DRL can match the accuracy of methods relying on direct data collection. Through experiments, we demonstrate that LLM-inferred interaction information effectively substitutes for direct data, enhancing both the efficiency and accuracy of automated GUI testing. Our results indicate that this approach not only streamlines GUI testing for web applications but also has broader implications for domains where direct state information is hard to obtain. The study suggests that integrating LLMs with DRL offers a promising path toward more efficient and scalable automation in GUI testing. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Test gui web""]}",10.5220/0013248800003890,,,,,,,,
rayyan-394626755,Investigating Answer Validation Using Noise Identification and Classification in Goal-Oriented Dialogues,2025,,,International Conference on Agents and Artificial Intelligence,,2,,658 - 669,"Mirabi, Sara and Ofoghi, Bahadorreza and Yearwood, John L. and Mollá-Aliod, Diego and Mak-Hau, Vicky H.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001695655&doi=10.5220%2F0013304000003890&partnerID=40&md5=2204eccb956ee00463dd77cc58d055fb,,,,"Goal-oriented conversational systems based on large language models (LLMs) provide the potential capability to gather the necessary requirements for solving tasks or developing solutions. However, in real-world scenarios, non-expert users may respond incorrectly to dialogue questions, which can impede the system’s effectiveness in eliciting accurate information. This paper presents a novel approach to detecting and categorizing noisy answers in goal-oriented conversations, with a focus on modeling linear programming problems. Using a current LLM, Gemini, we develop multi-agent synthetic conversations based on problem statements from the benchmark optimization modeling dataset NL4Opt to generate dialogues in the presence of noisy answers too. Our experiments show the LLM is not sufficiently equipped with the capabilities to detect noisy answers and hence, in almost 59% of the cases where there is a noisy answer, the LLM continues with the conversation without any attempts at resolving the noise. Thus, we also propose a two-step answer validation method for the identification and classification of noisy answers. Our findings demonstrate that while some LLM and non-LLM-based models perform well in detecting answer inaccuracies, there is a need for further improvements in classifying noisy answers into fine-grained stress types. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.5220/0013304000003890,,,,,,,,
rayyan-394626756,Agentic AI for Behavior-Driven Development Testing Using Large Language Models,2025,,,International Conference on Agents and Artificial Intelligence,,2,,805 - 815,"Päduraru, Ciprian Ionut and Zavelca, Miruna and Ştefǎnescu, Alin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001687420&doi=10.5220%2F0013374400003890&partnerID=40&md5=9a5f5ecb6df9a0851aa031db5d4e7894,,,,"Behavior-driven development (BDD) testing significantly improves communication and collaboration between developers, testers and business stakeholders, and ensures that software functionality meets business requirements. However, the benefits of BDD are often overshadowed by the complexity of writing test cases, making it difficult for non-technical stakeholders. To address this challenge, we propose BDDTestAIGen, a framework that uses Large Language Models (LLMs), Natural Language Processing (NLP) techniques, human-in-theloop and Agentic AI methods to automate BDD test creation. This approach aims to reduce manual effort and effectively involve all project stakeholders. By fine-tuning an open-source LLM, we improve domain-specific customization, data privacy and cost efficiency. Our research shows that small models provide a balance between computational efficiency and ease of use. Contributions include the innovative integration of NLP and LLMs into BDD test automation, an adaptable open-source framework, evaluation against industry-relevant scenarios, and a discussion of the limitations, challenges and future directions in this area. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Agent bdd""]}",10.5220/0013374400003890,,,,,,,,
rayyan-394626759,FlexFL: Flexible and Effective Fault Localization With Open-Source Large Language Models,2025,,,IEEE Transactions on Software Engineering,,51,5,1455 - 1471,"Xu, Chuyang and Liu, Zhongxin and Ren, Xiaoxue and Zhang, Gehao and Liang, Ming and Lo, David",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000368545&doi=10.1109%2FTSE.2025.3553363&partnerID=40&md5=fb2b1f9a800980a644f4ff5a2d40e048,,,,"Fault localization (FL) targets identifying bug locations within a software system, which can enhance debugging efficiency and improve software quality. Due to the impressive code comprehension ability of Large Language Models (LLMs), a few studies have proposed to leverage LLMs to locate bugs, i.e., LLM-based FL, and demonstrated promising performance. However, first, these methods are limited in flexibility. They rely on bug-triggering test cases to perform FL and cannot make use of other available bug-related information, e.g., bug reports. Second, they are built upon proprietary LLMs, which are, although powerful, confronted with risks in data privacy. To address these limitations, we propose a novel LLM-based FL framework named FlexFL, which can flexibly leverage different types of bug-related information and effectively work with open-source LLMs. FlexFL is composed of two stages. In the first stage, FlexFL reduces the search space of buggy code using state-of-the-art FL techniques of different families and provides a candidate list of bug-related methods. In the second stage, FlexFL leverages LLMs to delve deeper to double-check the code snippets of methods suggested by the first stage and refine fault localization results. In each stage, FlexFL constructs agents based on open-source LLMs, which share the same pipeline that does not postulate any type of bug-related information and can interact with function calls without the out-of-the-box capability. Extensive experimental results on Defects4J demonstrate that FlexFL outperforms the baselines and can work with different open-source LLMs. Specifically, FlexFL with a lightweight open-source LLM Llama3-8B can locate 42 and 63 more bugs than two state-of-the-art LLM-based FL approaches AutoFL and AgentFL that both use GPT-3.5. In addition, FlexFL can localize 93 bugs that cannot be localized by non-LLM-based FL techniques at the top 1. Furthermore, to mitigate potential data contamination, we conduct experiments on a dataset which Llama3-8B has not seen before, and the evaluation results show that FlexFL can also achieve good performance. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/TSE.2025.3553363,Computer debugging; Computer software selection and evaluation; Open source software; Outages; Pr...,,,,,,,
rayyan-394626760,Is my Meeting Summary Good? Estimating Quality with a Multi-LLM Evaluator,2025,,,"Proceedings - International Conference on Computational Linguistics, COLING",,,,561 - 574,"Kirstein, Frederic and Ruas, Terry Lima and Gipp, Béla",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000134902&partnerID=40&md5=2d07495ebdfd5beb01ff1e1cdd18a5a5,,,,"The quality of meeting summaries generated by natural language generation (NLG) systems is hard to measure automatically. Established metrics such as ROUGE and BERTScore have a relatively low correlation with human judgments and fail to capture nuanced errors. Recent studies suggest using large language models (LLMs), which have the benefit of better context understanding and adaption of error definitions without training on a large number of human preference judgments. However, current LLM-based evaluators risk masking errors and can only serve as a weak proxy, leaving human evaluation the gold standard despite being costly and hard to compare across studies. In this work, we present MESA, an LLM-based framework employing a three-step assessment of individual error types, multi-agent discussion for decision refinement, and feedback-based self-training to refine error definition understanding and alignment with human judgment. We show that MESA’s components enable thorough error detection, consistent rating, and adaptability to custom error guidelines. Using GPT-4o as its backbone, MESA achieves mid to high Point-Biserial correlation with human judgment in error detection and mid Spearman and Kendall correlation in reflecting error impact on summary quality, on average 0.25 higher than previous methods. The framework’s flexibility in adapting to custom error guidelines makes it suitable for various tasks with limited human-labeled data. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",,Context free languages; Errors; Natural language processing systems; Risk assessment; 'current; E...,,,,,,,
rayyan-394626761,Performance of the ChatGPT large language model for decision support in community pharmacy,2024,,,British Journal of Clinical Pharmacology,,90,12,3320 - 3333,"Shin, Euibeom and Hartman, Maggie and Ramanathan, Murali",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202185675&doi=10.1111%2Fbcp.16215&partnerID=40&md5=4053a98427dbd1af6999cdcabda15cf6,,,,"Aims: The aim of this study was to assess the ChatGPT-4 (ChatGPT) large language model (LLM) on tasks relevant to community pharmacy. Methods: ChatGPT was assessed with community pharmacy-relevant test cases involving drug information retrieval, identifying labelling errors, prescription interpretation, decision-making under uncertainty and multidisciplinary consults. Drug information on rituximab, warfarin, and St. John's wort was queried. The decision-support scenarios consisted of a subject with swollen eyelids and a maculopapular rash in a subject on lisinopril and ferrous sulfate. The multidisciplinary scenarios required the integration of medication management with recommendations for healthy eating and physical activity/exercise. Results: The responses from ChatGPT for rituximab, warfarin, and St. John's wort were satisfactory and cited drug databases and drug-specific monographs. ChatGPT identified labeling errors related to incorrect medication strength, form, route of administration, unit conversion, and directions. For the patient with inflamed eyelids, the course of action developed by ChatGPT was comparable to the pharmacist's approach. For the patient with the maculopapular rash, both the pharmacist and ChatGPT placed a drug reaction to either lisinopril or ferrous sulfate at the top of the differential. ChatGPT provided customized vaccination requirements for travel to Brazil, guidance on management of drug allergies and recovery from a knee injury. ChatGPT provided satisfactory medication management and wellness information for a diabetic on metformin and semaglutide. Conclusions: LLMs have the potential to become a powerful tool in community pharmacy. However, rigorous validation studies across diverse pharmacist queries, drug classes and populations, and engineering to secure patient privacy will be needed to enhance LLM utility. © 2024 Elsevier B.V., All rights reserved.","Cited by: 12; All Open Access; Bronze Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1111/bcp.16215,amoxicillin; atorvastatin; cholesterol; cyanocobalamin; diphtheria pertussis tetanus vaccine; fer...,,,,,,,
rayyan-394626762,Arondight: Red Teaming Large Vision Language Models with Auto-generated Multi-modal Jailbreak Prompts,2024,,,,,,,3578 - 3586,"Liu, Yi and Cai, Chengjun and Zhang, Xiaoli and Yuan, Xingliang and Wang, Cong",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209781753&doi=10.1145%2F3664647.3681379&partnerID=40&md5=c77dd3adfe1e0aacdbeebf593fd69b3b,,,,"Large Vision Language Models (VLMs) extend and enhance the perceptual abilities of Large Language Models (LLMs). Despite offering new possibilities for LLM applications, these advancements raise significant security and ethical concerns, particularly regarding the generation of harmful content. While LLMs have undergone extensive security evaluations with the aid of red teaming frameworks, VLMs currently lack a well-developed one. To fill this gap, we introduce Arondight, a standardized red team framework tailored specifically for VLMs. Arondight is dedicated to resolving issues related to the absence of visual modality and inadequate diversity encountered when transitioning existing red teaming methodologies from LLMs to VLMs. Our framework features an automated multi-modal jailbreak attack, wherein visual jailbreak prompts are produced by a red team VLM, and textual prompts are generated by a red team LLM guided by a reinforcement learning agent. To enhance the comprehensiveness of VLM security evaluation, we integrate entropy bonuses and novelty reward metrics. These elements incentivize the RL agent to guide the red team LLM in creating a wider array of diverse and previously unseen test cases. Our evaluation of ten cutting-edge VLMs exposes significant security vulnerabilities, particularly in generating toxic images and aligning multi-modal prompts. In particular, our Arondight achieves an average attack success rate of 84.5% on GPT-4 in all fourteen prohibited scenarios defined by OpenAI in terms of generating toxic text. For a clearer comparison, we also categorize existing VLMs based on their safety levels and provide corresponding reinforcement recommendations. Our multimodal prompt dataset and red team code will be released after ethics committee approval. CONTENT WARNING: THIS PAPER CONTAINS HARMFUL MODEL RESPONSES. © 2024 Elsevier B.V., All rights reserved.","Cited by: 4 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1145/3664647.3681379,Reinforcement learning; Ethical concerns; Jailbreak attack; Language model; Large vision language...,,,,,,,
rayyan-394626763,WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization,2024,,,,,,,,"Xie, Liwenhan and Zheng, Chengbo and Xia, Haijun and Qu, Huamin and Chen, Zhutian",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210681708&doi=10.1145%2F3654777.3676374&partnerID=40&md5=6f106b0db8a9dc413efc4b084427f202,,,,"Large language models (LLMs) support data analysis through conversational user interfaces, as exemplified in OpenAI's ChatGPT (formally known as Advanced Data Analysis or Code Interpreter). Essentially, LLMs produce code for accomplishing diverse analysis tasks. However, presenting raw code can obscure the logic and hinder user verification. To empower users with enhanced comprehension and augmented control over analysis conducted by LLMs, we propose a novel approach to transform LLM-generated code into an interactive visual representation. In the approach, users are provided with a clear, step-by-step visualization of the LLM-generated code in real time, allowing them to understand, verify, and modify individual data operations in the analysis. Our design decisions are informed by a formative study (N=8) probing into user practice and challenges. We further developed a prototype named WaitGPT and conducted a user study (N=12) to evaluate its usability and effectiveness. The findings from the user study reveal that WaitGPT facilitates monitoring and steering of data analysis performed by LLMs, enabling participants to enhance error detection and increase their overall confidence in the results. © 2025 Elsevier B.V., All rights reserved.","Cited by: 12; All Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""representacao visual do codigo, chatbot ?""]}",10.1145/3654777.3676374,Data assimilation; Data reduction; Program interpreters; Code visualization; Codes verification; ...,,,,,,,
rayyan-394626764,Self-Collaboration Code Generation via ChatGPT,2024,,,ACM Transactions on Software Engineering and Methodology,,33,7,,"Dong, Yihong and Jiang, Xue and Jin, Zhi and LI, Ge",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198255497&doi=10.1145%2F3672459&partnerID=40&md5=c103ee9b9813f3e4926767fd4a5695f6,,,,"Although large language models (LLMs) have demonstrated remarkable code-generation ability, they still struggle with complex tasks. In real-world software development, humans usually tackle complex tasks through collaborative teamwork, a strategy that significantly controls development complexity and enhances software quality. Inspired by this, we present a self-collaboration framework for code generation employing LLMs, exemplified by ChatGPT. Specifically, through role instructions, (1) Multiple LLM agents act as distinct ""experts,""each responsible for a specific subtask within a complex task; (2) Specify the way to collaborate and interact, so that different roles form a virtual team to facilitate each other's work, ultimately the virtual team addresses code generation tasks collaboratively without the need for human intervention. To effectively organize and manage this virtual team, we incorporate software-development methodology into the framework. Thus, we assemble an elementary team consisting of three LLM roles (i.e., analyst, coder, and tester) responsible for software development's analysis, coding, and testing stages. We conduct comprehensive experiments on various code-generation benchmarks. Experimental results indicate that self-collaboration code generation relatively improves 29.9-47.1% Pass@1 compared to the base LLM agent. Moreover, we showcase that self-collaboration could potentially enable LLMs to efficiently handle complex repository-level tasks that are not readily solved by the single LLM agent. © 2024 Elsevier B.V., All rights reserved.","Cited by: 50 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1145/3672459,Benchmarking; Computer software selection and evaluation; Intelligent agents; Intelligent virtual...,,,,,,,
rayyan-394626765,"A-TEST 2024 - Proceedings of the 15th ACM International Workshop on Automating Test Case Design, Selection and Evaluation, Co-located with: SSTA 2024",2024,,,,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207225924&partnerID=40&md5=4031f9ed95d9d102d63cead39b13d5c5,,,,"The proceedings contain 3 papers. The topics discussed include: GreeDDy: accelerate parallel DDMIN; use of ChatGPT as an assistant in the end-to-end test script generation for android apps; and first experiments on automated execution of gherkin test specifications with collaborating LLM agents. © 2024 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""}",,,,,,,,,
rayyan-394626766,First Experiments on Automated Execution of Gherkin Test Specifications with Collaborating LLM Agents,2024,,,,,,,12 - 15,"Bergsmann, Severin and Schmidt, Alexander and Fischer, Stefan and Ramler, Rudolf",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207104093&doi=10.1145%2F3678719.3685692&partnerID=40&md5=96e8a10edaf283adc4a4c1910d96fd0e,,,,"Gherkin is a domain-specific language for describing test scenarios in natural language, which are the basis for automated acceptance testing. The emergence of Large Language Models (LLMs) has opened up new possibilities for processing such test specifications and for generating executable test code. This paper investigates the feasibility of employing LLMs to execute Gherkin test specifications utilizing the AutoGen multi-agent framework. Our findings show that our LLM agent system is able to automatically run the given test scenarios by autonomously exploring the system under test, generating executable test code on the fly, and evaluating execution results. We observed high success rates for executing simple as well as more complex test scenarios, but we also identified difficulties regarding failure scenarios and fault detection. © 2024 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""gerkin""]}",10.1145/3678719.3685692,Autonomous agents; Intelligent agents; Model checking; Specification languages; Domains specific ...,,,,,,,
rayyan-394626767,AutoCodeRover: Autonomous Program Improvement,2024,,,,,,,1592 - 1604,"Zhang, Yuntong and Ruan, Haifeng and Fan, Zhiyu and Roychoudhury, Abhik",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203182652&doi=10.1145%2F3650212.3680384&partnerID=40&md5=310c02174e2875183e70cc48042048fa,,,,"Researchers have made significant progress in automating the software development process in the past decades. Automated techniques for issue summarization, bug reproduction, fault localization, and program repair have been built to ease the workload of developers. Recent progress in Large Language Models (LLMs) has significantly impacted the development process, where developers can use LLM-based programming assistants to achieve automated coding. Nevertheless, software engineering involves the process of program improvement apart from coding, specifically to enable software maintenance (e.g. program repair to fix bugs) and software evolution (e.g. feature additions). In this paper, we propose an automated approach for solving Github issues to autonomously achieve program improvement. In our approach called AutoCodeRover, LLMs are combined with sophisticated code search capabilities, ultimately leading to a program modification or patch. In contrast to recent LLM agent approaches from AI researchers and practitioners, our outlook is more software engineering oriented. We work on a program representation (abstract syntax tree) as opposed to viewing a software project as a mere collection of files. Our code search exploits the program structure in the form of classes/methods to enhance LLM's understanding of the issue's root cause, and effectively retrieve a context via iterative search. The use of spectrum-based fault localization using tests, further sharpens the context, as long as a test-suite is available. Experiments on the recently proposed SWE-bench-lite (300 real-life Github issues) show increased efficacy in solving Github issues (19% on SWE-bench-lite), which is higher than the efficacy of the recently reported Swe-agent. Interestingly, our approach resolved 57 GitHub issues in about 4 minutes each (pass@1), whereas developers spent more than 2.68 days on average. In addition, AutoCodeRover achieved this efficacy with significantly lower cost (on average, $0.43 USD), compared to other baselines. We posit that our workflow enables autonomous software engineering, where, in future, auto-generated code from LLMs can be autonomously improved. © 2024 Elsevier B.V., All rights reserved.","Cited by: 27; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""solve issues""]}",10.1145/3650212.3680384,Computer debugging; Computer software maintenance; Computer software selection and evaluation; Co...,,,,,,,
rayyan-394626768,Multi-agent voltage control in distribution systems using GAN-DRL-based approach,2024,,,Electric Power Systems Research,,234,,,"Hossain, Rakib and Gautam, Mukesh and Olowolaju, Joshua and Livani, Hanif and Benidris, Mohammed A.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195180990&doi=10.1016%2Fj.epsr.2024.110528&partnerID=40&md5=7c175170798fdf2f64e414dd6f00e7cc,,,,"Active distribution grids can experience voltage fluctuations and violations due to the high penetration of variable distributed energy resources (DERs). These problems might occur because of the uncertain and variable generation natures of these resources, especially solar photovoltaic resources, during panel shadowing scenarios. Volt-VAR control (VVC) is an efficient method that controls the reactive power set-points of the inverters to regulate the voltage of distribution grids. Although several VVC approaches have been proposed recently, the performance of these approaches degrades significantly if behind-the-meter solar generation data are unobservable/missing. Therefore, it is necessary to impute missing/unobservable PV data accurately to be utilized in VVC approaches. This paper proposes a model-free, data-driven, centrally trained, and decentrally executed multi-agent deep reinforcement learning-based VVC architecture to regulate the voltage of distribution networks. A generative adversarial network (GAN) is incorporated to impute the unobservable PV data accurately, which improves the performance of the proposed control architecture. The proposed multi-agent-soft-actor–critic algorithm (MASAC)-based VVC technique utilizes the actual PV dataset as well as the imputed dataset from the GAN framework to learn the optimal coordinated control policy for controlling the optimal reactive power set-points of PV inverters. The effectiveness of the proposed approach is analyzed on a modified IEEE 34-bus test case with added PV inverters. The results are compared and analyzed with a base case model with no VVC and VVC with a local droop control approach, genetic algorithm optimization, and a centralized soft actor–critic-based approach. Moreover, the performance of the proposed approach is compared with that of a multi-agent VVC framework without using the PV generation data and load information as the system state. The results illustrate that the proposed method with more state input improves the voltage profile and reduces the power loss of the network across various loading and PV generation scenarios. © 2024 Elsevier B.V., All rights reserved.","Cited by: 8; All Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1016/j.epsr.2024.110528,Electric inverters; Electric loads; Electric power distribution; Electric power system control; E...,,,,,,,
rayyan-394626769,Generative Adversarial Imitation Learning Based Bicycle Behaviors Simulation on Road Segments; 基于生成对抗模仿学习的路段非机动车行为仿真,2024,,,Jiaotong Yunshu Xitong Gongcheng Yu Xinxi/ Journal of Transportation Systems Engineering and Information Technology,,24,4,105 - 115,"Wei, Shuqiao and Ni, Ying and Sun, Jian and Qiu, Hongtong",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203195647&doi=10.16097%2Fj.cnki.1009-6744.2024.04.011&partnerID=40&md5=1cfdd422239e0ecbb6a6b2d9c80153dc,,,,"In order to accurately reproduce the interaction behavior of bicycles to meet the needs of autonomous driving simulation testing, a Position Reward Augmented Generative Adversarial Imitation Learning (PRA-GAIL) method is proposed. In urban roads, since the disturbance behavior is mainly generated by electric bicycles, electric bicycles are selected as the research object. In the constructed simulation environment, Generative Adversarial Imitation Learning (GAIL) is used to make the simulated trajectories approximate the real trajectories, while Position Reward and Lagrangian Constraint methods are added to solve the homogenization and uncontrollable behaviors of existing simulation methods. In the test set validation, the average displacement error of the GAIL and PRA-GAIL methods decreased by 61.7% and 65.8%, respectively, compared to the behavioral cloning method. In the behavioral performance validation, the KL divergence of acceleration distributions between simulation and reality was significantly reduced in PRA-GAIL compared to GAIL, and the percentage error of overtaking and illegal lane-changing behaviors decreased by 7.2% and 20.2%, respectively. Using the Lagrangian method to add constraints resulted in a 75.8% reduction in the number of agents with risky behavior compared to commonly used reward augmentation methods. In trajectory validation, in the simulation environment, the average displacement error of PRA-GAIL is reduced by 17.5% compared to GAIL. The resulting model realistically reproduces the overtaking maneuver space of cyclists. The results show that the method adopted in this paper is suitable for bicycle behavior simulation, the proposed modifications effectively enhance the simulation performance, and the obtained simulation model accurately reproduces the disturbance behavior of bicycles on road segments, which can be applied to automated vehicle simulation tests. © 2024 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.16097/j.cnki.1009-6744.2024.04.011,Automobile driver simulators; Automobile testing; Homogenization method; Lagrange multipliers; Ma...,,,,,,,
rayyan-394626770,Reasoning and Planning with Large Language Models in Code Development,2024,,,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,6480 - 6490,"Ding, Hao and Fan, Ziwei and Guehring, Ingo and Gupta, Gaurav and Ha, Wooseok and Huan, Jun and Liu, Linbo and Omidvar-Tehrani, Behrooz and Wang, Shiqi and Zhou, Hao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203695772&doi=10.1145%2F3637528.3671452&partnerID=40&md5=fc12de2370734bff9def6340f3d29a54,,,,"Large Language Models (LLMs) are revolutionizing the field of code development by leveraging their deep understanding of code patterns, syntax, and semantics to assist developers in various tasks, from code generation and testing to code understanding and documentation. In this survey, accompanying our proposed lecture-style tutorial for KDD 2024, we explore the multifaceted impact of LLMs on the code development, delving into techniques for generating a high-quality code, creating comprehensive test cases, automatically generating documentation, and engaging in an interactive code reasoning. Throughout the survey, we highlight some crucial components surrounding LLMs, including pre-training, fine-tuning, prompt engineering, iterative refinement, agent planning, and hallucination mitigation. We put forward that such ingredients are essential to harness the full potential of these powerful AI models in revolutionizing software engineering and paving the way for a more efficient, effective, and innovative future in code development. © 2025 Elsevier B.V., All rights reserved.","Cited by: 6; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1145/3637528.3671452,Digital elevation model; Software agents; Software testing; Syntactics; Application modernization...,,,,,,,
rayyan-394626771,A New Generation of Intelligent Development Environments,2024,,,,,,,43 - 46,"Marron, Mark",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202433134&doi=10.1145%2F3643796.3648452&partnerID=40&md5=a3b21d5959d1802461780485e0036d84,,,,"The practice of programming is undergoing a revolution with the introduction of AI assisted development (copilots) and the creation of new programming languages that are designed explicitly for tooling, analysis, and automation. Integrated Development Environments (IDEs) as they are currently conceptualized have not yet responded to these changes. They are still designed around the idea of a human programmer typing textual code into an editor window with the IDE providing assistance via the integration of various tools for syntax highlighting, compilation, debugging, and (maybe) code version control. This paper presents a vision for transforming the IDE from an Integrated Development Environment to an Intelligent Development Environment. The new IDE will be designed around the idea of a human programmer as the manager or curator of a software project who, rather than manually typing in code to implement a solution, will instead use the IDE to direct AI programming agents and/or automated tools to combine existing APIs, packages, and new code to implement the needed features. In this new model, the fundamental roles of the IDE are to 1) facilitate the communication between the human programmer and the AI agents and automated tools and 2) organize the workflow tasks needed to go from requirements gathering to the final tested and validated deployed feature. This paper presents a vision for the new Intelligent Development Environment based on a range of proof-of-concept high-value scenarios we have experimented with and discusses the challenges that remain to realizing these in a cohesive intelligent development experience. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""ide agent, suggets ?""]}",10.1145/3643796.3648452,Computer debugging; Intelligent agents; Software testing; AI assisted programming; Automated tool...,,,,,,,
rayyan-394626772,Large Language Model-based Test Case Generation for GP Agents,2024,,,,,,,914 - 923,"Jorgensen, Steven and Nadizar, Giorgia and Pietropolli, Gloria and Manzoni, Luca and Medvet, Eric and O'Reilly, Una May and Hemberg, Erik",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206916406&doi=10.1145%2F3638529.3654056&partnerID=40&md5=278ef19fd4082e819c67a0e167225af3,,,,"Genetic programming (GP) is a popular problem-solving and optimization technique. However, generating effective test cases for training and evaluating GP programs requires strong domain knowledge. Furthermore, GP programs often prematurely converge on local optima when given excessively difficult problems early in their training. Curriculum learning (CL) has been effective in addressing similar issues across different reinforcement learning (RL) domains, but it requires the manual generation of progressively difficult test cases as well as their careful scheduling. In this work, we leverage the domain knowledge and the strong generative abilities of large language models (LLMs) to generate effective test cases of increasing difficulties and schedule them according to various curricula. We show that by integrating a curriculum scheduler with LLM-generated test cases we can effectively train a GP agent player with environments-based curricula for a single-player game and opponent-based curricula for a multi-player game. Finally, we discuss the benefits and challenges of implementing this method for other problem domains. © 2024 Elsevier B.V., All rights reserved.","Cited by: 7; All Open Access; Hybrid Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1145/3638529.3654056,Adversarial machine learning; Contrastive Learning; Curricula; Domain Knowledge; Modeling languag...,,,,,,,
rayyan-394626773,Mutation Testing for Task-Oriented Chatbots,2024,,,,,,,232 - 241,"Gómez-Abajo, Pablo and Perez-Soler, Sara and Cañizares, Pablo C. and Guerra, Esther and Lara, Juan De",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197414986&doi=10.1145%2F3661167.3661220&partnerID=40&md5=a695baef7c9f20af2ef2f3a7480605dd,,,,"Conversational agents, or chatbots, are increasingly used to access all sorts of services using natural language. While open-domain chatbots - like ChatGPT - can converse on any topic, task-oriented chatbots - the focus of this paper - are designed for specific tasks, like booking a flight, obtaining customer support, or setting an appointment. Like any other software, task-oriented chatbots need to be properly tested, usually by defining and executing test scenarios (i.e., sequences of user-chatbot interactions). However, there is currently a lack of methods to quantify the completeness and strength of such test scenarios, which can lead to low-quality tests, and hence to buggy chatbots. To fill this gap, we propose adapting mutation testing (MuT) for task-oriented chatbots. To this end, we introduce a set of mutation operators that emulate faults in chatbot designs, an architecture that enables MuT on chatbots built using heterogeneous technologies, and a practical realisation as an Eclipse plugin. Moreover, we evaluate the applicability, effectiveness and efficiency of our approach on open-source chatbots, with promising results. © 2024 Elsevier B.V., All rights reserved.","Cited by: 3 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.1145/3661167.3661220,Botnet; Botium; Chatbots; Conversational agents; Dialogflow; Mutation testing; Natural languages;...,,,,,,,
rayyan-394626774,Coverage-based Strategies for the Automated Synthesis of Test Scenarios for Conversational Agents,2024,,,,,,,23 - 33,"Cañizares, Pablo C. and Ávila, Daniel and Perez-Soler, Sara and Guerra, Esther and Lara, Juan De",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196398493&doi=10.1145%2F3644032.3644456&partnerID=40&md5=1a07cb9731740db2bace5b78bda5d552,,,,"Conversational agents-or chatbots-are increasingly used as the user interface to many software services. While open-domain chatbots like ChatGPT excel in their ability to chat about any topic, task-oriented conversational agents are designed to perform goal-oriented tasks (e.g., booking or shopping) guided by a dialogue-based user interaction, which is explicitly designed. Like any kind of software system, task-oriented conversational agents need to be properly tested to ensure their quality. For this purpose, some tools permit defining and executing conversation test cases. However, there are currently no established means to assess the coverage of the design of a task-oriented agent by a test suite, or mechanisms to automate quality test case generation ensuring the agent coverage.To attack this problem, we propose test coverage criteria for task-oriented conversational agents, and define coverage-based strategies to synthesise test scenarios, some oriented to test case reduction. We provide an implementation of the criteria and the strategies that is independent of the agent development platform. Finally, we report on their evaluation on open-source Dialogflow and Rasa agents, and a comparison against a state-of-The-Art testing tool. The experiment shows benefits in terms of test generation correctness, increased coverage and reduced testing time. © 2025 Elsevier B.V., All rights reserved.","Cited by: 5; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""chatbot cenarios de test""]}",10.1145/3644032.3644456,Open source software; Software agents; Software testing; Automated synthesis; Chatbots; Conversat...,,,,,,,
rayyan-394626775,"Proceedings - 2024 IEEE/ACM International Conference on Automation of Software Test, AST 2024",2024,,,,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196368939&partnerID=40&md5=71f9f2911bbe3fedb4218360dd66b435,,,,"The proceedings contain 26 papers. The topics discussed include: mutation coverage is not strongly correlated with mutation coverage; running a red light: an investigation into why software engineers (occasionally) ignore coverage checks; coverage-based strategies for the automated synthesis of test scenarios for conversational agents; using GitHub copilot for test generation in Python: an empirical study; grammar-based action selection rules for scriptless testing; fences: systematic sample generation for JSON schemas using Boolean algebra and flow graphs; generating software tests for mobile applications using fine-tuned large language models; sugar-coated poison defense on deepfake face-swapping attacks; anonymizing test data in android: does it hurt?; and properties that allow or prohibit transferability of adversarial attacks among quantized networks. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626776,ICSE 2024 - Proceedings of the 46th IEEE/ACM International Conference on Software Engineering,2024,,,Proceedings - International Conference on Software Engineering,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185600215&partnerID=40&md5=c44294d715f21e7bdde299c08eef4d71,,,,"The proceedings contain 68 papers. The topics discussed include: a large-scale survey on the usability of ai programming assistants: successes and challenges; LogShrink: effective log compression by leveraging commonality and variability of log data; how to support ML end-user programmers through a conversational agent; kind controllers and fast heuristics for non-well-separated GR(1) specifications; domain knowledge matters: improving prompts with fix templates for repairing python type errors; EDEFuzz: a web API Fuzzer for excessive data exposures; large language models are few-shot summarizers: multi-intent comment generation via in-context learning; modularizing while training: a new paradigm for modularizing DNN models; FAIR: flow type-aware pre-training of compiler intermediate representations; prompting is all you need: automated android bug replay with large language models; and do automatic test generation tools generate flaky tests?. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626777,ACM International Conference Proceeding Series,2024,,,,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184338205&partnerID=40&md5=be404bb8ea6880aefdbf9633cec2b57a,,,,"The proceedings contain 22 papers. The topics discussed include: combinatorial transition testing in dynamically adaptive systems; partial proofs to optimize deductive verification of feature-oriented software product lines; incremental identification of T-wise feature interactions; UnWise: high T-Wise coverage from uniform sampling; sampling cardinality-based feature models; leveraging software product lines for testing automated driving systems; managing customizable user interface for web application product lines using delta modeling; generative AI and software variability – a research vision; towards feature-based versioning for musicological research; variability in data transformation: towards data migration product lines; explaining edits to variability annotations in evolving software product lines; handling automotive hardware/software co-configurations with integer difference logic; conversational agents in healthcare: a variability perspective; and a practitioners perspective on addressing cyber security and variability challenges in modern automotive systems. © 2024 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626778,Try-Then-Eval: Equipping an LLM-based Agent with a Two-Phase Mechanism to Solve Computer Tasks,2024,,,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",,,,1224 - 1229,"Cao, Duy and Nguyen, Phu Khoa and Le, Vy and Nguyen, Long Hong Buu and Nguyen, Vu Thanh D.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217854479&doi=10.1109%2FSMC54092.2024.10831260&partnerID=40&md5=02525e9757b73b387b961b937acd6ad5,,,,"Building an autonomous intelligent agent capable of carrying out web automation tasks from descriptions in natural language offers a wide range of applications, including software testing, virtual assistants, and task automation in general. However, recent studies addressing this problem often require manually constructing of prior human demonstrations. In this paper, we approach the problem by leveraging the idea of reinforcement learning (RL) with the two-phase mechanism to form an agent using LLMs for automating computer tasks without relying on human demonstrations. We evaluate our LLM-based agent using the MiniWob++ dataset of web-based application tasks, showing that our approach achieves 85% success rate without prior demonstrations. The results also demonstrate the agent's capability of self-improvement through training. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.1109/SMC54092.2024.10831260,Autonomous agents; Chatbots; Demonstrations; Intelligent agents; Intelligent virtual agents; Prob...,,,,,,,
rayyan-394626779,Unit Test Generation Multi-Agent AI System for Enhancing Software Documentation and Code Coverage,2024,,,,,,,,"Stojanovic, Dimitrije and Pavković, Bogdan and Četić, Nenad B. and Krunić, Momčilo V. and Vidakovic, Luka",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216854650&doi=10.1109%2FTELFOR63250.2024.10819096&partnerID=40&md5=590d88c939c87c1b052534a891819d4c,,,,"Software development necessitates a robust testing plan though test development can be laborious and nonappealing task. We explore the utilization of the application artificial intelligence agents for generating and executing unit tests, enhancing the 'Mostly Basic Python Problems' dataset. We employ behavior-driven development within a three-agent system to generate user stories and unit tests. Empirical results indicate improvements in branch coverage, illustrating the effective utilization of large language models in software testing and development processes. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/TELFOR63250.2024.10819096,Distribution transformers; Electric transformer testing; Model checking; Problem oriented languag...,,,,,,,
rayyan-394626780,IryoNLP* at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents,2024,,,,,,,570 - 580,"Corbeil, Jean Philippe",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216813757&partnerID=40&md5=e2b6d7faf89ea153fa361344e13a315d,,,,"In natural language processing applied to the clinical domain, utilizing large language models has emerged as a promising avenue for error detection and correction on clinical notes, a knowledge-intensive task for which annotated data is scarce. This paper presents MedReAct’N’MedReFlex, which leverages a suite of four LLM-based medical agents. The MedReAct agent initiates the process by observing, analyzing, and taking action, generating trajectories to guide the search to target a potential error in the clinical notes. Subsequently, the MedEval agent employs five evaluators to assess the targeted error and the proposed correction. In cases where MedReAct’s actions prove insufficient, the MedReFlex agent intervenes, engaging in reflective analysis and proposing alternative strategies. Finally, the MedFinalParser agent formats the final output, preserving the original style while ensuring the integrity of the error correction process. One core component of our method is our RAG pipeline based on our ClinicalCorp corpora. Among other well-known sources containing clinical guidelines and information, we preprocess and release the open-source MedWiki dataset for clinical RAG application. Our results demonstrate the central role of our RAG approach with ClinicalCorp leveraged through the MedReAct’N’MedReFlex framework. It achieved the ninth rank on the MEDIQA-CORR 2024 final leaderboard. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",,Modeling languages; Natural language processing systems; Clinical notes; Error detection and corr...,,,,,,,
rayyan-394626781,Aegis:An Advanced LLM-Based Multi-Agent for Intelligent Functional Safety Engineering,2024,,,,,,,1571 - 1583,"Shi, Lu and Qi, Bin and Luo, Jiarui and Zhang, Yang and Liang, Zhanzhao and Gao, Zhaowei and Deng, Wenke and Sun, Lin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216731136&doi=10.18653%2Fv1%2F2024.emnlp-industry.115&partnerID=40&md5=9a12586fae2fc0233e68586a031a1614,,,,"Functional safety is a critical aspect of automotive engineering, encompassing all phases of a vehicle’s lifecycle, including design, development, production, operation, and decommissioning. This domain involves highly knowledge-intensive tasks. This paper introduces Aegis: An Advanced LLM-Based Multi-Agent for Intelligent Functional Safety Engineering. Aegis is specifically designed to support complex functional safety tasks within the automotive sector. It is tailored to perform Hazard Analysis and Risk Assessment (HARA), document Functional Safety Requirements (FSR), and plan test cases for Automatic Emergency Braking (AEB) systems. The most advanced version, Aegis-Max, leverages Retrieval-Augmented Generation (RAG) and reflective mechanisms to enhance its capability in managing complex, knowledge-intensive tasks. Additionally, targeted prompt refinement by professional functional safety practitioners can significantly optimize Aegis’s performance in the functional safety domain. This paper demonstrates the potential of Aegis to improve the efficiency and effectiveness of functional safety processes in automotive engineering. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.18653/v1/2024.emnlp-industry.115,Accident prevention; Automatic testing; Automotive industry; Computational linguistics; All phase...,,,,,,,
rayyan-394626782,Automated test generation to evaluate tool-augmented LLMs as conversational AI agents,2024,,,,,,,54 - 68,"Arcadinho, Samuel and Aparício, David and Almeida, Mariana S.C.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216591803&partnerID=40&md5=eeb0044155d867548dffcb3f87a276bb,,,,"Tool-augmented LLMs are a promising approach to create AI agents that can have realistic conversations, follow procedures, and call appropriate functions. However, evaluating them is challenging due to the diversity of possible conversations, and existing datasets focus only on single interactions and function-calling. We present a test generation pipeline to evaluate LLMs as conversational AI agents. Our framework uses LLMs to generate diverse tests grounded on user-defined procedures. For that, we use intermediate graphs to limit the LLM test generator’s tendency to hallucinate content that is not grounded on input procedures, and enforces high coverage of the possible conversations. Additionally, we put forward ALMITA, a manually curated dataset for evaluating AI agents in customer support, and use it to evaluate existing LLMs. Our results show that while tool-augmented LLMs perform well in single interactions, they often struggle to handle complete conversations. While our focus is on customer support, our method is general and capable of AI agents for different domains. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",,Automatic test pattern generation; Computational linguistics; Am generals; Automated test generat...,,,,,,,
rayyan-394626783,"GenBench 2024 - GenBench: 2nd Workshop on Generalisation (Benchmarking) in NLP, Proceedings of the Workshop",2024,,,,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216585900&partnerID=40&md5=259e163ab95af8cfeb414c3b64c44cd1,,,,"The proceedings contain 13 papers. The topics discussed include: evaluating the fairness of task-adaptive pretraining on unlabeled test data before few-shot text classification; from language to pixels: task recognition and task learning in LLMs; the SlayQA benchmark of social reasoning: testing gender-inclusive generalization with neopronouns; automated test generation to evaluate tool-augmented LLMs as conversational AI agents; MMLU-SR: a benchmark for stress-testing reasoning capability of large language models; MLissard: multilingual long and simple sequential reasoning benchmarks; MultiPragEval: multilingual pragmatic evaluation of large language models; beyond the numbers: transparency in relation extraction benchmark creation and leaderboards; and is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don’t mimic the full human distribution. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626784,RGD: Multi-LLM Based Agent Debugger via Refinement and Generation Guidance,2024,,,,,,,136 - 141,"Jin, Haolin and Sun, Zechao and Chen, Huaming",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215607472&doi=10.1109%2FICA63002.2024.00037&partnerID=40&md5=bad4ee6cce20c207147b12cb02bf5210,,,,"Large Language Models (LLMs) have shown incredible potential in code generation tasks, and recent research in prompt engineering have enhanced LLMs' understanding of textual information. However, ensuring the accuracy of generated code often requires extensive testing and validation by programmers. While LLMs can typically generate code based on task descriptions, their accuracy remains limited, especially for complex tasks that require a deeper understanding of both the problem statement and the code generation process. This limitation is primarily due to the LLMs' need to simultaneously comprehend text and generate syntactically and semantically correct code, without having the capability to automatically refine the code. In real-world software development, programmers seldom produce flawless code on their first attempt. Instead, iterative feedback and debugging are heavily leveraged to refine the programs. Inspired by this process, we introduce a novel architecture of LLM-based agents for code generation and automatic debugging: Refinement and Guidance Debugging (RGD). The RGD framework is a multi-LLM-based agent debugger that leverages three distinct LLM agents-Guide Agent, Debug Agent, and Feedback Agent. RGD decomposes the code generation task into multiple steps, ensuring a clearer workflow and enabling iterative code refinement based on self-reflection and feedback. Experimental results demonstrate that RGD exhibits remarkable code generation capabilities, achieving state-of-the-art performance with a 9.8% improvement on the HumanEval dataset and a {1 6. 2%} improvement on the MBPP dataset compared to the state-of-theart approaches and traditional direct prompting approaches. We highlight the effectiveness of the RGD framework in enhancing LLMs' ability to generate and refine code autonomously. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/ICA63002.2024.00037,Automatic programming; Autonomous agents; Behavioral research; Computer debugging; Error correcti...,,,,,,,
rayyan-394626785,Test-Agent: A Multimodal App Automation Testing Framework Based on the Large Language Model,2024,,,,,,,609 - 614,"Li, Youwei and Li, Yangyang and Yang, Yangzhao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214923908&doi=10.1109%2FDTPI61353.2024.10778901&partnerID=40&md5=2df3aabdcab54e9e039471ef43a47e60,,,,"This paper introduces a multimodal agent-based app automation testing framework, named Test-Agent, built on the Large Language Model (LLM), designed to address the growing challenges in mobile application automation testing. As mobile applications become more prevalent and emerging systems like Harmony OS Next and mini-programs emerge, traditional automated testing methods, which depend on manually crafting test cases and scripts, are no longer sufficient for cross-platform compatibility and complex interaction logic. The Test-Agent framework employs artificial intelligence technologies to analyze application interface screenshots and user natural language instructions. Combined with deep learning models, it automatically generates and executes test actions on mobile devices. This innovative approach eliminates the need for pre-written test scripts or backend system access, relying solely on screenshots and UI structure information. It achieves cross-platform and cross-application universality, significantly reducing the workload of test case writing, enhancing test execution efficiency, and strengthening cross-platform adaptability. Test-Agent offers an innovative and efficient solution for automated testing of mobile applications. © 2025 Elsevier B.V., All rights reserved.","Cited by: 2 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/DTPI61353.2024.10778901,Application programs; Computer debugging; Computer operating systems; Mobile agents; Model checki...,,,,,,,
rayyan-394626786,Failure Management Overview in Optical Networks,2024,,,IEEE Access,,12,,169170 - 169193,"Cruzes, Sergio",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209748371&doi=10.1109%2FACCESS.2024.3498704&partnerID=40&md5=8b5727e8bce93d9b97fbcfcc7b03c5bd,,,,"Conventional optical networks are limited by static operational methods that hinder their scalability and effectiveness. As networks operate with reduced margins to maximize resource utilization, the risk of hard failures increases, necessitating efficient failure prediction systems and accurate quality of transmission (QoT) estimation. Effective management requires the detection of soft failures, accurate bit error rate (BER) predictions, and dynamic network operations to maintain minimal margins. Machine learning (ML) offers promising solutions for automating these tasks, significantly enhancing failure management and network reliability. This article provides an extensive overview of ML techniques applied to optical networks, specifically focusing on failure management. The key ML techniques discussed include network kriging (NK) for performance estimation and failure localization, support vector machine (SVM) for classification tasks, convolutional neural networks (CNNs) for signal analysis and soft failure identification, and generative adversarial networks (GANs) for synthetic data generation and soft failure detection. It also explores the application of artificial neural networks (ANNs), autoencoders (AEs), Gaussian process (GP), long short-term memory (LSTM), and gated recurrent units (GRUs) in optical networks. This study surveys ML techniques for early-warning and failure prediction, failure detection, identification, localization, magnitude estimation, and soft failure detection and prediction. Emphasizing automation, it discusses how ML algorithms can streamline failure management processes, reducing manual intervention and service disruptions. The potential of large language models (LLMs) and digital twins (DTs) for further advancements in automating failure management, optimizing performance, and network optimization in optical networks is also examined. LLMs significantly advance network management by improving network design, diagnosis, security, and autonomous optimization through the integration of comprehensive domain resources and intelligent agents. These advancements are paving the way towards achieving artificial general intelligence and fully automated optical network management. © 2024 Elsevier B.V., All rights reserved.","Cited by: 11; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",10.1109/ACCESS.2024.3498704,Benchmarking; Convolutional neural networks; Error statistics; Fiber to the x; Forward error corr...,,,,,,,
rayyan-394626787,Fight Fire With Fire: How Much Can We Trust ChatGPT on Source Code-Related Tasks?,2024,,,IEEE Transactions on Software Engineering,,50,12,3435 - 3453,"Yu, Xiao and Liu, Lei and Hu, Xing and Keung, Jacky Wai and Liu, Jin and Xia, Xin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208721822&doi=10.1109%2FTSE.2024.3492204&partnerID=40&md5=11df2cbefd5bdd1d5eed10afaaccef29,,,,"With the increasing utilization of large language models such as ChatGPT during software development, it has become crucial to verify the quality of code content it generates. Recent studies proposed utilizing ChatGPT as both a developer and tester for multi-agent collaborative software development. The multi-agent collaboration empowers ChatGPT to produce test reports for its generated code, enabling it to self-verify the code content and fix bugs based on these reports. However, these studies did not assess the effectiveness of the generated test reports in validating the code. Therefore, we conduct a comprehensive empirical investigation to evaluate ChatGPT's self-verification capability in code generation, code completion, and program repair. We request ChatGPT to (1) generate correct code and then self-verify its correctness; (2) complete code without vulnerabilities and then self-verify for the presence of vulnerabilities; and (3) repair buggy code and then self-verify whether the bugs are resolved. Our findings on two code generation datasets, one code completion dataset, and two program repair datasets reveal the following observations: (1) ChatGPT often erroneously predicts its generated incorrect code as correct, its vulnerable completed code as non-vulnerable, and its failed program repairs as successful during its self-verification. (2) The self-contradictory hallucinations in ChatGPT's behavior arise: (a) ChatGPT initially generates code that it believes to be correct but later predicts it to be incorrect; (b) ChatGPT initially generates code completions that it deems secure but later predicts them to be vulnerable; (c) ChatGPT initially outputs code that it considers successfully repaired but later predicts it to be buggy during its self-verification. (3) The self-verification capability of ChatGPT can be enhanced by asking the guiding question, which queries whether ChatGPT agrees with assertions about incorrectly generated or repaired code and vulnerabilities in completed code. (4) Using test reports generated by ChatGPT can identify more vulnerabilities in completed code, but the explanations for incorrectly generated code and failed repairs are mostly inaccurate in the test reports. Based on these findings, we provide implications for further research or development using ChatGPT. © 2024 Elsevier B.V., All rights reserved.","Cited by: 2 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""secundario ?""]}",10.1109/TSE.2024.3492204,C (programming language); Chatbots; Computer debugging; Computer software maintenance; Computer s...,,,,,,,
rayyan-394626788,ADAGENT: Anomaly Detection Agent With Multimodal Large Models in Adverse Environments,2024,,,IEEE Access,,12,,172061 - 172074,"Zhang, Miao and Shen, Yiqing and Yin, Jun and Lu, Shuai and Wang, Xueqian",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207726151&doi=10.1109%2FACCESS.2024.3480250&partnerID=40&md5=1dd672e8f2475c7bcbce7de31435a71d,,,,"Multimodal Language Models (MMLMs), such as LLaVA and GPT-4V, have shown zero-shot generalization capabilities for understanding images and text across various domains. However, their effectiveness in open-world visual tasks, particularly anomaly detection under challenging conditions, such as low light or poor image quality, has yet to be thoroughly investigated. Assessing the robustness and limitations of MMLMs in these scenarios is essential to ensuring their reliability and safety in real-world applications, where the input image quality can vary significantly. To address this gap, we propose a benchmark comprising 460 images captured under challenging conditions, including low light and blurring. This benchmark is specifically designed to evaluate the anomaly detection capabilities of MMLMs. We assess the performance of state-of-the-art MMLMs, such as Qwen-VL-Max-0809, GPT-4V, Gemini-1.5, Claude3-opus, ERNIE-Bot-4, and SparkDesk-v3.5, across six diverse scenes. Our evaluations indicate that these MMLMs struggle with error detection in adverse scenarios, thereby highlighting the need for further investigation into the underlying causes and potential improvement strategies. To tackle these limitations, we introduce a novel anomaly detection agent (ADAGENT) framework, which is an AI agent framework that combines the ""Chain of Critical Self-Reflection (CCS)"", specialized toolsets, and ""Heuristic Retrieval-Augmented Generation (RAG)""to enhance anomaly detection performance with MMLMs. ADAGENT sequentially evaluates abilities, such as text generation, semantic understanding, contextual comprehension, key information extraction, reasoning, and logical thinking. By implementing this framework, we demonstrated a 15%∼ 30% improvement in the top-3 accuracy for anomaly detection tasks under adverse conditions, compared with baseline approaches. © 2024 Elsevier B.V., All rights reserved.","Cited by: 9; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Tester agent, testar imagens ?""]}",10.1109/ACCESS.2024.3480250,Ada (programming language); Benchmarking; Agent Framework; AI agent; Anomaly detection; Condition...,,,,,,,
rayyan-394626789,Extending the Frontier of ChatGPT: Code Generation and Debugging,2024,,,,,,,,"Sakib, Fardin Ahsan and Khan, Saadat Hasan and Karim, A. H.M.Rezaul",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207460221&doi=10.1109%2FICECET61485.2024.10698405&partnerID=40&md5=9061172122ad4b9fa410d2c10d273c63,,,,"Large language models (LLMs), trained on vast corpora, have emerged as a groundbreaking innovation in the realm of question-answering and conversational agents. Among these LLMs, ChatGPT has pioneered a new phase in AI, adeptly handling varied tasks from writing essays and biographies to solving complex mathematical problems. However, assessing the performance of ChatGPT's output poses a challenge, particularly in scenarios where queries lack clear objective criteria for correctness. We delve into the efficacy of ChatGPT (GPT-4) in generating correct code for programming problems, examining both the correctness and the efficiency of its solution in terms of time and memory complexity. A custom dataset containing problems of various topics and difficulties from Leetcode has been used. The research reveals an overall success rate of 71.875%, denoting the proportion of problems for which ChatGPT was able to provide correct solutions that successfully satisfied all the test cases present in Leetcode. It exhibits strength in structured problems and shows a linear correlation between its success rate and problem acceptance rates. However, it struggles to improve incorrect solutions based on feedback, pointing to potential shortcomings in debugging tasks. These findings provide a compact yet insightful glimpse into ChatGPT's capabilities and areas for improvement. © 2024 Elsevier B.V., All rights reserved.","Cited by: 8 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Secundário""]}",10.1109/ICECET61485.2024.10698405,Acceptance tests; Computer debugging; Program debugging; Structured programming; ChatGPT; Code de...,,,,,,,
rayyan-394626790,"PENTEST-AI, an LLM-Powered Multi-Agents Framework for Penetration Testing Automation Leveraging Mitre Attack",2024,,,,,,,763 - 770,"Bianou, Stanislas G. and Batogna, Rodrigue G.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206186144&doi=10.1109%2FCSR61664.2024.10679480&partnerID=40&md5=31791a7ca25673d064f6b1d90e42bb04,,,,"In the digital transformation era, the surge of better development technologies and citizen developers disrupted the space of innovation by increasing the number and complexity of applications used in production. This context prompts advanced cybersecurity measures and more frequent and thorough penetration testing to protect an organization's security posture. The scarcity of skilled expertise in cybersecurity today makes it challenging to cope with the evolving challenge and the growing demand. This paper introduces PENTESTAI, a novel framework for penetration testing automation using Large Language Model (LLM)-powered agents leveraging the MITRE ATTACK knowledge base. The paper provides an overview of the current state of research on cybersecurity and LLM-powered agents, followed by a detailed description of PENTESTAI building blocks. A proof-of-concept implementation is discussed to validate the framework's core constructs. The paper concludes with suggestions for future research directions to achieve the highest level of penetration testing automation with average skilled human-agent collaboration and to create citizen penetration testers. © 2024 Elsevier B.V., All rights reserved.","Cited by: 10 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Pentest agent""]}",10.1109/CSR61664.2024.10679480,Model checking; Multi agent systems; AI agent; Citizen penetration tester; Cyber security; Langua...,,,,,,,
rayyan-394626791,MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization,2024,,,Proceedings of the Annual Meeting of the Association for Computational Linguistics,,,,11789 - 11804,"Yang, Zhiyu and Zhou, Zihan and Wang, Shuo and Cong, Xin and Han, Xu and Yan, Yukun and Liu, Zhenghao and Tan, Zhixing and Liu, Pengyuan and Yu, Dong and Liu, Zhiyuan and Shi, Xiaodong and Sun, Maosong",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205323780&doi=10.18653%2Fv1%2F2024.findings-acl.701&partnerID=40&md5=7c3eb12300be93fde5164e7a87c7ef79,,,,"Scientific data visualization plays a crucial role in research by enabling the direct display of complex information and assisting researchers in identifying implicit patterns. Despite its importance, the use of Large Language Models (LLMs) for scientific data visualization remains rather unexplored. In this study, we introduce MatPlotAgent, an efficient model-agnostic LLM agent framework designed to automate scientific data visualization tasks. Leveraging the capabilities of both code LLMs and multi-modal LLMs, MatPlotAgent consists of three core modules: query understanding, code generation with iterative debugging, and a visual feedback mechanism for error correction. To address the lack of benchmarks in this field, we present MatPlotBench, a high-quality benchmark consisting of 100 human-verified test cases. Additionally, we introduce a scoring approach that utilizes GPT-4V for automatic evaluation. Experimental results demonstrate that MatPlotAgent can improve the performance of various LLMs, including both commercial and open-source models. Furthermore, the proposed evaluation method shows a strong correlation with human-annotated scores. © 2025 Elsevier B.V., All rights reserved.","Cited by: 6 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Visualização de Dados Científicos Agênticos Baseada em LLM""]}",10.18653/v1/2024.findings-acl.701,Benchmarking; Data visualization; Open source software; Program debugging; Structured Query Langu...,,,,,,,
rayyan-394626792,INJECAGENT: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents,2024,,,Proceedings of the Annual Meeting of the Association for Computational Linguistics,,,,10471 - 10506,"Zhan, Qiusi and Liang, Zhixiang and Ying, Zifan and Kang, Daniel D.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205291586&doi=10.18653%2Fv1%2F2024.findings-acl.624&partnerID=40&md5=99a292359dc3dbe9614bcfe732ffe0cf,,,,"Recent work has embodied LLMs as agents, allowing them to access tools, perform actions, and interact with external content (e.g., emails or websites). However, external content introduces the risk of indirect prompt injection (IPI) attacks, where malicious instructions are embedded within the content processed by LLMs, aiming to manipulate these agents into executing detrimental actions against users. Given the potentially severe consequences of such attacks, establishing benchmarks to assess and mitigate these risks is imperative. In this work, we introduce INJECAGENT, a benchmark designed to assess the vulnerability of tool-integrated LLM agents to IPI attacks. INJECAGENT comprises 1,054 test cases covering 17 different user tools and 62 attacker tools. We categorize attack intentions into two primary types: direct harm to users and exfiltration of private data. We evaluate 30 different LLM agents and show that agents are vulnerable to IPI attacks, with ReAct-prompted GPT-4 vulnerable to attacks 24% of the time. Further investigation into an enhanced setting, where the attacker instructions are reinforced with a hacking prompt, shows additional increases in success rates, nearly doubling the attack success rate on the ReAct-prompted GPT-4. Our findings raise questions about the widespread deployment of LLM Agents. Our benchmark is available at https://github.com/uiuc-kang-lab/InjecAgent. © 2025 Elsevier B.V., All rights reserved.","Cited by: 9 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.18653/v1/2024.findings-acl.624,Benchmarking; Access tools; Doublings; Exfiltration; Language model; Model agents; Private data; ...,,,,,,,
rayyan-394626793,"LangSuit·E: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments",2024,,,Proceedings of the Annual Meeting of the Association for Computational Linguistics,,,,14778 - 14814,"Jia, Zixia and Wang, Mengmeng and Tong, Baichen and Zhu, Songchun and Zheng, Zilong",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205282419&doi=10.18653%2Fv1%2F2024.findings-acl.879&partnerID=40&md5=2331fe1ab4d91248d447103efc051066,,,,"Recent advances in Large Language Models (LLMs) have shown inspiring achievements in constructing autonomous agents that rely on language descriptions as inputs. However, it remains unclear how well LLMs can function as few-shot or zero-shot embodied agents in dynamic interactive environments. To address this gap, we introduce LangSuit·E, a versatile and simulation-free testbed featuring 6 representative embodied tasks in textual embodied worlds. Compared with previous LLM-based testbeds, LangSuit·E (i) offers adaptability to diverse environments without multiple simulation engines, (ii) evaluates agents' capacity to develop “internalized world knowledge” with embodied observations, and (iii) allows easy customization of communication and action strategies. To address the embodiment challenge, we devise a novel chain-of-thought (CoT) schema, EmMem, which summarizes embodied states w.r.t. history information. Comprehensive benchmark results illustrate challenges and insights of embodied planning. LangSuit·E represents a significant step toward building embodied generalists in the context of language models. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.18653/v1/2024.findings-acl.879,Autonomous agents; Benchmarking; Computational linguistics; Computer simulation languages; Contex...,,,,,,,
rayyan-394626794,Leveraging large language models for automated knowledge graphs generation in non-destructive testing,2024,,,CEUR Workshop Proceedings,,3760,,101 - 110,"Zia, Ghezal Ahmad Jan and Valdestilhas, André and Torres, Benjamin Moreno and Kruschwitz, Sabine F.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204975994&partnerID=40&md5=3a0c5b49d90a7df3acf65d870ce8b225,,,,"This paper presents an innovative approach for the automatic generation of Knowledge Graphs (KGs) from heterogeneous scientific articles in the domain of Non-Destructive Testing (NDT) applied to building materials. Our methodology leverages large language models (LLMs) to extract and semantically relate concepts from diverse sources. We developed material-specific agents for concrete, wood, steel, and bricks, each equipped with a curated glossary of terms to ensure domain accuracy. These agents process PDF documents, extracting relevant information on deterioration mechanisms, physical changes, and applicable NDT methods. The extracted data is then normalized, validated, and structured into a Neo4j graph database, forming a comprehensive KG. Our results demonstrate the system's ability to automatically discover and represent intricate relationships between materials, deterioration mechanisms, physical changes, and NDT techniques. The generated KG successfully captures complex interactions, such as the applicability of specific NDT methods to various materials under different deterioration conditions. This work not only highlights the potential of KGs in enhancing knowledge discovery and representation in NDT research but also provides a scalable framework for extending this approach to other scientific domains. © 2024 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",,Automatic test pattern generation; Concrete testing; Deterioration; Metadata; Network security; S...,,,,,,,
rayyan-394626795,CODEAGENT: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges,2024,,,Proceedings of the Annual Meeting of the Association for Computational Linguistics,,1,,13643 - 13658,"Zhang, Kechi and Li, Jia and LI, Ge and Shi, Xianjie and Jin, Zhi",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204422336&doi=10.18653%2Fv1%2F2024.acl-long.737&partnerID=40&md5=99fd7c9dd58ad15390110ca57961ce7c,,,,"Large Language Models (LLMs) have shown promise in automated code generation but typically excel only in simpler tasks such as generating standalone code units. However, real-world software development often involves complex code repositories with complex dependencies and extensive documentation. To enable LLMs to handle these real-world repo-level code generation, we present CODEAGENT, a novel LLM-based agent framework that employs external tools for effective repo-level code generation. CODEAGENT integrates five programming tools, enabling interaction with software artifacts for information retrieval, code implementation, and code testing. We implement four agent strategies to optimize these tools' usage. To the best of our knowledge, CODEAGENT is the first agent framework specifically for repo-level code generation. In order to measure the effectiveness of our method at the repository level, we design a repo-level benchmark CODEAGENTBENCH. The performance on this benchmark shows a significant improvement brought by our method, with improvements in pass rate ranging from 2.0 to 15.8. Further tests on the HumanEval benchmark confirm CODEAGENT's adaptability and efficacy across various code generation tasks. Notably, CODEAGENT outperforms commercial products like GitHub Copilot, showcasing superior accuracy and efficiency. These results demonstrate CODEAGENT's robust capabilities in code generation, highlighting its potential for real-world repo-level coding challenges. © 2025 Elsevier B.V., All rights reserved.","Cited by: 3 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.18653/v1/2024.acl-long.737,Autonomous agents; Benchmarking; Computational linguistics; Intelligent agents; Search engines; S...,,,,,,,
rayyan-394626796,Towards LLM-Assisted System Testing for Microservices,2024,,,,,,,29 - 34,"Almutawa, Mustafa and Ghabrah, Qusai and Canini, Marco",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204295455&doi=10.1109%2FICDCSW63686.2024.00011&partnerID=40&md5=c288614757b12066e8a8ed4ab7ec145e,,,,"As modern applications are being designed in a distributed, Microservices Architecture (MSA), it becomes increasingly difficult to debug and test those systems. Typically, it is the role of software testing engineers or Quality Assurance (QA) engineers to write software tests to ensure the reliability of applications, but such a task can be labor-intensive and time-consuming. In this paper, we explore the potential of Large Language Models (LLMs) in assisting software engineers in generating test cases for software systems, with a particular focus on performing end-to-end (black-box) system testing on web-based MSA applications. We present our experience building Kashef, a software testing tool that utilizes the advanced capabilities of current LLMs in code generation and reasoning, and builds on top of the concept of communicative agents. © 2024 Elsevier B.V., All rights reserved.","Cited by: 2 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Secundário""]}",10.1109/ICDCSW63686.2024.00011,Ability testing; Autonomous agents; Black-box testing; Computer debugging; Computer software sele...,,,,,,,
rayyan-394626797,"Proceedings - 2024 IEEE Conference on Software Testing, Verification and Validation, ICST 2024",2024,,,,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203788997&partnerID=40&md5=bcf9c7d3bd0b5fb3f566006445b017bc,,,,"The proceedings contain 48 papers. The topics discussed include: enhanced fast and reliable statistical vulnerability root cause analysis with sanitizer; BugOut: automated test generation and bug detection for low-code; on the coupling between vulnerabilities and LLM-generated mutants: a study on Vul4J dataset; evolutionary testing for program repair; are we testing or being tested? exploring the practical applications of large language models in software testing; intent-driven mobile GUI testing with autonomous large language model agents; in industrial embedded software, are some compilation errors easier to localize and fix than others?; automatically reproducing timing-dependent flaky-test failures; 230,439 test failures later: an empirical evaluation of flaky failure classifiers; and adversarial testing with reinforcement learning: a case study on autonomous driving. © 2024 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626798,Intent-Driven Mobile GUI Testing with Autonomous Large Language Model Agents,2024,,,,,,,129 - 139,"Yoon, Juyeon and Feldt, Robert and Yoo, Shin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203242246&doi=10.1109%2FICST60714.2024.00020&partnerID=40&md5=da75e662900ea316debff970ce334a1b,,,,"GUI testing checks if a software system behaves as expected when users interact with its graphical interface, e.g., testing specific functionality or validating relevant use case scenarios. Currently, deciding what to test at this high level is a manual task since automated GUI testing tools target lower level adequacy metrics such as structural code coverage or activity coverage. We propose DroidAgent, an autonomous GUI testing agent for Android, for semantic, intent-driven automation of GUI testing. It is based on Large Language Models and support mechanisms such as long- and short-term memory. Given an Android app, DroidAgent sets relevant task goals and subsequently tries to achieve them by interacting with the app. Our empirical evaluation of DroidAgent using 15 apps from the Themis benchmark shows that it can set up and perform realistic tasks, with a higher level of autonomy. For example, when testing a messaging app, DroidAgent created a second account and added a first account as a friend, testing a realistic use case, without human intervention. On average, DroidAgent achieved 61% activity coverage, compared to 51 % for current state-of-the-art GUI testing techniques. Further, manual analysis shows that 317 out of the 547 autonomously created tasks are realistic and relevant to app functionalities, and also that DroidAgent interacts deeply with the apps and covers more features. © 2024 Elsevier B.V., All rights reserved.","Cited by: 14 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.1109/ICST60714.2024.00020,Autonomous agents; Benchmarking; Graphical user interfaces; High level languages; Mobile agents; ...,,,,,,,
rayyan-394626799,IDENTIFYING THE RISKS OF LM AGENTS WITH AN LM-EMULATED SANDBOX,2024,,,,,,,,"Ruan, Yangjun and Dong, Honghua and Wang, Andrew and Pitis, Silviu and Zhou, Yongchao and Ba, Jimmy Lei and Dubois, Yann and Maddison, Chris J. and Hashimoto, Tatsunori B.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200583637&partnerID=40&md5=1f21b7d4facf9a045ef6b63eb40d55f3,,,,"Recent advances in Language Model (LM) agents and tool use, exemplified by applications like ChatGPT Plugins, enable a rich set of capabilities but also amplify potential risks-such as leaking private data or causing financial losses. Identifying these risks is labor-intensive, necessitating implementing the tools, setting up the environment for each test scenario manually, and finding risky cases. As tools and agents become more complex, the high cost of testing these agents will make it increasingly difficult to find high-stakes, long-tail risks. To address these challenges, we introduce ToolEmu: a framework that uses an LM to emulate tool execution and enables scalable testing of LM agents against a diverse range of tools and scenarios. Alongside the emulator, we develop an LM-based automatic safety evaluator that examines agent failures and quantifies associated risks. We test both the tool emulator and evaluator through human evaluation and find that 68.8% of failures identified with ToolEmu would be valid real-world agent failures. Using our curated initial benchmark consisting of 36 high-stakes toolkits and 144 test cases, we provide a quantitative risk analysis of current LM agents and identify numerous failures with potentially severe outcomes. Notably, even the safest LM agent exhibits such failures 23.9% of the time according to our evaluator, underscoring the need to develop safer LM agents for real-world deployment. © 2025 Elsevier B.V., All rights reserved.","Cited by: 19 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",,Losses; Risk analysis; Risk assessment; Financial loss; Labour-intensive; Language model; Model a...,,,,,,,
rayyan-394626800,A Generative Adversarial Imitation Learning Method for Continuous Integration Testing,2024,,,,,,,1084 - 1089,"Huang, Luosen and Liu, Hengyuan and Liu, Yong and Shang, Ying and Li, Zheng",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199171129&doi=10.1109%2FAINIT61980.2024.10581812&partnerID=40&md5=8c4501d6057031be3cb889fffcbf208b,,,,"In Continuous Integration (CI), Test Case Prioritization (TCP) is crucial for the efficiency and effectiveness of the software testing. While Reinforcement Learning (RL) offers a promising approach for TCP, it struggles with the low failure rates of test cases in industrial CI environment, leading to sparse rewards and unstable learning efficiency. Furthermore, designing a proper reward function is challenging due to its dependency on the abstracted features of the test cases. To address these issues, we propose a Generative Adversarial Imitation Learning (GAIL) method for TCP, which allows agents to learn directly from the expert experience rather than through potentially biased reward functions. We use the Copeland method as a pairwise ranking strategy and train the agent using optimal rankings, considered as expert experience generated from previous CI cycles, leading to more stable and efficient learning. In addition, we introduce a new metric, the Average of the Percentage of Faults Detected based on Execution Time (APFDET), to evaluate the effectiveness of the proposed approach. Empirical studies are performed on six industrial datasets. The results show that GAIL has a better fault detection capability on TCP problems. © 2024 Elsevier B.V., All rights reserved.","Cited by: 2 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Test case ci""]}",10.1109/AINIT61980.2024.10581812,Efficiency; Failure analysis; Integration; Integration testing; Learning systems; Reinforcement l...,,,,,,,
rayyan-394626801,Routing optimization based on DRL and Generative Adversarial Networks for SDN environments,2024,,,,,,,,"Altamirano, Juan Chafla and Guitouni, Mariem and Hassan, Hassan and Drira, Khalil",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198373346&doi=10.1109%2FNOMS59830.2024.10575453&partnerID=40&md5=cd4e8dd73c65b3c9f05d8284b6996134,,,,"Traditional routing protocols and analytical routing optimization models face limitations in adapting to dynamic and complex environments such as SDN. Deep Reinforcement Learning (DRL) offers promise for addressing these challenges, but its intensive training phase hinders practical implementation. This paper presents a distributed DRL-based routing optimization solution in SDN, enhanced with Generative Adversarial Networks (GAN) to expedite agent training. Our approach, evaluated on a Containernet and OpenAI Gym-based testbed, effectively optimizes network traffic routes for diverse traffic classes, maximizing throughput. Activation of the GAN module significantly reduces training times, enhancing the feasibility of our solution for real-world deployment. © 2024 Elsevier B.V., All rights reserved.","Cited by: 3; All Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1109/NOMS59830.2024.10575453,Deep learning; Generative adversarial networks; Network routing; Complex environments; Deep reinf...,,,,,,,
rayyan-394626802,ChatDev: Communicative Agents for Software Development,2024,,,Proceedings of the Annual Meeting of the Association for Computational Linguistics,,1,,15174 - 15186,"Qian, Chen and Liu, Wei and Liu, Hongzhang and Chen, Nuo and Dang, Yufan and Li, Jiahao and Yang, Cheng and Chen, Weize and Su, Yusheng and Cong, Xin and Xu, Juyuan and Li, Dahai and Liu, Zhiyuan and Sun, Maosong",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197091676&doi=10.18653%2Fv1%2F2024.acl-long.810&partnerID=40&md5=c71c0c92f0115ee34a983a62e5d9a761,,,,"Software development is a complex task that necessitates cooperation among multiple members with diverse skills. Numerous studies used deep learning to improve specific phases in a waterfall model, such as design, coding, and testing. However, the deep learning model in each phase requires unique designs, leading to technical inconsistencies across various phases, which results in a fragmented and ineffective development process. In this paper, we introduce ChatDev, a chat-powered software development framework in which specialized agents driven by large language models (LLMs) are guided in what to communicate (via chat chain) and how to communicate (via communicative dehallucination). These agents actively contribute to the design, coding, and testing phases through unified language-based communication, with solutions derived from their multi-turn dialogues. We found their utilization of natural language is advantageous for system design, and communicating in programming language proves helpful in debugging. This paradigm demonstrates how linguistic communication facilitates multi-agent collaboration, establishing language as a unifying bridge for autonomous task-solving among LLM agents. The code and data are available at https://github.com/OpenBMB/ChatDev. © 2025 Elsevier B.V., All rights reserved.","Cited by: 75 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",10.18653/v1/2024.acl-long.810,Autonomous agents; Computational linguistics; Computer debugging; Program debugging; Software des...,,,,,,,
rayyan-394626803,ZEUS 2024 - Proceedings of the 16th ZEUS Workshop on Sercices and their Composition,2024,,,CEUR Workshop Proceedings,,3673,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191986661&partnerID=40&md5=9b912cc17e88720c12ddd8bf703706f2,,,,"The proceedings contain 10 papers. The topics discussed include: towards process mining on Kafka event streams; towards the usage of object-aware process variants in multiple autonomous organizations; simulating event logs from object lifecycle processes; Clounaq - cloud-native architectural quality; how good are you? an empirical classification performance comparison of large language models with traditional open set recognition classifiers; a BPMN profile for test case execution visualization; towards robustness of IoT devices in BPMNE4IoT; predictive process monitoring: an implementation and comparison of student performance prediction; a literature review on reproducibility studies in computer science; and user-agent as a cyber intrusion artifact: detection of APT activity using minimal anomalies on the user-agent string traffic. © 2024 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626804,A dynamic test scenario generation method for autonomous vehicles based on conditional generative adversarial imitation learning,2024,,,Accident Analysis and Prevention,,194,,,"Jia, Lulu and Yang, Dezhen and Ren, Yi and Qian, Cheng and Feng, Qiang and Sun, Bo and Wang, Zili",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174922934&doi=10.1016%2Fj.aap.2023.107279&partnerID=40&md5=6a4dccd093a016fce4d01698b76b8778,,,,"Autonomous vehicles must be comprehensively evaluated before deployed in cities and highways. However, most existing evaluation approaches for autonomous vehicles are static and model environmental vehicles with predefined trajectories, which ignore the time-sequential interactions between the ego vehicle and environmental vehicles. In this paper, we propose a dynamic test scenario generation method to evaluate autonomous vehicles by modeling environmental vehicles as agents with human behavior and simulating the interaction process between the autonomous vehicle and environmental vehicles. Considering the multimodal features of traffic scenarios, we cluster the real-word traffic environments, and integrate the scenario class labels into the conditional generative adversarial imitation learning (CGAIL) model to generate different types of traffic scenarios. The proposed method is validated in a typical lane-change scenario that involves frequent interactions between ego vehicle and environmental vehicles. Results show that the proposed method further test autonomous vehicles’ ability to cope with dynamic scenarios, and can be used to infer the weaknesses of the tested vehicles. © 2023 Elsevier B.V., All rights reserved.","Cited by: 18 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.1016/j.aap.2023.107279,Behavioral research; Learning systems; Autonomous Vehicles; Conditional generative adversarial im...;Traffic; Automobile Driving; Humans; Imitative Behavior,,,,,,,
rayyan-394626805,Cloud-Based System for Source Code Analysis of Microservices with LLM Agents,2024,,,International Scientific and Technical Conference on Computer Sciences and Information Technologies,,,,,"Chaplia, Oleh and Klym, Halyna I.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005826698&doi=10.1109%2FCSIT65290.2024.10982613&partnerID=40&md5=aa79d5bead960eeab495f82530874986,,,,"This paper presents a cloud-based system for microservice code analysis that utilizes LLM agents as a foundation. The system is designed to receive the code updates, analyze the code, and provide results to the user. Users can obtain information about the microservice, code summaries, code reviews, reliability checks, and improvement recommendations. The history of changes allows for tracking the evolution of microservices and identifying the issues when they appear. The prototype of the proposed system was implemented and tested. The results show the systems' usability and provide valuable insights. This research underscores the potential of combining LLM agents with cloud technologies, offering a scalable microservice solution that paves the way for future innovations in automated code analysis and software engineering. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Test for microservices""]}",10.1109/CSIT65290.2024.10982613,Computer operating systems; Computer software maintenance; Software design; Software prototyping;...,,,,,,,
rayyan-394626806,"Architecting Enterprise AI Applications: A Guide to Designing Reliable, Scalable, and Secure Enterprise-Grade AI Solutions",2024,,,,,,,1 - 286,"Cagle, Anton and Ahmed, Ahmed Ceifelnasr",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004114634&doi=10.1007%2F979-8-8688-0902-6&partnerID=40&md5=20f51584b6e39fef625251f05c36a938,,,,"This book explores how to define, design, and maintain enterprise AI applications, exploring the impacts they will have on the teams who work with them. The book is structured into four parts. In Part 1: Defining Your AI Application, you are introduced to the dynamic interplay between human adaptability and AI specialization, the concept of meta systems, and the mechanics of prediction machines. In Part 2: Designing Your AI Application, the book delves into the anatomy of an AI application, unraveling the intricate relationships among data, machine learning, and reasoners. This section introduces the building blocks and enterprise architectural framework for designing multi-agent systems. Part 3: Maintaining Your AI Application takes a closer look at the ongoing life cycle of AI systems. You are guided through the crucial aspects of testing and test automation, providing a solid foundation for effective development practices. This section covers the critical tasks of security and information curation that ensure the long-term success of enterprise AI applications. The concluding section, Part 4: AI Enabled Teams, navigates the evolving landscape of collaborative efforts between humans and AI. It explores the impact of AI on remote work dynamics and introduces the new roles of the expert persona and the AI handler. This section concludes with a deep dive into the legal and ethical dimensions that AI-enabled teams must navigate. This book is a comprehensive guide that not only equips developers, architects, and product owners with the technical know-how of AI application development, but also delves into the broader implications for teams and society. What You Will Learn Understand the algorithms and processes that enable AI to make accurate predictions and enhance decision making Grasp the concept of metasystems and their role in the design phase of AI applications Know how data, machine learning, and reasoners drive the functionality and decision-making capabilities of AI applications Know the architectural components necessary for scalable and maintainable multi-agent AI applications Understand methodologies for testing AI applications, ensuring their robustness, accuracy, and reliability in real-world applications Understand the evolving dynamics of human-AI coordination facing teams in the new enterprise working environment Who This book Is For A diverse audience, primarily targeting enterprise architects, middle managers, tech leads, and team leads entrenched in the IT sector or possessing a tech-savvy background, including professionals such as digital marketers. Additionally, tech-savvy individual contributors—ranging from digital content creators and data analysts to administrators and programmers—stand to benefit significantly. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1007/979-8-8688-0902-6,Ethical aspects; Veneers; AI applications; AI architecture; AI observability; AI safety; AWS bedr...,,,,,,,
rayyan-394626807,CRALA: A Chinese-centric Risk Simulation and Assessment Framework for LLM Agents,2024,,,,,,,561 - 566,"Ye, Wenyou and Zhang, Zengqi and Li, Wuyang and Qin, Yifeng and Zhang, Peng",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002236687&doi=10.1109%2FAIIM64537.2024.10934441&partnerID=40&md5=2974d996341dd3a70a3f72414f6132b3,,,,"In recent years, large language models (LLMs) become more and more powerful. They can do many interesting tasks, like connecting to different external tools-sometimes we call them “plugins”-to help handle real things in the world. But at the same time, giving LLM agents more real-world power also creates a lot of risks we must be careful about. Checking these risks is not easy at all. It can cost lots of time and energy because we have to make special plugins and do complicated tests just to see if the model might do something unsafe. Most of the “serious” security checks, like the ones done on GPT-4, focus mostly on English. In Chinese, we know very little about the dangers with existing research. Many research pays attention to English, but not so much to Chinese cases, even though it’s super important. To fix this problem, we made a new framework called CRALA (Chinese-centric Risk Assessment for LLM Agents). It can simulate many situations in Chinese and then carefully check if there are any safety issues hiding inside these LLM agent tasks. CRALA includes two main parts: a Chinese Interaction Simulator, which creates and records pretend conversations, and an Evaluator, which looks at all these interactions and decides if interaction might be unsafe. We tested CRALA with human reviewers on 55 different Chinese scenarios. The results show that about 81.5% collected test cases are realistic. When the CRALA flags a case as dangerous, about 63.5% really were problems. We even tested 100 risky cases in Chinese apps with popular LLMs like GPT-4. GPT-4 only handled around 35% of them safely. This shows that we still have a long way to go before we can trust these agents completely, at least in Chinese contexts. In conclusion, CRALA makes checking these risks much less painful and gives us a better understanding of how safe Chinese LLM agents really are. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/AIIM64537.2024.10934441,Application programming interfaces (API); Autonomous agents; Computer system recovery; Digital el...,,,,,,,
rayyan-394626808,AI-Powered Multi-Agent Framework for Automated Unit Test Case Generation: Enhancing Software Quality through LLM's,2024,,,,,,,,"Garlapati, Anusha and Parmesh, M. N.V.Satya Sai Muni and Savitha, null and Jaisri, S.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002210499&doi=10.1109%2FGCAT62922.2024.10923987&partnerID=40&md5=5ab5972bdb1effde4abdc467aec1d3bb,,,,"Recent years have witnessed an enormous rise in the design, repair and the enhancement of software automation tests. The reliability of program's unit testing has major impact on its overall performance. The anticipated influence of Artificial Intelligence advancements on test automation methodologies are significant. Many studies on automated testing implicitly assume that the test results are deterministic, means that similar tests faults remain same. The precision of software is largely ensured by unit testing. But writing unit tests manually is a time-consuming process, which leads us to drive into ""Automation Analysis"". Recent years comprised the application of Large Language Models (LLM's) in numerous fields related to software development, especially the automated creation of unit testing.However, these frameworks require more instructions, or few shot learnings on sample tests that already exist. This research provides a comprehensive empirical assessment of the efficiency of LLM's for automating unit testing production, with no need for further manual analysis. The method we employ is put into practice for test cases, an adaptable Agents and LLM-based testing framework that evaluates test cases generated, by reviewing and re-writing them in different phases. Evaluation of this test cases was done by using mistral-large LLM Model. The analysis results that developed acquired an overall coverage of 100% for code given. Finally, to enhance the typical evaluation, this research suggests and concludes that LLMs, can be successfully incorporated into present practices, through adaptative instructions and improvements. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Estudo empirico llm test""]}",10.1109/GCAT62922.2024.10923987,Application programs; Automatic test pattern generation; Computer software selection and evaluati...,,,,,,,
rayyan-394626810,"21st International Conference on Informatics in Control, Automation and Robotics, ICINCO 2024",2024,,,"Proceedings of the International Conference on Informatics in Control, Automation and Robotics",,1,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001400727&partnerID=40&md5=27dc2169eb8b0e9dd9d4204e0010c7a1,,,,"The proceedings contain 129 papers. The special focus in this conference is on Informatics in Control, Automation and Robotics. The topics include: Comparison of Lateral Controllers for Autonomous Vehicles Based on Passenger Comfort Optimization; domain-Decoupled Physics-informed Neural Networks with Closed-Form Gradients for Fast Model Learning of Dynamical Systems; Solving Multi-Agent Pathfinding with Stochastic Local Search SAT Algorithms; Model-Free versus Model-Based Reinforcement Learning for Fixed-Wing UAV Attitude Control Under Varying Wind Conditions; implementation of 12 Transition Controls for Rotary Double Inverted Pendulum Using Direct Collocation; automatic Placement of Digital Signals in Railway Digitalization: A Constraint Approach; a Hybrid Constraint- and Search-Based Approach on the Stockyard Planning Problem; data-Driven Predictive Maintenance for Component Life-Cycle Extension; multi-Risk Assessment and Management in the Presence of Personal Light Electric Vehicles; potato Leaf Disease Detection Approach Based on Transfer Learning with Spatial Attention; modelling and Simulation of an Autonomous Pod-Tethered Quadcopter Drone System for Aviation Applications; A Comparison of Adaptive PID, Adaptive Dual-PID and Adaptive Fractional PID Controllers for a Nonlinear System with Variable Parameters; sliding Mode Control for Inverse Response Systems: A Trajectory Tracking Study; a New Observer-Based Fault Tolerant Shared Control for SbW Systems with Actuator Fault for Driver Assistance; a Neural Network-Based Controller Towards Achieving Near-Natural Gait in Transfemoral Amputees; Two-Stage Fault Detection and Control Approach for DFIG-Based Wind Energy Conversion System; H<inf>∞</inf> Type Control of Periodic Stochastic Systems Subject to Multiplicative White Noises: Application to Satellite AOCS Design; optimizing Small-Scale Surgery Scheduling with Large Language Model; reinforcement Learning for Autonomous Headland Turns. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626811,RTL Agent: An Agent-Based Approach for Functionally Correct HDL Generation via LLMs,2024,,,Proceedings of the Asian Test Symposium,,,,,"Ranga, Sriram and Mao, Rui and Bhattacharjee, Debjyoti and Cambria, Erik and Chattopadhyay, Anupam",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001149854&doi=10.1109%2FATS64447.2024.10915277&partnerID=40&md5=5d2351bc53185a63b8fbff920e4434bb,,,,"LLMs as code generators have undergone rapid progress over the past couple of years. However, the models on their own provide no guarantees for the functional correctness of the generated code. Functional tests can not only be used by designers to assess the functional correctness of code, but also to guide them towards the solution of the problem. The same can be applied to LLMs performing automatic code generation through the use of the Reflexion technique. Reflexion is an agent-based workflow where the model generating code iterates over a loop of code generation, getting feedback from the test bench, reflecting on the feedback, and making appropriate changes to the code. The technique is known to drastically improve the performance of LLMs on software code generation. In this work, we adopt the technique for hardware description language (HDL) code generation as RTL Agent - an implementation of the workflow for Verilog generation with Reflexion. We compare multiple LLMs with standard inference vs with Reflexion on the VerilogEval benchmark. Within 5 iterations of the feedback loop, we observe a relative improvement of 33.2% for the low-performance model Llama3 and an average of 17.7% for the high-performance models GPT-4o and GPT-4o-mini in their Pass@1 performance. We present a cost analysis of the technique to enable cost-performance trade-offs. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC6",10.1109/ATS64447.2024.10915277,Automatic programming; Autonomous agents; Benchmarking; Problem oriented languages; Software test...,,,,,,,
rayyan-394626812,Enhancing User Story Generation in Agile Software Development Through Open AI and Prompt Engineering,2024,,,"Proceedings - Frontiers in Education Conference, FIE",,,,,"Ramasamy, Vijayalakshmi and Ramamoorthy, Suganya and Walia, Gursimran Singh and Kulpinski, Eli and Antreassian, Aaron",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000807589&doi=10.1109%2FFIE61694.2024.10893343&partnerID=40&md5=00b4e824a4353767442b7ddb4c19fc19,,,,"This innovative practice full paper explores the use of AI technologies in user story generation. With the emergence of agile software development, generating comprehensive user stories that capture all necessary functionalities and perspectives has become crucial for software development. Every computing program in the United States requires a semester-or year-long senior capstone project, which requires student teams to gather and document technical requirements. Effective user story generation is crucial for successfully implementing software projects. However, user stories written in natural language can be prone to inherent defects such as incompleteness and incorrectness, which may creep in during the downstream development activities like software designs, construction, and testing. One of the challenges faced by software engineering educators is to teach students how to elicit and document requirements, which serve as a blueprint for software development. Advanced AI technologies have increased the popularity of large language models (LLMs) trained on large multimodal datasets. Therefore, utilizing LLM-based techniques can assist educators in helping students discover aspects of user stories that may have been overlooked or missed during the manual analysis of requirements from various stakeholders. The main goal of this research study is to investigate the potential application of OpenAI techniques in software development courses at two academic institutions to enhance software design and development processes, aiming to improve innovation and efficiency in team project-based educational settings. The data used for the study constitute student teams generating user stories by traditional methods (control) vs. student teams using OpenAI agents (treatment) such as gpt-4-turbo for generating user stories. The overarching research questions include: RQ-l) What aspects of user stories generated using OpenAI prompt engineering differ significantly from those generated using the traditional method? RQ-2) Can the prompt engineering data provide insights into the efficacy of the questions/prompts that affect the quality and comprehensiveness of user stories created by software development teams? Industry experts evaluated the user stories created and analyzed how prompt engineering affects the overall effectiveness and innovation of user story creation, which provided guidelines for incorporating AI-driven approaches into software development practices. Overall, this research seeks to contribute to the growing body of knowledge on the application of AI in software engineering education, specifically in user story generation. Investigating the use of AI technologies in user story generation could further enhance the usability of prompt engineering in agile software development environments. We plan to expand the study to investigate the long-term effects of prompt engineering on all phases of software development. © 2025 Elsevier B.V., All rights reserved.","Cited by: 1 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/FIE61694.2024.10893343,Application programs; Behavioral research; Computer software selection and evaluation; Creep test...,,,,,,,
rayyan-394626813,SWT-Bench: Testing and Validating Real-World Bug-Fixes with Code Agents,2024,,,Advances in Neural Information Processing Systems,,37,,,"Mündler, Niels and Müller, Mark Niklas and He, Jingxuan and Vechev, Martin T.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000529637&partnerID=40&md5=64830080c1fd8ab3a15e5f855dd9811b,,,,"Rigorous software testing is crucial for developing and maintaining high-quality code, making automated test generation a promising avenue for both improving software quality and boosting the effectiveness of code generation methods. However, while code generation with Large Language Models (LLMs) is an extraordinarily active research area, test generation remains relatively unexplored. We address this gap and investigate the capability of LLM-based Code Agents to formalize user issues into test cases. To this end, we propose a novel benchmark based on popular GitHub repositories, containing real-world issues, ground-truth bug-fixes, and golden tests. We find that LLMs generally perform surprisingly well at generating relevant test cases, with Code Agents designed for code repair exceeding the performance of systems designed specifically for test generation. Further, as test generation is a similar but more structured task than code generation, it allows for a more fine-grained analysis using issue reproduction rate and coverage changes, providing a dual metric for analyzing systems designed for code repair. Finally, we find that generated tests are an effective filter for proposed code fixes, doubling the precision of SWE-AGENT. We release all data and code at github.com/logic-star-ai/SWT-Bench. © 2025 Elsevier B.V., All rights reserved.","Cited by: 2 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""}",,,,,,,,,
rayyan-394626814,AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents,2024,,,Advances in Neural Information Processing Systems,,37,,,"Debenedetti, Edoardo and Zhang, Jie and Balunović, Mislav and Beurer-Kellner, Luca and Fischer, Marc and Tramèr, Florian",https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000481564&partnerID=40&md5=4709b92f3c97e097413eb0c1ca4a1cfa,,,,"AI agents aim to solve complex tasks by combining text-based reasoning with external tool calls. Unfortunately, AI agents are vulnerable to prompt injection attacks where data returned by external tools hijacks the agent to execute malicious tasks. To measure the adversarial robustness of AI agents, we introduce AgentDojo, an evaluation framework for agents that execute tools over untrusted data. To capture the evolving nature of attacks and defenses, AgentDojo is not a static test suite, but rather an extensible environment for designing and evaluating new agent tasks, defenses, and adaptive attacks. We populate the environment with 97 realistic tasks (e.g., managing an email client, navigating an e-banking website, or making travel bookings), 629 security test cases, and various attack and defense paradigms from the literature. We find that AgentDojo poses a challenge for both attacks and defenses: state-of-the-art LLMs fail at many tasks (even in the absence of attacks), and existing prompt injection attacks break some security properties but not all. We hope that AgentDojo can foster research on new design principles for AI agents that solve common tasks in a reliable and robust manner. © 2025 Elsevier B.V., All rights reserved.","Cited by: 2 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",,,,,,,,,
rayyan-394626815,Intelligent fault diagnosis of bearings under small samples: A mechanism-data fusion approach,2023,,,Engineering Applications of Artificial Intelligence,,126,,,"Xu, Kun and Kong, Xianguang and Wang, Qibin and Han, Bing and Sun, Liqiang",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170043647&doi=10.1016%2Fj.engappai.2023.107063&partnerID=40&md5=5d6ceb0799b09a19e9a0edc011bc1182,,,,"In recent years, deep learning has been extensively applied to bearing fault diagnosis with remarkable achievements. However, in real industrial scenarios, the primary challenge in developing an effective intelligent diagnosis model is the scarcity of fault samples required for training due to shutting down operations during failure behavior. Simulation data-driven and data augmentation-based small sample diagnosis methods have their own limitations, including insufficient diagnostic performance and low data quality. In view of these, a novel mechanism-data fusion diagnosis scheme with bearing dynamic model and multi-agent diverse generative adversarial network (MAD-GAN) is proposed in this study. Specifically, the bearing dynamic model addresses the scarcity of failure samples by simulating vibration signals across various operating conditions. Besides, A simulation-real transformation model based on MAD-GAN is developed to achieve the conversion between simulated domain and real domain, which shares the diagnostic knowledge between two domains. Finally, the domain adversarial based comprehensive generalization network is improved by maximum mean discrepancy and metric learning to further generalize diagnosis knowledge from simulation domain to real domain. Two bearing experimental datasets are applicated and case studies are conducted under small sample, validating the effectiveness and superiority of the proposed method. Experimental results show the potential application of this method in real industrial scenarios. © 2023 Elsevier B.V., All rights reserved.","Cited by: 47 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1016/j.engappai.2023.107063,Bearings (machine parts); Data fusion; Deep learning; Dynamic models; Dynamics; Failure analysis;...,,,,,,,
rayyan-394626816,Fine Motor Skills: Operating standard robotic fabrication as a generative system,2023,,,Proceedings of the ACM on Computer Graphics and Interactive Techniques,,6,2,,"Elran, Sharan R. and Harel, Yuval and Zoran, Amit Raphael",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168804922&doi=10.1145%2F3597627&partnerID=40&md5=cb82b90c7e4cdbcee35407947303247c,,,,"Our concept of a digital spirit refers to the agency of technology in the creative process and the potential to use it as an autonomous agent that both influences and participates in the artistic process. By attributing a digital spirit, we are able to have a more collaborative and interactive relationship with technology, where the role of the artist is to guide and direct the design rather than fully control it. In this work, we extend the autonomy of this spirit to allow the machine and the material to interact freely and generate forms independently from our will. In this new approach to digital fabrication, we transform a deterministic mechanical procedure into a creative exploration. Rather than designing traditional machine operations, we propose machine-material operations tailored for a specific material context. As a test case, we show a digital agent that manipulates clay while allowing the material's internal dynamics to play a dominant role in the finalization of the design. Through this machine-material interaction, we are able to generate an abundance of forms and complexity that would be impossible to create by hand or through traditional programming. It exposes an untapped expressive potential of digital tools that is made possible by operating digital machines outside the paradigm of tight control. © 2023 Elsevier B.V., All rights reserved.","Cited by: 3; All Open Access; Bronze Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1145/3597627,Autonomous agents; Digital devices; Artistic process; Ceramic; Creative process; Digital craft; F...,,,,,,,
rayyan-394626817,Safety Issues in Conversational Systems,2023,,,,,,,950 - 951,"Kim, Jinhwa",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173624739&doi=10.1145%2F3600211.3604748&partnerID=40&md5=020d543b3e0617611ed07fb09cf7cc71,,,,"This paper addresses two critical safety issues in conversational systems and methods to mitigate these problems. In section 1, I will discuss the problems faced by online conversational systems due to the actions of malicious users. It will particularly focus on the cyberpredator problem, which often targets vulnerable individuals, especially young children. In this section, I will review existing models to detect such predators, including my previous work, and present the results. In section 2, I will discuss safety issues related to conversational agents based on the Large Language Models. I highlight the limitations of existing works in assessing the safety of the models and propose a research topic that I plan to undertake to address them. © 2023 Elsevier B.V., All rights reserved.","Cited by: 3 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3 | USER-NOTES: {""Nicolas""=>[""Cyberpredadores conversasao com llm""]}",10.1145/3600211.3604748,Automatic testing; Online systems; Agent based; Conversational agents; Conversational systems; La...,,,,,,,
rayyan-394626818,"Few-Shot Learning-Based, Long-Term Stable, Sensitive Chemosensor for On-Site Colorimetric Detection of Cr(VI)",2023,,,Analytical Chemistry,,95,14,6156 - 6162,"Huang, Zhaojing and Li, Hao and Luo, Jiayi and Li, Shunxing and Liu, Fengjiao",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151506414&doi=10.1021%2Facs.analchem.3c00604&partnerID=40&md5=ad73fab447b5dcb460ba18aff59f5aed,,,,"The rapid emergence of deep learning, e.g., deep convolutional neural networks (DCNNs) as one-click image analysis with super-resolution, has already revolutionized colorimetric determination. But it is severely limited by its data-hungry nature, which is overcome by combining the generative adversarial network (GAN), i.e., few-shot learning (FSL). Using the same amount of real sample data, i.e., 414 and 447 samples as training and test sets, respectively, the accuracy could be increased from 51.26 to 85.00% because 13,500 antagonistic samples are created and used by GAN as the training set. Meanwhile, the generated image quality with GAN is better than that with the commonly used convolution self-encoder method. The simple and rapid on-site determination of Cr(VI) with 1,5-diphenylcarbazide (DPC)-based test paper is a favorite for environment monitoring but is limited by unstable DPC, poor sensitivity, and narrow linear range. The chromogenic agent of DPC is protected by the blending of polyacrylonitrile (PAN) and then loaded onto thin chromatographic silica gel (SG) as a Cr(VI) colorimetric sensor (DPC/PAN/SG); its stability could be prolonged from 18 h to more than 30 days, and its repeatable reproducibility is realized via facile electrospinning. By replacing the traditional Ed method with DCNN, the detection limit is greatly improved from 1.571 mg/L to 50.00 μg/L, and the detection range is prolonged from 1.571-8.000 to 0.0500-20.00 mg/L. The complete test time is shortened to 3 min. Even without time-consuming and easily stained enrichment processing, its detection limit of Cr(VI) in the drinking water can meet on-site detection requirements by USEPA, WHO, and China. © 2023 Elsevier B.V., All rights reserved.","Cited by: 20 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1021/acs.analchem.3c00604,Chromium compounds; Color; Colorimetry; Convolution; Deep neural networks; Potable water; Silica ...,,,,,,,
rayyan-394626819,"Proceedings - 15th Search-Based Software Testing Workshop, SBST 2022",2023,,,,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135152890&partnerID=40&md5=4c7678c669199b2d462ea3f270061134,,,,"The proceedings contain 15 papers. The topics discussed include: Wasserstein generative adversarial networks for online test generation for cyber physical systems; a comparative evaluation on the quality of manual and automatic test case generation techniques for scientific software - a case study of a python project for material science workflows; towards run-time search for real-world multi-agent systems; learning to rank for test case prioritization; basic block coverage for unit test generation at the SBST 2022 tool competition; SBST tool competition 2022; EvoSuite at the SBST 2022 tool competition; and Kex at the 2022 SBST tool competition. © 2025 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626820,Meet C4SE: Your New Collaborator for Software Engineering Tasks,2023,,,,,,,235 - 238,"De Vito, Gabriele and Lambiase, Stefano and Palomba, Fabio and Ferrucci, Filomena",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183322950&doi=10.1109%2FSEAA60479.2023.00044&partnerID=40&md5=ade60021c71ddbad55702599f7a6f037,,,,"The software industry's complexity and scale have increased rapidly, leading to challenges in managing information and tasks among developer teams, often resulting in inefficiencies, misunderstandings, and delays. The extensive search for automated tasks led to using chatbots - conversational agents - in software development. However, despite their positive contributions, their adoption has numerous issues, notably the lack of full working context, making their support sometimes useless. To address such a limitation, we propose C4SE, a chatbot designed to assist software engineers and managers in performing various tasks by gathering information helpful for better support. We use the GPT 3.5 model, and a specialized data store based on a vector database for long-term memory, to understand users' intentions and maintain contextual information. Our prototype C4SE can perform code suggestions, reviews, GitHub API operations, and generate unit and acceptance test cases. Preliminary evaluation reports encouraging results, showing potential to increase productivity in the software development lifecycle. © 2024 Elsevier B.V., All rights reserved.","Cited by: 7 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Chatbot""]}",10.1109/SEAA60479.2023.00044,Life cycle; Software agents; Software design; Automated tasks; Chatbots; Conversational agents; D...,,,,,,,
rayyan-394626821,Generative Model-Based Testing on Decision-Making Policies,2023,,,,,,,243 - 254,"Li, Zhuo and Wu, Xiongfei and Zhu, Derui and Cheng, Mingfei and Chen, Siyuan and Zhang, Fuyuan and Xie, Xiaofei and Ma, Lei and Zhao, Jianjun",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179007823&doi=10.1109%2FASE56229.2023.00153&partnerID=40&md5=673a5b4aaf49be50f5502763a11c869f,,,,"The reliability of decision-making policies is urgently important today as they have established the fundamentals of many critical applications, such as autonomous driving and robotics. To ensure reliability, there have been a number of research efforts on testing decision-making policies that solve Markov decision processes (MDPs). However, due to the deep neural network (DNN)-based inherit and infinite state space, developing scalable and effective testing frameworks for decision-making policies still remains open and challenging. In this paper, we present an effective testing framework for decision-making policies. The framework adopts a generative diffusion model-based test case generator that can easily adapt to different search spaces, ensuring the practicality and validity of test cases. Then, we propose a termination state novelty-based guidance to diversify agent behaviors and improve the test effectiveness. Finally, we evaluate the framework on five widely used benchmarks, including autonomous driving, aircraft collision avoidance, and gaming scenarios. The results demonstrate that our approach identifies more diverse and influential failure-triggering test cases compared to current state-of-the-art techniques. Moreover, we employ the detected failure cases to repair the evaluated models, achieving better robustness enhancement compared to the baseline method. © 2023 Elsevier B.V., All rights reserved.","Cited by: 14 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/ASE56229.2023.00153,Aircraft accidents; Autonomous vehicles; Behavioral research; Deep neural networks; Markov proces...,,,,,,,
rayyan-394626822,Towards Autonomous Testing Agents via Conversational Large Language Models,2023,,,,,,,1688 - 1693,"Feldt, Robert and Kang, Sungmin and Yoon, Juyeon and Yoo, Shin",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179005153&doi=10.1109%2FASE56229.2023.00148&partnerID=40&md5=a280bae3f3cc3d999608c16f706082cd,,,,"Software testing is an important part of the development cycle, yet it requires specialized expertise and substantial developer effort to adequately test software. Recent discoveries of the capabilities of large language models (LLMs) suggest that they can be used as automated testing assistants, and thus provide helpful information and even drive the testing process. To highlight the potential of this technology, we present a taxonomy of LLM-based testing agents based on their level of autonomy, and describe how a greater level of autonomy can benefit developers in practice. An example use of LLMs as a testing assistant is provided to demonstrate how a conversational framework for testing can help developers. This also highlights how the often criticized 'hallucination' of LLMs can be beneficial for testing. We identify other tangible benefits that LLM-driven testing agents can bestow, and also discuss potential limitations. © 2023 Elsevier B.V., All rights reserved.","Cited by: 19 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | USER-NOTES: {""Nicolas""=>[""Taxonomia llm tests""]}",10.1109/ASE56229.2023.00148,Autonomous agents; Computational linguistics; Learning systems; Machine learning; Artificial inte...;test automation; Development cycle; Intelligence tests; Language model; Large language model; Lev...,,,,,,,
rayyan-394626823,ChatGPT and Software Testing Education: Promises & Perils,2023,,,,,,,430 - 437,"Jalil, Sajed and Rafi, Suzzana and LaToza, Thomas D. and Moran, Kevin and Lam, Wing",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163136873&doi=10.1109%2FICSTW58534.2023.00078&partnerID=40&md5=203768452df569a75922306c1755317f,,,,"Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the ad-vent of general purpose ""large language models"", based on neural transformer architectures, that have been trained on massive datasets of human written text, which includes code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users.The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum. We found that given its current capabilities, ChatGPT is able to respond to 77.5% of the questions we examined and that, of these questions, it is able to provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct answers and explanations. Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors. © 2023 Elsevier B.V., All rights reserved.","Cited by: 171 | RAYYAN-INCLUSION: {""Nicolas""=>""Included""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.1109/ICSTW58534.2023.00078,Codes (symbols); Computational linguistics; Curricula; Education computing; Large dataset; Modeli...,,,,,,,
rayyan-394626824,Generative Personas That Behave and Experience Like Humans,2022,,,ACM International Conference Proceeding Series,,,,,"Barthet, Matthew and Khalifa, Ahmed and Liapis, Antonios and Yannakakis, Georgios N.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137212529&doi=10.1145%2F3555858.3555879&partnerID=40&md5=6e37f9191fa4fd3026ae7e29730d001b,,,,"Using artificial intelligence (AI) to automatically test a game remains a critical challenge for the development of richer and more complex game worlds and for the advancement of AI at large. One of the most promising methods for achieving that long-standing goal is the use of generative AI agents, namely procedural personas, that attempt to imitate particular playing behaviors which are represented as rules, rewards, or human demonstrations. All research efforts for building those generative agents, however, have focused solely on playing behavior which is arguably a narrow perspective of what a player actually does in a game. Motivated by this gap in the existing state of the art, in this paper we extend the notion of behavioral procedural personas to cater for player experience, thus examining generative agents that can both behave and experience their game as humans would. For that purpose, we employ the Go-Explore reinforcement learning paradigm for training human-like procedural personas, and we test our method on behavior and experience demonstrations of more than 100 players of a racing game. Our findings suggest that the generated agents exhibit distinctive play styles and experience responses of the human personas they were designed to imitate. Importantly, it also appears that experience, which is tied to playing behavior, can be a highly informative driver for better behavioral exploration. © 2022 Elsevier B.V., All rights reserved.","Cited by: 15; All Open Access; Green Accepted Open Access; Green Final Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1145/3555858.3555879,Computer games; Affective Computing; Artificial intelligence agent; Automatically test; Critical ...,,,,,,,
rayyan-394626825,Real-Time Light Simulation Methodology for Expedited Comparison and Optimization Studies through Agent-Based Photon Modelling,2022,,,Building Simulation Conference Proceedings,,,,1750 - 1756,"Vaidhyanathan, Vishal and Wang, Jichen",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151533187&doi=10.26868%2F25222708.2021.30572&partnerID=40&md5=03909dfa6ff3a1722661ac897c39db74,,,,"Designing for receiving ample daylight is an integral part of an Architect's early design framework. However, conventional Daylight Simulation tools for daylight analyses are time taking due to their dependency on external simulation engines. Moreover, several inputs are required to set up the simulation process. While this maybe useful for analytical studies, conventional daylight analysis workflows in early-phase design decisions, for multiple design iterations can be cumbersome and require running thousands of test cases to optimize a design. This research proposes a step-by-step method for utilizing light simulation as a metric for optimization that uses agent- based modelling of photon particles to generate instantaneous daylight illumination results for comparative and real-time directional analysis of early-phase design iterations. This algorithm removes external dependencies of simulation engines and runs instantaneously. This enables quick performance optimization for real time design decision making, and also allows using real- time daylight impact assessment in generative design studies. It also consists of a front-end interface for non- intuitive users to perform comparative studies with ease. To demonstrate the speed and effortlessness of daylight evaluation using this methodology, a façade design is explored using multiple geometrical inputs to find an optimized solution with real-time directional and comparative feedback. It has been observed that the proposed methodology is near-instantaneous as compared to conventional simulation methods for iterative design optimization. © 2023 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",10.26868/25222708.2021.30572,Architectural design; Autonomous agents; Computational methods; Decision making; Engines; Iterati...,,,,,,,
rayyan-394626826,"2022 IEEE Conference on Games, CoG 2022",2022,,,"IEEE Conference on Computatonal Intelligence and Games, CIG",,2022,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139098016&partnerID=40&md5=298acfc327a61ed07ef95366979163fa,,,,"The proceedings contain 99 papers. The topics discussed include: paste you into game: towards expression and identity consistency face swapping; learning task-independent game state representations from unlabeled images; DOTA 2 match prediction through deep learning team fight models; counter-strike deathmatch with large-scale behavioral cloning; face in the game: using facial action units to track expertise in competitive video game play; online game level generation from music; space segmentation and multiple autonomous agents: a Minecraft settlement generator; compressing and comparing the generative spaces of procedural content generators; VMAPD: generate diverse solutions for multi-agent games with recurrent trajectory discriminators; Bayesian opponent exploitation by inferring the opponent's policy selection pattern; towards verifiable benchmarks for reinforcement learning; generating game levels of diverse behavior engagement; automatic testing and validation of level of detail reductions through supervised learning; and mastering the game of 3v3 snakes with rule-enhanced multi-agent reinforcement learning. . © 2022 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626827,Quality Assurance of Generative Dialog Models in an Evolving Conversational Agent Used for Swedish Language Practice,2022,,,,,,,22 - 32,"Borg, Markus and Bengtsson, Johan and Osterling, Harald and Hagelborn, Alexander and Gagner, Isabella and Tomaszewski, Piotr",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133467455&doi=10.1145%2F3522664.3528592&partnerID=40&md5=d565b8d72a17a1f6910a6367e1c4f20e,,,,"Due to the migration megatrend, efficient and effective second-language acquisition is vital. One proposed solution involves AI-enabled conversational agents for person-centered interactive language practice. We present results from ongoing action research targeting quality assurance of proprietary generative dialog models trained for virtual job interviews. The action team elicited a set of 38 requirements for which we designed corresponding automated test cases for 15 of particular interest to the evolving solution. Our results show that six of the test case designs can detect meaningful differences between candidate models. While quality assurance of natural language processing applications is complex, we provide initial steps toward an automated framework for machine learning model selection in the context of an evolving conversational agent. Future work will focus on model selection in an MLOps setting. © 2022 Elsevier B.V., All rights reserved.","Cited by: 1; All Open Access; Gold Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1145/3522664.3528592,Learning algorithms; Natural language processing systems; Quality assurance; Requirements enginee...,,,,,,,
rayyan-394626828,"2nd International Conference on Smart Technologies, Systems and Applications, SmartTech-IC 2021",2022,,,Communications in Computer and Information Science,,1532,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128458728&partnerID=40&md5=64339acbeecc602862b986f2a7f29bee,,,,"The proceedings contain 30 papers. The special focus in this conference is on Smart Technologies, Systems and Applications. The topics include: Lightweight Convolutional Neural Networks Framework for Really Small TinyML Devices; an Approach to Estimate the Orientation and Movement Trend of a Person in the Vicinity of an Industrial Robot; a Novel Algorithm for Greatly Accurate Electrical Fault Detection and Classification Based on Haar Wavelet; weather Recognition Using Self-supervised Deep Learning; software to Assist Visually Impaired People During the Craps Game Using Machine Learning on Python Platform; A Novel Technique for Forest Height Estimation from SAR Radar Images Using the Omega K Algorithm; air Pollution Software Architecture Design and Modeling: A Peruvian Case; automatic Recognition of Pictograms with Convolutional Neural Network Approach for Literacy; pose Conditioned Human Motion Generation Using Generative Adversarial Networks; computational Analysis of the Particles Matter in the Respiratory Tract of Children; diabetic Retinopathy: Detection and Classification Using AlexNet, GoogleNet and ResNet50 Convolutional Neural Networks; design, Implementation, and Modeling of a LoRa Network Installed in a Freshwater Body; Convolutional Neural Network for Imagine Movement Classification for Neurorehabilitation of Upper Extremities Using Low-Frequency EEG Signals for Spinal Cord Injury; a New Handwritten Number Recognition Approach Using Typical Testors, Genetic Algorithms, and Neural Networks; Land Cover Classification Using CNN and Semantic Segmentation: A Case of Study in Antioquia, Colombia; towards the Recommendation of Time for Physical Activities Based on Air Pollution and Meteorological Variables; analysis of the Generation of a Synthetic Response to the Application of Contrast Agents in Breast Medical Images Using Generative Adversarial Networks; Brain Tumor Segmentation Based on 2D U-Net Using MRI Multi-modalities Brain Images. © 2022 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626829,An artificial intelligence-driven agent for real-time head-and-neck IMRT plan generation using conditional generative adversarial network (cGAN),2021,,,Medical Physics,,48,6,2714 - 2723,"Li, Xinyi and Wang, Chunhao and Sheng, Yang and Zhang, Jiahan and Wang, Wentao and Yin, Fangfang and Wu, Qiuwen and Wu, Qingrong Jackie and Ge, Yaorong",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104898115&doi=10.1002%2Fmp.14770&partnerID=40&md5=ba50f3eead3acf6a9049532c89b5fab5,,,,"Purpose: To develop an artificial intelligence (AI) agent for fully automated rapid head-and-neck intensity-modulated radiation therapy (IMRT) plan generation without time-consuming dose-volume-based inverse planning. Methods: This AI agent was trained via implementing a conditional generative adversarial network (cGAN) architecture. The generator, PyraNet, is a novel deep learning network that implements 28 classic ResNet blocks in pyramid-like concatenations. The discriminator is a customized four-layer DenseNet. The AI agent first generates multiple customized two-dimensional projections at nine template beam angles from a patient’s three-dimensional computed tomography (CT) volume and structures. These projections are then stacked as four-dimensional inputs of PyraNet, from which nine radiation fluence maps of the corresponding template beam angles are generated simultaneously. Finally, the predicted fluence maps are automatically postprocessed by Gaussian deconvolution operations and imported into a commercial treatment planning system (TPS) for plan integrity check and visualization. The AI agent was built and tested upon 231 oropharyngeal IMRT plans from a TPS plan library. 200/16/15 plans were assigned for training/validation/testing, respectively. Only the primary plans in the sequential boost regime were studied. All plans were normalized to 44 Gy prescription (2 Gy/fx). A customized Harr wavelet loss was adopted for fluence map comparison during the training of the PyraNet. For test cases, isodose distributions in AI plans and TPS plans were qualitatively evaluated for overall dose distributions. Key dosimetric metrics were compared by Wilcoxon signed-rank tests with a significance level of 0.05. Results: All 15 AI plans were successfully generated. Isodose gradients outside of PTV in AI plans were comparable to those of the TPS plans. After PTV coverage normalization, D<inf>mean</inf> of left parotid (D<inf>AI</inf> = 23.1 ± 2.4 Gy; D<inf>TPS</inf> = 23.1 ± 2.0 Gy), right parotid (D<inf>AI</inf> = 23.8 ± 3.0 Gy; D<inf>TPS</inf> = 23.9 ± 2.3 Gy), and oral cavity (D<inf>AI</inf> = 24.7 ± 6.0 Gy; D<inf>TPS</inf> = 23.9 ± 4.3 Gy) in the AI plans and the TPS plans were comparable without statistical significance. AI plans achieved comparable results for maximum dose at 0.01cc of brainstem (D<inf>AI</inf> = 15.0 ± 2.1 Gy; D<inf>TPS</inf> = 15.5 ± 2.7 Gy) and cord + 5mm (D<inf>AI</inf> = 27.5 ± 2.3 Gy; D<inf>TPS</inf> = 25.8 ± 1.9 Gy) without clinically relevant differences, but body D<inf>max</inf> results (D<inf>AI</inf> = 121.1 ± 3.9 Gy; D<inf>TPS</inf> = 109.0 ± 0.9 Gy) were higher than the TPS plan results. The AI agent needed ~3 s for predicting fluence maps of an IMRT plan. Conclusions: With rapid and fully automated execution, the developed AI agent can generate complex head-and-neck IMRT plans with acceptable dosimetry quality. This approach holds great potential for clinical applications in preplanning decision-making and real-time planning. © 2023 Elsevier B.V., All rights reserved.","Cited by: 37; All Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1002/mp.14770,Computerized tomography; Deep learning; Inverse problems; Learning systems; Radiation; Radiothera...;Computer-Assisted; Radiotherapy;Intensity-Modulated,,,,,,,
rayyan-394626830,On the Adaptability of Recurrent Neural Networks for Real-Time Jazz Improvisation Accompaniment,2021,,,Frontiers in Artificial Intelligence,,3,,,"Kritsis, Kosmas and Kylafi, Theatina and Kaliakatsos-Papakostas, Maximos A. and Pikrakis, Aggelos and Katsouros, V.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117895449&doi=10.3389%2Ffrai.2020.508727&partnerID=40&md5=39dad68c7eedc40b26aa08c9a5f4ba59,,,,"Jazz improvisation on a given lead sheet with chords is an interesting scenario for studying the behaviour of artificial agents when they collaborate with humans. Specifically in jazz improvisation, the role of the accompanist is crucial for reflecting the harmonic and metric characteristics of a jazz standard, while identifying in real-time the intentions of the soloist and adapt the accompanying performance parameters accordingly. This paper presents a study on a basic implementation of an artificial jazz accompanist, which provides accompanying chord voicings to a human soloist that is conditioned by the soloing input and the harmonic and metric information provided in a lead sheet chart. The model of the artificial agent includes a separate model for predicting the intentions of the human soloist, towards providing proper accompaniment to the human performer in real-time. Simple implementations of Recurrent Neural Networks are employed both for modeling the predictions of the artificial agent and for modeling the expectations of human intention. A publicly available dataset is modified with a probabilistic refinement process for including all the necessary information for the task at hand and test-case compositions on two jazz standards show the ability of the system to comply with the harmonic constraints within the chart. Furthermore, the system is indicated to be able to provide varying output with different soloing conditions, while there is no significant sacrifice of “musicality” in generated music, as shown in subjective evaluations. Some important limitations that need to be addressed for obtaining more informative results on the potential of the examined approach are also discussed. © 2021 Elsevier B.V., All rights reserved.","Cited by: 8; All Open Access; Gold Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.3389/frai.2020.508727,,,,,,,,
rayyan-394626831,Technology enhanced learning using humanoid robots,2021,,,Future Internet,,13,2,1 - 17,"Reforgiato Recupero, Diego",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100411257&doi=10.3390%2Ffi13020032&partnerID=40&md5=808b2faa167ed1e64e804a679984593f,,,,"In this paper we present a mixture of technologies tailored for e-learning related to the Deep Learning, Sentiment Analysis, and Semantic Web domains, which we have employed to show four different use cases that we have validated in the field of Human-Robot Interaction. The approach has been designed using Zora, a humanoid robot that can be easily extended with new software behaviors. The goal is to make the robot able to engage users through natural language for different tasks. Using our software the robot can (i) talk to the user and understand their sentiments through a dedicated Semantic Sentiment Analysis engine; (ii) answer to open-dialog natural language utterances by means of a Generative Conversational Agent; (iii) perform action commands leveraging a defined Robot Action ontology and open-dialog natural language utterances; and (iv) detect which objects the user is handing by using convolutional neural networks trained on a huge collection of annotated objects. Each module can be extended with more data and information and the overall architectural design is general, flexible, and scalable and can be expanded with other components, thus enriching the interaction with the human. Different applications within the e-learning domains are foreseen: The robot can either be a trainer and autonomously perform physical actions (e.g., in rehabilitation centers) or it can interact with the users (performing simple tests or even identifying emotions) according to the program developed by the teachers. © 2021 Elsevier B.V., All rights reserved.","Cited by: 5; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.3390/fi13020032,Anthropomorphic robots; Application programs; Convolutional neural networks; Deep learning; E-lea...,,,,,,,
rayyan-394626832,"Proceedings - 2021 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing and International Conference on Cyber Science and Technology Congress, DASC/Pi...",2021,,,,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127545586&partnerID=40&md5=8e2c0cf20584b74d1b6debeb5f8ab919,,,,"The proceedings contain 148 papers. The topics discussed include: design and implementation of face recognition system based on raspberry pie; a privacy-preserving revocable framework in the deep-learning-as-a-service platform system based on non-software as a service; beyond homeostasis: a novel approach for assessing the stability and coherence of self-adaptive systems; a meta multi-agent reinforcement learning algorithm for multi-intersection traffic signal control; reducing model complexity and cost in the generation of efficient error detection mechanisms; quantitative security assurance case for in-vehicle embedded systems; chaos engineering for understanding consensus algorithms performance in permissioned blockchains; rethinking of reentrancy on the ethereum; self-attention based text matching model with generative pre-training; role-based approach as support for safety analysis of collaborative systems; optimizing dynamic timing analysis and reinforcement learning; impact of selective implementation on soft error detection through low-level re-execution; and applying neural networks for plant model simulation in embedded control system. © 2022 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626833,Diverse Critical Interaction Generation for Planning and Planner Evaluation,2021,,,IEEE International Conference on Intelligent Robots and Systems,,,,7036 - 7043,"Yin, Zhaoheng and Sun, Lingfeng and Sun, Liting and Tomizuka, Masayoshi and Zhan, Wei",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124348604&doi=10.1109%2FIROS51168.2021.9636266&partnerID=40&md5=b3c92dfce165641a37ee6710b4d9a0a9,,,,"Generating diverse and comprehensive interacting agents to evaluate the decision-making modules is essential for the safe and robust planning of autonomous vehicles (AV). Due to efficiency and safety concerns, most researchers choose to train interactive adversary (competitive or weakly competitive) agents in simulators and generate test cases to interact with evaluated AVs. However, most existing methods fail to provide both natural and critical interaction behaviors in various traffic scenarios. To tackle this problem, we propose a styled generative model RouteGAN that generates diverse interactions by controlling the vehicles separately with desired styles. By altering its style coefficients, the model can generate trajectories with different safety levels serve as an online planner. Experiments show that our model can generate diverse interactions in various scenarios. We evaluate different planners with our model by testing their collision rate in interaction with RouteGAN planners of multiple critical levels. © 2025 Elsevier B.V., All rights reserved.","Cited by: 13 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1109/IROS51168.2021.9636266,Decision making; Planning; Autonomous Vehicles; Competitive agents; Decisions makings; Generative...,,,,,,,
rayyan-394626835,Automated playtesting with procedural personas through MCTs with evolved heuristics,2019,,,IEEE Transactions on Games,,11,4,352 - 362,"Holmgård, Christoffer and Green, Michael Cerny and Liapis, Antonios and Togelius, Julian",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089098499&doi=10.1109%2FTG.2018.2808198&partnerID=40&md5=59381161a70f8522c6a204cbc287b7bf,,,,"This paper describes a method for generative player modeling and its application to the automatic testing of game content using archetypal player models called procedural personas. Theoretically grounded in psychological decision theory, procedural personas are implemented using a variation of Monte Carlo tree search (MCTS) where the node selection criteria are developed using evolutionary computation, replacing the standard UCB1 criterion of MCTS. Using these personas, we demonstrate how generative player models can be applied to a varied corpus of game levels and demonstrate how different playstyles can be enacted in each level. In short, we use artificially intelligent personas to construct synthetic playtesters. The proposed approach could be used as a tool for automatic play testing when human feedback is not readily available or when quick visualization of potential interactions is necessary. Possible applications include interactive tools during game development or procedural content generation systems where many evaluations must be conducted within a short time span. © 2020 Elsevier B.V., All rights reserved.","Cited by: 70; All Open Access; Green Accepted Open Access; Green Open Access | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1109/TG.2018.2808198,Automatic testing; Computation theory; Decision theory; Game contents; Game development; Interact...,,,,,,,
rayyan-394626836,Evolving levels for general games using deep convolutional generative adversarial networks,2019,,,,,,,96 - 101,"Irfan, Ayesha and Zafar, Adeel and Hassan, Shahbaz",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079357688&doi=10.1109%2FCEEC47804.2019.8974332&partnerID=40&md5=e0cf1bcb7032bbc1df77dc1463ff1031,,,,"Deep Convolutional Generative Adversarial Networks (DCGANs) are a machine learning approach that can learn to mimic any distribution of data. DCGANs consist of a generator and discriminator where generator generates new content and discriminator finds whether the generated content is real or fake. Procedural Content Generation (PCG) for level generation could potentially benefit from such models, particularly for a game where there is an existing level to emulate. In this paper, DCGANs are trained on existing levels generated through a random generator. Three different games (Freeway, Zelda, and Colourescape) are selected from the General Video Game Artificial Intelligence (GVG-AI) framework for level generation. The proposed approach successfully generates various levels which mimic the training levels. Generated levels are also evaluated using agent-based testing to ensure their play-ability. © 2020 Elsevier B.V., All rights reserved.","Cited by: 11 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1109/CEEC47804.2019.8974332,Ability testing; Artificial intelligence; Convolution; Adversarial networks; Agent-based testing;...,,,,,,,
rayyan-394626837,Optimization of statistical single subject analysis of brain FDG PET for the prognosis of mild cognitive impairment-to-Alzheimer's disease conversion,2015,,,Journal of Alzheimer's Disease,,49,4,945 - 959,"Lange, Catharina and Suppa, Per and Frings, Lars and Brenner, Winfried and Spies, Lothar and Buchert, Ralph",https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953728818&doi=10.3233%2FJAD-150814&partnerID=40&md5=1f137695e41ef463826b4dddbfad5e3f,,,,"Background: Positron emission tomography (PET) with the glucose analog F-18-fluorodeoxyglucose (FDG) is widely used in the diagnosis of neurodegenerative diseases. Guidelines recommend voxel-based statistical testing to support visual evaluation of the PET images. However, the performance of voxel-based testing strongly depends on each single preprocessing step involved. Objective: To optimize the processing pipeline of voxel-based testing for the prognosis of dementia in subjects with amnestic mild cognitive impairment (MCI). Methods: The study included 108 ADNI MCI subjects grouped as 'stable MCI' (n = 77) or 'MCI-to-AD converter' according to their diagnostic trajectory over 3 years. Thirty-two ADNI normals served as controls. Voxel-based testing was performed with the statistical parametric mapping software (SPM8) starting with default settings. The following modifications were added step-by-step: (i) motion correction, (ii) custom-made FDG template, (iii) different reference regions for intensity scaling, and (iv) smoothing was varied between 8 and 18 mm. The t-sum score for hypometabolism within a predefined AD mask was compared between the different settings using receiver operating characteristic (ROC) analysis with respect to differentiation between 'stable MCI' and 'MCI-to-AD converter'. The area (AUC) under the ROC curve was used as performance measure. Results: The default setting provided an AUC of 0.728. The modifications of the processing pipeline improved the AUC up to 0.832 (p = 0.046). Improvement of the AUC was confirmed in an independent validation sample of 241 ADNI MCI subjects (p = 0.048). Conclusion: The prognostic value of voxel-based single subject analysis of brain FDG PET in MCI subjects can be improved considerably by optimizing the processing pipeline. © 2018 Elsevier B.V., All rights reserved.","Cited by: 52 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.3233/JAD-150814,fluorodeoxyglucose f 18; glucose; radiopharmaceutical agent; aged; Alzheimer disease; Article; br...;Computer-Assisted; Male; Positron-Emission Tomography; Prognosis; Radiopharmaceuticals; ROC Curve,,,,,,,
rayyan-394626838,Proceedings - ASE 2002: 17th IEEE International Conference on Automated Software Engineering,2002,,,,,,,,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980615056&partnerID=40&md5=87cec4aff10d5845c0127609e3040c07,,,,"The proceedings contain 39 papers. The topics discussed include: assumption generation for software component verification; an approach to rapid prototyping of large multi-agent systems; generative design patterns; deviation analysis through model checking; experience report on automated procedure construction for deductive synthesis; generating product-lines of product-families; knowledge-based synthesis of numerical programs for simulation of rigid-body systems in physics-based animation; no Java without caffeine: a tool for dynamic analysis of Java programs; and constructing CORBA-supported Oracles for testing: a case study in automated software testing. © 2016 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: wrong publication type",,,,,,,,,
rayyan-394626839,Gemini in RoboCup-2000,2001,,,Lecture Notes in Computer Science,,2019,,477 - 480,"Ohta, Masayuki",https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867450862&partnerID=40&md5=638b138034ead690bf94639e0e174088,,,,"We implemented ""Gemini"" a client program for the SoccerServer. The objective of this program is testing a lot of learning methods on multi-agent environments. In the current implementation,Gemini can select the most effective strategy for an enemy,using reinforcement learning. Furthermore,w e are trying to implement a meta-level learning, which turn each learning function on or off according to whether the learning succeed or not. © 2001 Springer-Verlag Berlin Heidelberg. © 2012 Elsevier B.V., All rights reserved.","Cited by: 0 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3,EC6",,Client programs; Learning functions; Learning methods; Multi-agent environment; SoccerServer; Met...,,,,,,,
rayyan-394626840,Towards intelligent decision support systems for emergency managers: the IDA approach,2001,,,International Journal of Risk Assessment and Management,,2,3,224 - 242,"Gadomski, Adam and Bologna, Sandro and Di Costanzo, Giovanni and Perini, Anna and Schaerf, Marco",https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869062735&doi=10.1504%2Fijram.2001.001507&partnerID=40&md5=eae727d556cae786e4bc4652e6aba44b,,,,"The paper presents ENEA’s next step towards the development of Intelligent Decision Support Systems (IDSS) for large-scale industrial and territorial emergencies. The prototype IDA (Intelligent Decision Advisor) for emergency management in an oil port is analysed as a test case. The work was performed under the national R&D MICA project and specifically ENEA’s long-term strategic MINDES Program synchronized with indications of the worldwide GEMINI (Global Emergency Management Information Network Initiative) of the G7 Committee. IDA is an approach in designing intelligentagent based kernels of IDSS. In the frame of the generic TOGA (Top-down Object-based Goal-oriented Approach) model of abstract intelligent agents, IPK (Information, Preferences, Knowledge) architecture was employed. The specific IDA objectives were to develop and verify the properties of an information-managed agent and a knowledge managed agent, where the latter should suggest an action or plan after every new significant event in the emergency domain. The IDA functional kernel is composed of three simple agents: a DirectAdvisor, which interacts with the human user and emergency domain, an InfoProvider, which manages information and intervention goals and an IDAPlanner, which plans adequate interventions. For the design, UML (Unified Modelling Language) has been employed. MDP (Markov Decision Process) and CBR (Case-Based Reasoning) are used for planning crisis management actions. Owing to a generic agent model and object-based conceptualization, the IDA system should be adaptable to the different roles of emergency managers. The obtained results confirm the IPK conceptualization hypothesis and provide a concrete technological experience for the next step towards high-intelligent DSSs for the management of emergencies. © 2001 Inderscience Enterprises Ltd. © 2020 Elsevier B.V., All rights reserved.","Cited by: 47 | RAYYAN-INCLUSION: {""Nicolas""=>""Excluded""} | RAYYAN-EXCLUSION-REASONS: EC3",10.1504/ijram.2001.001507,,,,,,,,